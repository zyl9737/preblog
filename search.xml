<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[[翻译]关于无线体域网支持远程医疗监控技术的调研]]></title>
    <url>%2F2020%2F05%2F15%2F%E7%BF%BB%E8%AF%91-%E5%85%B3%E4%BA%8E%E6%97%A0%E7%BA%BF%E4%BD%93%E5%9F%9F%E7%BD%91%E6%94%AF%E6%8C%81%E8%BF%9C%E7%A8%8B%E5%8C%BB%E7%96%97%E7%9B%91%E6%8E%A7%E6%8A%80%E6%9C%AF%E7%9A%84%E8%B0%83%E7%A0%94%2F</url>
    <content type="text"><![CDATA[（本文由实验室同学翻译） 摘要：在无处不在的医疗监控(HCM)中，无线体域网(WBAN)被视为一种有吸引力的解决方案，它通过使用新兴通信技术可能成为提供病人健康转台实时监控的方法。这篇论文综述了能够用于探索医疗监控(HCM)中下一代无线体域网(WBAN)的最新无线通信技术。这篇论文也解决了用于医疗监控(HCM)中的无线体域网(WBAN)面临的关键问题。这些问题包括健康数据远距离传输约束，数据交付可靠性以及用于无线体域网(WBAN)中的短距离通信技术，中程通信技术以及蜂窝网络通信技术局限性导致的能源效率问题。因为WBAN传感器设备通常配备使用有限的电池电源，在长时间的操作过程中，他们经常会能源耗尽。现有的通信系统在进行数据通信时消耗更多能量，这一事实加剧了这种现象。这种不幸的情况为在本研究使用确定的合适的通信系统提高HCM中WBAN的上产率提供了空间。为了实现这个目标，本论文调研了新出现的技术例如低功耗广域网(LPWANs)，研究了他们的传输功率，数据传输率，高效数据交付环境下的数据可靠性，通信覆盖，时延以及他们的优缺点。因此，在远程HCM中WBAN提出了低功耗广域网(LPWAN)方案。此外，在这篇调研中为实现下一代WBAN系统以及如何改进识别通信系统去为HCM中WBAN增强生产效率的解决方案指明了未来的方向。 关键词：5G，通信技术，能源效率，医疗监控，LoRa，低功耗广域网，窄带物联网，服务质量，Sigfox,无线体域网。 Ⅰ引言 ​ 近年来，在无线传感器网络(WSNs)领域的研究工作变得日益活跃起来以改善健康护理产业，并因此提出了一种以人体为中心的新技术。这种新技术被称为无线体域网(WBANs)。无线体域网(WBANs)被称为无线传感器网络致力于医疗监控(HCM)的子领域。它是一种需要激昂传感器放置在人体内，人体上和人体周围的新型无线传感器网络(WSN)的范例。WBAN由于适用性和在医疗应用和非医疗应用中的广泛应用而获得了广泛的认可。基本上，一些WBAN传感器设备，特别是用于医疗应用中的设备致力于持续性的监控病人的身体而不影响他们正常的日常生活(文献[2][3])。值得一提的是WBAN解决方案是承诺推进HCM应用的成熟方案。不幸的是虽然WBAN解决方案有引人关注的承诺，但是他们面临许多开放性的问题去解决以使WBANs对HCM高效，有效和可信。这些问题包括能耗，数据通信可信度和广泛的通信覆盖。由于这些提到的问题，他可能难以满足HCM中WBANs的持续的健康监控，一致的健康数据收集，远距离健康数据传输，低时延，足够的数据率以及能源效率的服务质量(QoS)需求。此外，WBAN中能源消耗问题可以追溯到电池电源WBAN传感器设备，当不考虑高效能源管理方案时，在持续性健康数据监控操作中，它的能量会很快耗尽(文献[4])。一旦传感器设备能源被耗尽，传感器节点就难以将病人重要的健康数据传输到远程医疗接入点。例如，植入人体内实施WBAN医疗应用的传感器节点档期能量耗尽时难以频繁的更换医疗传感器中的电池。因此，为可靠的HCM和可持续性网络操作设计能源高效方案是至关重要的。为了实现这一复杂的任务，新兴的低功耗关于网技术是一种有吸引力的解决方案，可以探索和使用这种方案为HCM中的WBAN实现能源高效和健康数据高度可靠性。因此这篇调研的主要贡献如下： WBAN结构体系，传感器种类，应用环境的综合调研和对HCM中WBAN的服务质量(QoS)需求的考虑。 调研和比较被调查的现有的短程和远程通信技术。 调查了新出现的低功耗广域网技术的能源效用，低电磁辐射，安全性，健康数据可靠性，数据率，吞吐量，时延，成本效益和通信覆盖的情况，以便利用它的潜力去支持下一代WBAN系统。 识别LPWAN节能模式和调制机制以便于确定他们在能源效用方面的适用性。 讨论和建议电磁辐射对人体的影响。 提出未来的调研方向以缩小认识和建议的差距。 这篇论文剩下的内容结构如下：第三部分介绍了HCM中的WBANs的概况和概念，包括WBAN医疗传感器的各种种类和分类。第四部分介绍了WBANs中的不同应用场景和通信接入方式。第五部分介绍了WBAN通信结构体系和服务质量需求(Qos)。第六部分介绍了现有的短程通信技术的探索与比较。同时也讨论了用于WBANs中现有的和新出现的远程通信技术。第七部分明确研究空白，开放性问题和提出问题。第八部分是本文的结论。 Ⅱ相关的调研工作 目前，关于WBAN使用现有的短距离通信技术的调研层出不穷，而对新出现的低功耗广域网(LPWAN)通信系统的利用还有待探索。因此，我们做了一个不同于现有的调查的调查，该调查的重点是新兴的通信系统。这些通信系统能被使用以实现大规模的通信覆盖，能量效率和快速传递WBAN健康数据时的高数据可信性度。值得一提的是仅有少数调研调查了在HCM应用中低功耗广域网(LPWAN)通信技术的用途，而在HCM和WBAN的交叉领域，它的适用性和实用性还有待考虑。在现有的调研中调查了用于WBAN中的短程数据通信技术，例如文献[5]-[15]。然而，据作者所知，基于HCM应用的WBAN的低功耗广域网(LPWAN)技术的审视在文献中尚不存在。现存的文献如文献[16]调查在HCM中而非基于WBAN的解决方案的低功耗广域网(LPWAN)通信技术的概念。在文献[16]中，作者讨论了新型健康护理应用的关键需求的同时调查了新兴的LPWAN技术，这些技术有基于非蜂窝网络的技术如Sigfox、LoRa、Ingenu以及基于蜂窝网络的技术如长期演进技术(LTE)M1,窄宽带物联网(NB-IoT),专注于基于物联网(IoT)个性化医疗护理应用程序扩展覆盖全球移动通信系统(EC-GSM)。他们对LPWAN通信系统在能源效率和通信范围方面做了比较。不同于文献[16],我们为远程HCM的WBAN解决方案做了调查，使用已经出现的LPWAN技术延长网络的生命周期，实现低时延，健康数据传输可靠性和实时的WBAN系统。此外，我们也介绍了WBAN结构体系中的LPWAN的实现设计。文献[17]的作者研究了LPWAN通信系统如LoRa，NB-IoT和LTE-M在医疗环境中的应用而没有研究在WBANｓ环境下的应用。他们更侧重于共存问题。于文献[17]形成对照，我们做了LPWAN解决方案的调查，调查侧重于基于能量效率的网络服务质量需求(QoS)参数，健康数据传输可靠性，时延，通信覆盖以及电磁辐射的问题。此外，我们将LPWAN技术引入到WBANs的结构体系。文献[18]的作者为医疗护理系统做了一个基于IoT网络的WBAN的调研。健康医疗物联网网络结构体系、服务提供、安全和网络拓扑结构被审查，同时他们也简要的确定了包括6LoWPAN、蓝牙、ZigBee、IEEE802.15.6等在内的一些短程通信系统的规格。不同于文献[18]，我们做了一个不同的调查，介绍新出现的WBAN系统的专用以及非专用LPWAN通信解决方案，重点是包括实时健康数据传输、能量效率、通信覆盖和远程HCM时延在内的网络需求因素。在文献[19]中，作者做了一个用于物联网健康护理环境的射频识别技术和ZigBee技术的调研。文献[19]的作者没有考虑例如LPWAN解决方案的远程通信技术，这为这项新研究提供了一个背景。因此，不同于文献[19]，本研究利用WBAN中的LPWAN解决方案，改善远程健康护理中对病人健康状态的监控同时同时满足WBAN系统在提高能源效率、可靠度、时延性能提升方面的网络服务质量需求。 为了简单明了，对HCM中WBAN的LPWAN通信技术和LPWAN的设计实现的相关工作进行了列表调查，描述如表一。 考虑到上述讨论，显而易见的是大多数审核主要侧重于用于WBANs短程通信技术的时延，而仅有少数审核关注HCM中的LPWAN的综合性，如文献[16]、[17]，没有人开发利用WBANs中LPWAN的综合性去实现远程HCM对能源效率、低时延、健康数据传输可靠性等方面的网络服务质量需求。因此，补充现有的调查文献和弥补调研中的不足，本文侧重于探索和比较新型LPWAN通信系统为了确定在低功耗、可支付、数据率、健康数据传输可靠性和病人远程健康监控方面，LPWAN是HCM中WBANs最可行和最合适的解决方案。同时还讨论和建议了电磁辐射对病人的影响。此外，没有文献对用重点在WBANs服务质量雪球的LPWAN解决方案的设计实现进行研究，因此，甭问将考虑在WBAN中LPWAN一体化解决方案。 Ⅲ.回顾HCM中WBAN解决方案的概述和概念 Ａ．无线体域网 ​ WBAN能被描述为由几个智能和小型（大型）传感器设备组成的无线通信系统。这些传感器能植入人体或者可穿戴在人身上持续或间断性的监测重要的身体信号如心电图（ECG）、心率、血压、脉搏、温度而不影响他们正常的日常活动。这些传感器测量的健康数据被发送到远程医疗服务机构，在那里这些数据能被分析用于评估病人的健康状况以便于做出决策。WBAN解决方案能被用于包括学术、健康、工业、军队、和运动在内的许多领域（文献［20］、［21］）。它是一项很有前景的技术，能将HCM、生活方式和消费电子产品如智能手机整合到人体周围（文献［22］）。WBAN的特点是一些有趣的承诺，包括成本效益、非侵入性、主动测量和可靠性，因为它们也给病人、医生和卫生工作者带来许多好处（文献［23］、［24］）。血压计(血压计)和胰岛素泵等传感器可以帮助患者跟踪和记录他们的生理生命体征，并帮助医学专家和卫生工作者远程监测和管理患者的治疗。为了便于说明，图1表示HCM的WBAN网络的部署结构，以及到本地基站(BS)和远程医疗中心的信息传输。 Ｂ．WBAN的特点 ​ WBAN是一种独特的无线网络，由于其特殊的功能,包括传感器设备的类型是用于监控、传感器设备的数据速率的要求以实现一个可靠的健康数据通信,WBAN系统目标应用程序的环境，健康数据的流量模式，可以是连续的，也可以是周期性的;健康数据的延迟，只需要很少或者不需要延迟;健康数据的可靠性，使它不同于认知等传统网络和其他类型的网络无线传感器网络(CRSNs)。HCM中WBAN系统的这些独特特性导致了WBAN中的能源问题。应该注意的是WBAN解决方案要求的成功取决于可用的能源。由于WBAN中的能效问题，电力感知技术，如高效能通信技术解决方案以及其他可以提高能源效率的方法，在WBAN中是迫切需要的，以实现可持续工作，包括满足HCM中WBAN系统的重要要求。 Ｃ．WBAN传感器节点设备的结构体系 ​ 一般来说，一个典型的传感器设备由四个主要电路组成，包括传感电路、处理电路、通信电路和电源电路。在WBANs的背景下传感电路由医学传感器组成，如脑电图(EEG)传感器、肌电图(EMG)传感器、心电图（ECG）传感器和加速度计传感器，以及模拟数字转换器(ADC)。医用传感器在本质上是复杂的，因为它们能够准确无误地检测和监控病人身体必要部位，如脉搏率、血糖水平、体温、脉搏率和呼吸频率，而模拟数字转化器（ADC）将传感器收集的测量健康数据(模拟格式)转换为数字格式，并将其发送到处理电路。另一方面，处理电路由操作系统、微型控制器和存储设备组成。它是负责管理医疗传感器产生的数据，以及处理和传输数据到通信电路的单位。通信电路负责创建一个合适的平台，以便将数据传播到邻近的传感器设备和基站。为了实现远程监控，可以将基站（BS）连接到因特网云平台，将处理后的测量的健康数据传输到远程医疗控制中心，医疗专家在远程医疗控制中心获取特定患者所需的健康信息，以便采取医疗行动。而电源电路负责给传感器负载供电，传感器负载包括传感器、处理器、存储器和通信模块。值得一提的是，传感器节点最耗能的部分是通信电路，而传感电路以及处理电路消耗的能量较少（文献[25]、[26]）。因为传感器设备的主要能量来源是容量有限的电池，为了充分挖掘WBAN传感器设备的潜力，它们必须是节能的，这可以通过开发低功耗的通信技术来实现。为了说明，图2展示了一个典型的WBAN传感器设备架构。 D．WBAN系统中的传感器节点的分类和种类 ​ WBAN中的每个传感器根据应用的具体需求和系统基础架构被用于不同的功能（文献［27］）。WBAN中的传感器可以应用于不同的应用场景，分为医疗应用和非医疗应用。在考虑医疗应用场景时，考虑传感器设备的材料、尺寸和形状是非常重要的，以确保它们与患者身体的兼容性和它们在身体上的具体位置。HCM中使用的几个WBAN医学应用传感器的例子被分为三类，如图3所示，图4展示了HCM患者典型的WBAN医学应用传感器的定位和类型。 Ⅳ.基于WBAN的HCM应用和通信访问解决方案 ​ 有几个创新的应用程序可纳入WBAN，这些创新的应用程序分为两个主要的应用场景，包括医疗和非医疗应用程序。WBAN的医疗应用主要集中在HCM上，HCM通过有效可靠的通信技术(文献[28])，对患者的健康状况进行无缝、无处不在的持续测量，而非医疗应用则主要用于非医疗场景。出于清晰的目的，下面将讨论大量的医疗和非医疗应用。 A. 医疗应用 1) 远程HCM和远程医疗 基本上，远程HCM的主要目的是提供实时访问，以监控患者在医院外的健康状况。远程HCM有助于疾病的早期发现，预防过早死亡，降低成本，减少住院次数（文献［29］）。因此，将WBAN综合运用到远程HCM有助于慢性病的管理，因为它可以在医生的护理下无缝地自动监控患者的健康状况，而不会限制他们的日常活动。远程HCM关键特点之一是对患者生理参数的监测，以便在病情恶化之前及早发现疾病，从而减少急诊、住院和长时间住院的次数。一个好的远程HCM系统的例子可以在文献[30]中找到。文献［30］的作者提出了一个被称为“Healthface”的网页界面，它是为远程HCM设计的。该网页界面通过使用WIFI，通用分组无线电系统（GPRS）以及基于IEEE802.15.4的传输协议的基站（BS）将测量和发送病人的设管理信号给远程医生。 此外，远程医疗可以描述为利用无线通信技术进行远程医疗诊断、患者护理和治疗。远程医疗的一些主要目的是为偏远地区或医疗中心的病人提供基于专业的医疗护理，这些地方的医疗人员不足，同时使全球各地的医生、卫生专业人员和科学家能够向任何地方的病人提供医疗服务。一个基于远程医疗的研究工作的例子可以在文献[31]中找到。远程医疗能提供一个接口，专家的建议、监控和治疗几英里外的病人可以通过视屏会议。基于此综述，通信网络包括蓝牙、Wi-Fi、GPRS和IEEE 802.15.4可能广泛用于远程HCM和远程医疗。 Ｂ．周围环境辅助生活 据报道，世界上有超过10亿人患有残疾问题，包括瘫痪、学习障碍、失明和耳聋（文献[32]）。通常，受到这种限制的个人完全依靠其家庭、非政府组织和各国政府的支持（文献[32]）。值得注意的是，有些疾病也会导致残疾，其中一种被称为神经退行性疾病例如帕金森病。帕金森病是影响超过2%的60岁以上老年人的最常见疾病之一（文献[33]）。这是一种与大脑紊乱有关的疾病，最终可能导致震颤、运动障碍和姿势不稳定（文献［34］）。因此，环境辅助技术最近被用于帮助残疾人和老年人在许多方面，如姿势检测，活动监测，支持老年人，和寻路。这项技术的目的是改善在智能环境中如智能住宅和智能办公室生活方式的质量,并允许残疾人和老年人留在方便和更加安全的家园,而不是在昂贵的医院或疗养院,因此, 使得残疾人和老年人能最大化的实现独立生活（文献［35］）。另一种在老年人中流行的疾病是阿尔兹海默症。阿尔兹海默症是一种影响大脑的认知活动，如推理、回忆和思考的疾病。这种疾病会导致老年人四处流浪，也就是说，他们会对自己的行踪感到困惑。为了解决这一现象，环境辅助解决方案利用一些通信技术，如通用分组无线服务（GPRS），以帮助老年人找到他们的回家的路（文献［37］、［38］）。例如，文献[36]的作者为老年人设计了一个移动健康监测的系统，称为iCare。这个解决方案是设计来利用蓝牙的，全球移动通信系统（GSM）和通用分组无线服务（GPRS）作为其通信技术。因此，在环境辅助生活中，Wi-Fi、蓝牙、ZigBee和2G蜂窝技术用于在患者和医疗专家之间提供通信访问主要技术。 ３）紧急医疗系统（EMSs） 紧急医疗系统有助改善紧急服务，例如病人紧急情况监察、车辆紧急事故及救护车服务。在患者急诊监护中，无论在家中、医院还是在任何地方，病情危重需要及时、定期监护的患者，随时都可能需要立即就医，因此，应急响应系统应尽可能快速，以无缝的方式挽救患者的生命（文献［38］）。在交通事故中，由于道路上的车辆越来越多，道路管理系统效率低下，事故发生的频率越来越高。这使得许多人由于致命的事故而失去了生命。在传统的救护车服务中，当紧急病人到达医疗中心时，医护人员可能对病人的健康状况一无所知，促使他们在开始必要的治疗之前提出问题。这一过程可能会导致宝贵的生命损失，因为获取患者信息的时间被浪费了，而不是立即对患者进行治疗。这种情况是造成死亡率增加的因素之一。克服了传统患者急诊监护、车辆急诊事故和救护车服务的局限，在WBAN的帮助下，实现了现代化紧急医疗系统是避免过早死亡的一个很有吸引力的解决方案，因为它可以在患者到达医疗中心之前有效地提供有关患者健康状况的必要信息。在文献[39]中可以找到紧急医疗系统解决方案的一个例子。文献[39]的作者提出了一种无处不在的紧急医疗系统，它包含远程诊断和使用WiMax和3.5G无线技术的流量引导接口，以提高系统在数据速率、快速响应时间和延迟方面的性能。类似地，文献[40]和文献[41]是研究采用3G和3.5G作为通信接入解决方案的紧急医疗系统的例子。 ４）康复系统 康复是一种动态干预方法，旨在减少中风、创伤、手术、身体障碍和出院后受伤的患者的残疾和优化其身体功能。它是一种通过体育锻炼和各种活动帮助病人恢复正常运动能力的疗法（文献［42］）。康复系统还帮助患者最大限度地提高生活、学习和工作的能力，不受任何约束（文献［43］）。他们提供一些服务，这些服务可分为物理治疗，语言治疗，职业治疗和心理治疗。物理疗法帮助那些在行走、平衡、移动和进行其他体育活动方面有问题的病人。语言治疗帮助患者学习和再次失去的语言技能，如说话，阅读，写作，以及吞咽问题的患者。职业治疗帮助患者在自我照顾和其他日常活动方面变得更加独立，包括饮食、穿衣、使用电话和打字。而心理咨询可以帮助患者适应由疾病或伤害引起的重大生活问题（文献［44］）。在传统的医疗保健系统中，病人的康复是由医疗专家监督和控制的，他们帮助病人实现正常的功能能力。他们利用病人身上任何部位的记号笔和照相机来跟踪和记录他们的动作。但传统的康复系统费用昂贵、复杂，需要患者长期到康复中心就诊（文献［45］）。由于传统康复系统在复杂性和高成本方面的局限性，基于WBAN的现代康复系统更有前途，因为它使康复治疗师能够有效地远程监控患者，并监督他们的身体锻炼，以实现最佳的康复。例如，文献[46]的作者使用ANT无线技术为刚从髋关节手术中康复的患者设计了一款护臀裤，文献[47]提出了使用无线蓝牙技术来跟踪中风康复患者的运动。 Ｂ．非医疗应用 １）运动、健身和健康 最近，研究人员提出了不同类型的传感器，可以用于体育运动，其中一个传感器是可穿戴式肌肉监测传感器，可以集成到体育用品，以分析运动员的肌肉能力。同样，运动员的基本生理参数，如心率、体重、血压、体温、呼吸率和脉搏率，也可以通过使用适当的传感器来测量，以了解运动员是否适合参加比赛。例如，在运动员训练过程中，利用射频识别（RFID）和IEEE 802.15.4作为通信接入解决方案，将加速度计传感器安装在运动员身体的不同部位，观察运动员的具体姿势，从而提高运动员的运动成绩，防止运动员受伤（文献［48］、［49］）。 ２）娱乐、生活方式和互动游戏 非医疗类的WBAN可以纳入娱乐行业，包括互动游戏和消费电子产品。交互式游戏是为医疗保健、学术和广告等领域的应用而设计的。其目的是增强技能、教育和放松（文献［50］）。非医疗WBAN还可以集成到电视、收音机、数码相机、MP3播放器、个人电脑和手机等消费类电子产品中。它还支持不同的基本服务，包括导航帮助，即当开车、步行或探索新地方时，以及实时流媒体(视频和音频流媒体)（文献[51]）。在拍摄时使用通用分组无线服务（GPRS）和射频识别技术（RFID）WBAN还可以帮助电影行业捕捉演员的动作（文献[52]）。 ３）军事和国防 WBAN技术使包括士兵和警察在内的制服人员能够通过安装可穿戴的WBAN非医疗传感器进行监控。WBAN可以用来为制服人员提供环境信息，这可以帮助他们在战场上表现良好，也可以帮助他们为战斗制定战略。WBAN在军事和国防方面的另一个好处是，WBAN的非医学传感器能够监测空气的毒性，因此，如果空气的毒性水平是剧毒或致命的，它就会向制服人员发出严重警告。在军事行动中使用的WBAN非医疗传感器可以帮助减少由于恶劣环境条件、水合水平造成的身体伤害，并最终提高伤口的医疗质量。最近，人们提出了一种很有前途的技术，称为网络使能能力(NEC)系统，它侧重于未来作战的概念。该技术可用于WBAN，以提高士兵的个人水平或小队水平的表现。在个人层面，士兵的重要和健康参数，如血压、心脏脉搏和压力水平可以被监测，同时测量的数据被发送到一个接入点。此外，在小队级别，该系统在超宽带的帮助下收集的信息（UWB)技术可协助有关当局更有效地协调小队行动，以及更有效地分配任务（文献［53］）。此外,提高军事和国防部门,一个身体区域网络虚拟现实模拟器系统使用基于IP的语音传输(VoIP)作为交流访问的解决方案。在文献[54]还提出提供信息和监控士兵的训练过程,以便小队的指挥官在战场上做出出色的决定。因此，图5给出了所述WBAN系统的分类，包括医疗和非医疗应用中的传感器。 Ｃ．WBAN应用的总结 从以上讨论的WBAN应用中，我们可以推断在医疗应用中，Wi-Fi、WiMAX、蓝牙、ZigBee、2G和3G蜂窝技术通常被用作通信访问解决方案，而非医疗应用程序通常使用VoIP、UWB、GPRS和RFID等通信解决方案。但是,像窄宽带物联网(NB-IoT)这样的LPWAN解决方案是一项很有前途的技术，因为它具有吸引人的特性，例如长距离覆盖、低功耗、可靠的数据传输以及高的接收灵敏度，可以潜在地运用到到医疗和非医疗应用中。此外，只有少数作品包括文献[16]和文献[17]简要讨论了LPWAN在HCM应用程序中的使用，但没有从WBAN的角度进行讨论，作者认为WBAN系统的LPWAN解决方案还有待探索。因此，本文将对其应用进行探讨LPWAN解决方案的医疗和非医疗应用，以实现低功耗的远程通信。 Ⅴ.WBAN通信结构体系和服务质量需求 A．WBAN通信结构体系 ​ 如图6所示，一般来说，WBAN通信架构可以分为三个通信层。第一层称为WBAN网内通信，第二层称为WBAN网间通信，第三层称为WBAN网外通信。下面的小节将讨论WBAN中突出显示的通信层。 1) WBAN网内通信 WBAN网内通信在WBAN中也可以称为体内通信。这意味着放置在一个人身体的不同部分周围2米范围内的医疗传感器设备之间的通信。体内通信也可以看作是医疗传感器设备与个人服务器(PS)之间建立的通信。因此，这一层的医疗传感器设备可以测量患者身体的重要参数，并将其转发给作为网络网关的个人服务器。然后，个人服务器通过无线通信网络可能包括蓝牙网络或ZigBee网络将测量数据传输到下一层，即第二层的基站(BS)(文献[55])。此外，根据网络需求的不同，可将个人服务设备(PS)与3G、4G和2G 以及GPRS等蜂窝技术相结合。 2）WBAN网间通信 ​ WANB网间通信描述了一个个人服务设备和一个或多个基站之间的通信。因此，基站接收来自个人服务设备的传输数据并将其连接到互联网。基站可以被视为网络上最重要的基础设施的一部分，它可以被定位为处理医疗应用中的紧急情况。基本上，这一层的通信目的是将WBAN与其他网络连接起来，以便通过包括互联网在内的几种通信媒介轻松检索健康数据。 因此，WBAN的网间通信模型可以分为两个子类，即基于基础设施的体系结构和基于ad hoc的体系结构。基于基础设施的体系结构主要用于WBAN，因为与基于ad hoc的网络相比，它能够提供更好的集中式安全控制措施和管理。由于采用了集中式体系结构，可以将基站用作与应用程序相关的数据库服务器。类似地，基于基础设施的网络可以应用于有限的环境中，如卫生中心、医院、办公室和家庭(文献[56])。基于ad hoc的架构使用多个基站，部署这些基站是为了使医疗传感器设备能够在更大的环境中中继它们的信息。Ad hoc中的多个基站架构部署可能配置形成网状拓扑结构,允许更多的服务覆盖以及能够支持病人的自由运动通过扩张的网络使用一种多跳传播方法,而不同于基础结构体系有服务覆盖范围的限制。因此，在考虑短期和长期设置时，基于ad hoc的连接类型更适合，因为服务覆盖区域扩展的典型距离为2 m 到100 m（文献[57]）。这一层可以使用的通信技术的一个例子是WiFi。 3）WBAN网外通信 ​ 在这一层建立的通信类型是为了在更广阔的区域位置使用。为了实现WBAN的远程通信，WBAN网间通信层和网外通信层能通过网关连接起来。例如，智能手机可以用作网关。通过允许授权的医疗专家远程访问医疗数据库中的患者健康数据，WBAN网外通信可用于改进WBAN应用程序以及在患者健康监测期间提供的服务覆盖。通过采用可用于远距离通信目的的通信技术，例如支持互联网的通信技术，新兴的LPWAN技术。因此，在医疗设置中，数据库被认为是WBAN通信的重要组成部分，因为它包含了危重患者的档案和健康历史。此外，WBAN网外通信数据库有助于存储可用于治疗的患者医疗信息，并在出现紧急情况时通知患者家属。 B．服务质量需求 1)能源效率 ​ 能源效率可以描述为一种设计考虑，用于最小化或降低系统中的能源消耗。节能技术可以应用于WBAN的应用中，以实现可持续的WBAN系统。以下是能效在WBAN系统中非常重要的主要原因: 通常情况下，医务人员远离他们的病人，尤其是患有慢性疾病的病人，唯一有效的方法是利用高效的HCM传感和通信技术来收集和传输这些病人的医疗数据。这些技术所涉及的传感器设备无法承受在数据收集和数据传输上花费更多的能量，因为它们主要依靠电池工作。 在任何通信网络中，能源效率都是一个基本问题。一旦一个网络中的能量耗尽他将失去活力。因此，为了实现网络的可持续运行，WBAN系统的节能是非常必要的。 由于WBAN应用程序的差异，有些应用程序需要低数据速率，而有些则需要高数据速率。WBAN应用程序之间数据速率要求的差异会影响对数据速率要求高的应用程序所消耗的功率。这在技术上是由于数据速率和功耗之间的权衡。因此，为了在功耗和高数据速率之间取得平衡，需要采用节能方案来优化数据传输，以减少数据传输的能耗。 2) 健康数据安全需求 另一个非常重要的要求是WBAN健康数据，这可以用于隐私、保密性、数据加密和完整性。WBAN中的安全性可以指在收集、处理、传输或存储数据时，保护患者的医疗数据或信息不受任何未授权人员的侵犯。在隐私和机密信的背景下，,病人的健康数据必须受到保护以这样一种方式,只有授权的医务人员可以访问集合以及使用病人的健康数据,也确保他们的健康信息不向任何第三方泄露或窃听(文献[59])。在任何情况下不能发送错误的数据因为一旦错误的数据被提供给医生，这可能会导致错误的治疗和处方从而导致病人的过早死亡。数据完整性和加密仅仅意味着保护患者信息的内容。在健康监控期间，加密的WBAN必须能够识别信息是来自冒名者还是来自知名可信医疗中心。 1) 健康数据的传输和可靠性 数据速率可以指健康数据的数量，也可以指健康数据在特定时间通过通信链路传输的速度(或速率)。在在WBAN中，数据速率需求的不同取决于应用程序的性质和应用程序流量模式的类型，如连续流量和周期性流量。一般来说，WBAN传感器设备需要几kbps (&lt; 1kbps)的数据速率才能实现对身体的监控，而对于实时视频流则需要非常高的kbps (&gt; 1000kbps)(文献[60])。同样，为了使健康数据传输可靠，在考虑WBAN系统的设计时，有必要确保最佳误码率(BERs)。误码率可以描述为单位时间内比特错误(数据丢失)的度量。例如,满足WBANs健康数据传输的可靠性要求,高数据率的传感器设备需求可能在环境的特点是低价值误码率的方方面面,例如,10 -10的权力,而传感器设备要求较低的数据率可能在环境的特点是高价值的误码率等于10 - 4的权力(文献[61])。类似地，通过开发不同的编码和自适应调制技术，适合一个WBAN系统的物理层通信信道条件可用于优化传输链路的误码率值(文献[62])。 2) 提供重要数据 WBAN系统中的大部分数据都是重要数据，需要实时的数据通信，以实现与合适的体检场所之间可靠的健康数据通信。具体来说，针对HCM的WBAN解决方案需要根据患者的健康状况，定期或连续地向各个医疗中心或医院实时严格的传输医疗数据。此外，为了满足HCM部署的WBAN中对数据重要性支持的要求，实现基于重要性的健康数据参数识别机制至关重要。这将使医疗专家作出适当的决定，并提出一个优先次序，以便及时提供最佳的医疗援助。 3) 健康数据时延 时延是指数据从一个设备传输到另一个设备所花费的时间(或延迟)。为了避免将健康数据发送到远程医疗中心的延迟，应该尽量减少WBAN系统医疗应用程序的时延。例如，在医疗应用中，健康数据的时延不应达到125 ms，而在非医疗应用中，应保证数据时延不超过250 ms(文献[63])。WBANs的数据时延要求的严格是由于大多数医学应用,例如,紧急医疗系统,不能容忍低响应时间,因为如果健康数据收集不及时交付一个医疗中心在处理紧急情况时可能会变得没有用的。然而，值得注意的是，如果所采用的通信技术在过于拥挤的频带中运行，WBAN系统在卫生数据通信方面可能会由于干扰挑战而遇到时延问题(文献[64])。为了处理医疗应用程序中的延迟，在文献[65]和[66]强调了一些可能在WBAN系统中有用的解决方案。 4) 吞吐量需求 吞吐量是用来测量一个系统在给定时间内可以处理的数据单位。它可以进一步描述为WBAN系统一个通信信道带宽可以传输的数据总量。由于大多数WBAN健康数据是关键的，需要及时地将健康数据发送到远程医疗中心，因此需要最佳的吞吐量来提高WBAN系统医疗数据的通信效率(文献[67])。为了实现这一点,一个WBAN系统的吞吐量可以通过最大化WBAN网络中传感器设备的单个吞吐量来优化，也可以通过最大化所有传感器设备的整体网络吞吐量来优化。 5) 通信带宽中的共存问题 WBAN可以描述为健康数据监控和通信系统。因此，作为通信系统的WBAN要求通信频带在网络设备之间提供通信信道。通信频带可以称为频带。它是射频(RF)频谱中给定的频率范围。出于经济原因，主要用于未授权的工业、科学和医疗(ISM)频段，如2.45 GHz，包括915 MHz。例如，通信技术包括ZigBee，蓝牙、WiFi和其他一些标准通常被用于WBAN的健康数据通信，它们在ISM频段上运行。请注意，除了WBAN之外的其他通信系统，例如WSNs和无线认知网络(CRNs)，也可以在WBAN 工业科学医疗(ISM)波段上运行。因此，这些无线通信技术的数量和多样性正在不断增加，使带宽过于拥挤。由于工业科学医疗(ISM)频带过于拥挤的特性，在频带上共存的过多的通信系统可能受到干扰。因此，为了使WBAN医学应用程序可靠，特别是在紧急情况下，需要实现具有抗干扰能力的技术。 6) 广阔的通信范围 一需求对于提高现有WBAN解决方案的性能对于下一代现代WBAN系统的开发是非常必要的。在下一代的发展中WBAN系统需要将关键的设计因素考虑到系统中，以解决现有系统的局限性。这些考虑可能包括考虑低成本的通信技术，这些技术能够在远距离的医疗中心以高效和可靠的方式传送病人的健康数据，因为病人可能是坐着的。 7) 低电磁辐射 高电磁波辐射可能会对人体健康造成很大的危害，因为它可能会造成不同的健康危害，如组织破坏、血流减少和酶紊乱等(文献[68])。由于WBAN是一个以身体为中心的网络，即与患者身体直接接触的网络，因此在设计WBAN系统时，必须考虑传感器设备在数据通信过程中所辐射的电磁波。外，值得一提的是，在高功率级别传输的身体传感器设备将实现高吞吐量，这是相当好的，因为更高的吞吐率提高了成功传递健康数据的分组成功率。然而，通过传感器设备以更高的功率水平传输会自动增加患者身体组织吸收的电磁辐射，这也会违反联邦规定的人体组织的可接受的特定吸收率(SAR)，即通信委员会(FCC)制定1.6 W/Kg的1g的规定。特定吸收率(SAR)用于测量人体及其组织在受到射频电磁辐射时，如何从电磁辐射中吸收能量或射频能量。为满足特定吸收率的约束要求:WBAN系统中每个医疗传感器设备的健康数据辐射功率约为0.0001 W，即-10 dBm，不应超过最大传输功率&lt; 0.001 W或0 dBm。 10)保障服务需求的供应 ​ 由于WBAN系统需要严格的服务质量需求(QoS)要求，如能效、健康数据可靠性、低时延端到端传输等，因此在HCM部署的WBAN中，服务质量需求(QoS)保障供应方案是非常必要的。然而，根据应用程序场景(例如，医疗和非医疗应用程序)，健康数据可靠性和电力利用率之间存在权衡。这需要在权衡之间取得平衡，以满足应用程序的需要。这种机制可能包括使用合适的通信技术，以支持低能耗和高数据可靠性。表二:HCM的医疗和非医疗应用的QoS要求与传感器类型、数据速率、频率、准确性、能耗和时延的关系。 Ⅵ.WBAN通信技术的回顾 本节将回顾现有的最先进技术和新出现的无线通信技术，如图7所示。在有效的数据通信、成本效益、能源效率以及鼓励快速开发和部署WBAN系统的能力方面，确定了它们的特点、优势和局限性。 A．短程通信技术 1) IEEE 802.15.4技术 IEEE 802.15.4技术是应用最广泛的通信标准之一，被认为是一种短程通信解决方案。它是由IEEE 802.15.4组设计的第一个在低数据下运行的标准用于数据通信的无线个域网(WPAN)。由于该技术的目标是低数据传输，所以它消耗的能量很低。因此，本标准的主要目标是最大化传感器设备的电池寿命。IEEE 802.15.4网络已经被证明是一个很好的可接受的技术标准，其他通信技术也可以作为其基础，如ZigBee、6LoPWAN等IEEE类通信技术802.15.4声明的技术。它可以在100米以内的网络覆盖范围内使用。IEEE802.15.4标准被研究人员证明是一个合适的解决方案，在监测系统，如无线传感器网络，因为它提供了一个较低的数据率。但是，在数据传输速率方面，部分满足WBAN的要求，但并不能完全满足WBANs低功耗的要求(文献[75])。 2) ZigBee技术 ZigBee是ZigBee联盟开发的一种无线技术，旨在为wban提供低功耗网络和低成本的短距离通信。在网络安全的背景下，ZigBee安全基于一种高级加密标准(AES) 128位算法，该算法提供了数据认证方面的安全性，并保证了数据完整性和数据隐私(文献[76]、[77])。此外，支持ZigBee的设备可以基于星型、网型(点对点)和树状网络拓扑进行连接。此外，ZigBee技术可以在包括915Mhz、868 MHz和2.4GHz在内的未经授权的工业科学医疗(ISM)频段上运行。在2.4 GHz频带下可提供高达250 kbps的数据传输速率，而在915 MHz和868 MHz频带下可分别达到40 kbps和20 kbps的数据传输速率。ZigBee技术可用于在有干扰的恶劣环境中覆盖约40米的通信范围，在与其他网络干扰较少或没有干扰的情况下覆盖约100米的通信范围。关于利用ZigBee技术的HCM应用包括文献[78]、[79]和[80]。文献[78]的作者改进了用于生物医学应用的2.4 GHz ZigBee收发机。文献[79]的作者利用ZigBee技术开发了一种低功耗可穿戴心电传感器。在文献[80]中，一个陪护系统被设计用来监控患有阿尔茨海默病的病人，并通过使用一个网型拓扑的ZigBee技术。值得一提的是，可以在WBAN通信体系结构的第2层使用ZigBee技术。 3) 蓝牙技术 蓝牙技术也可以被称为蓝牙经典解决方案是另一种无线近程通信技术，旨在取代移动系统连接中的电线无线个域网(WPAN)。该通信解决方案由IEEE 802.15.1组设计。蓝牙设备可以在2.4 GHz的免费许可ISM频段上运行，拥有79个接入通道，并可以以每秒1 Mbps的速率传输数据。蓝牙物理层采用高斯频移键控(GFSK)调制技术和跳频扩频技术(FHSS)方法，以支持1600跳/秒的速度减少衰落和干扰。发展蓝牙技术是为了提供低操作成本、低延迟、高数据速率传输和2 - 10米的通信范围。由于上述特点，蓝牙技术可以应用在需要高数据传输的WBAN系统中，但这也带来了较高的能量成本，代价是高的能量损耗(文献[81])。传统蓝牙的其他限制包括待机模式不足、连接设备有限、启动时间慢。的新(或改进的)版本蓝牙技术被称为低功耗蓝牙(BLE)，也被称为蓝牙4.0。低功耗蓝牙(BLE)是由蓝牙特别兴趣小组提出的(BSIG)和这个组负责的发展蓝牙技术以及技术规范的设计。低功耗蓝牙(BLE)技术主要应用于那些只以周期性方式传输数据的设备，这在技术上使它在非活动状态(即没有数据传输时)进入睡眠状态。 4) IEEE 802.15.6技术 IEEE 802.15.6标准是由IEEE任务组为WBAN设计的一种短程通信标准，与其他无线标准相比有几个优点。这个标准被用于人体上，人体周围的通信同时也用于电子消费产品。该技术的目的是为WBAN实时应用程序提供一个能够成功实现低功耗、低成本、高数据速率和低复杂度实现的标准。该标准可以在物理层(PHY)和媒体访问接入层(MAC)中以1 到 10Mbps的高数据传输速率运行。IEEE 802.15.6标准将wban中使用的物理层通信频带分为三个不同的层，即超宽带层(UWB)、窄带层(NB)和人体通信层(HBC)。超宽频被用来在两个不同的频段上工作，包括一个低频段和一个高频段。低频段由3个通道组成，强制通道为2个，高频段为8个通道，强制通道为7个(文献[82])。窄带层(NB)控制网络上的数据通信以及WBAN无线电收发信机的激活和停用，并负责清除信道评估。人体通信层(HBC)利用身体作为传输电信号的通信媒介，并利用或支持从5MHz到50MHz的频带。 5) 短程通信技术的总结 为便于理解，表Ⅲ列出了属于短程通信范畴的技术。值得注意的是，这类技术适用于HCM应用程序医疗传感器设备的本地部署,因为他们有一个有限的范围内5 - 200,然而,他们的通信覆盖范围可以扩展,例如无线个域网ZigBee网络可以利用一种扩大数据路由的方法,但这种扩张的高能耗和可能导致网络效率低下。因此，本总结将帮助WBAN设计人员在考虑HCM部署所采用的适当技术时，例如，以下一些因素包括能源效率、通信覆盖范围、时延、数据率和成本。 B．中程通信技术 1)IEEE 802.11ah(WIFI)技术 ​ Wi-Fi技术可以描述为基于无线局域网(WLAN)技术的IEEE 802.11ah标准。Wi-Fi设备可以在5和2.4 GHz的未授权工业科学医疗(ISM)频段上运行，数据传输速率高达11 到54 Mbps。WiFi的高速数据传输技术可以归因于其利用大量高效编码技术的能力。它也有能力覆盖超过100米的通信范围。它是一种支持互联网的通信技术，可以用于在WBAN中提供互联网连接。在短通信范围内，WiFi也被认为在高速和高数据传输速率方面优于其他通信技术（文献[83]）。因此，Wi-Fi技术可用于医疗和非医疗应用场景，例如视频流、电话会议和视频会议。然而，当WiFi解决方案在WBAN中使用时，由于其高数据传输速率，与其他技术相比，它有可能消耗更多的电能。该技术可能不适用于一些低能耗的WBAN系统医疗应用。 2)低功耗IEEE 802.11ah(WiFi)技术 这项技术是为了解决传统Wi-Fi技术的能效问题而开发的，预计将低至数百毫瓦，因此低功耗Wi-Fi可以被视为对传统Wi-Fi的改进。改进后的技术可在约1公里的通信覆盖范围内接入7000多台设备，并采用节电机节能(文献[84])。这项技术可以以347Mbps的速度传输数据。它也可以用来设计单跳网络。低功耗WiFi采用正交频分多址(OFDMA)调制方案，包括物理层操作的正交幅度调制等附加调制技术，这可能在一定程度上有利于满足WBAN的能效要求。低功耗WiFi技术工作在1 GHz一下的未授权ISM频段，数据速率约为8Mbps (文献[85])。 3)中程通信技术的总结 ​ 考虑到低功耗WiFi技术具有数据传输率高、通信距离远、能耗低等特点，低功耗WiFi技术在HCM应用中的WBAN应用前景十分广阔。然而，由于WBAN健康数据至关重要，因此在为HCM设计WBAN解决方案以实现效率时，考虑提供低数据延迟和大距离通信覆盖的技术会更有利。表四总结了中程通信技术。 C．远程通信技术 1)传统蜂窝网络 a:2G蜂窝网络技术 ​ 第二代(2G)技术是指在全球移动通信系统(GSM)上商业化引入的数字蜂窝通信系统网络大约在1991年。2G技术可以用于语音通话、消息传递和传真等服务，也可以用于大约9.6 kbps的数据传输(文献[86])。该技术采用码分多址(CDMA)方案来识别呼叫者。有一些好处可以归因于2 G技术,这些好处包括安全机制它雇佣的发送者和接收者,低消费的备用电池,低辐射最小的影响人体健康,同时也限制欺诈的行为,因为它是不可能有相同的手机号码。然而，2G技术也有很多缺点，其中之一是在实现更好的网络服务之前，对数字信号的要求比较高，另一个限制是数据速率低。2G技术的限制为其他改进版本如2.5G技术，也称为通用分组无线电系统(GPRS)提供了环境，旨在将数据传送速度提升至约171.2 kbps。 b:3G蜂窝网络技术 ​ 3G代表第三代蜂窝系统，由国际电信联盟(ITU)开发。该技术的目标是获得高速数据传输和无线宽带。第三代技术采用的是由全球移动通信系统(GSM)提出的通用移动通信系统(UMTS)。通用移动通信系统(UMTS)还采用了一种称为宽带码分多址(WCDMA)的无线电技术，不同于2G技术中的码分多址(CDMA)，目的是实现高带宽。由于其高带宽，宽带码分多址(WCDMA)技术通过统计复用提高了数据传输速率，提高了系统的服务质量需求，增强了技术的能力。在此基础上,能够达到的最大数据速率固定3G兼容设备2 Mbps,和行人缓慢移动(即用户)下降到大约384 kbps，高速移动用户如在车内的用户的数据率进一步下降到144Kbps。因此，3G技术可以在WBAN中使用，因为它提供的数据速率不同，可以在WBAN中支持移动患者的移动性。然而，3G技术的电磁波辐射可能会对人体健康造成危害，而且3G使能设备消耗更多的电能，这可能会缩短设备的电池寿命。文献[87]的作者考虑了利用3G技术实现实时无所不在的HCM。 c:4G蜂窝网络技术 ​ 4G是第四代移动通信技术，旨在提供惊人的传输速度，由国际移动通信公司(IMT)设计，是对3G技术的发展。3G和4G技术的主要区别在于安全性、数据传输速率和访问方法。4G技术有两个提供宽带无线服务的通信标准，即长期演进(LTE)和全球微波接入互操作性(WiMAX)。因此，设备可以不受任何干扰地保持与4G技术的连接。与Wi-Fi等其他互联网接入技术相比，4G的覆盖范围为几公里。然而，4G技术仍有部分地区无法接入，数据传输速度快，降低了设备的电池寿命(文献[88])。 2)传统蜂窝网络技术总结 ​ 自从2 G、3 G和4 G蜂窝技术作为移动通信运营技术,可以用来提供互联网接入连接WBAN系统以及实现广泛交流,因此任何蜂窝技术可能用在WBAN网内,网间,或网外通信体系结构中。蜂窝技术具有相当大的通信覆盖范围，数据传输速度快，具有足够的移动支持和良好的安全措施。例如，蜂窝技术提供了高吞吐量，但同时也带来了高能量需求、复杂性和高成本。而且，它们不能满足WBAN所需的低延迟和高健康数据可靠性。此外，值得一提的是在支持蜂窝网络技术的设备中的电池能源只能维持几天或则几个月，这可能会导致网络故障，特别是当医疗传感器设备被植入患者体内，而电池无法充电或容易更换时。因此，考虑到蜂窝技术的上述局限性，我们认为蜂窝技术并不是实现HCM高效WBAN系统的理想通信解决方案。因此，所审查的蜂窝技术的总结如表五所示。 D．低功耗广域网通信系统 ​ 最近，LPWAN解决方案正在出现并获得的认可超过了已有的短程通信和蜂窝网络通信技术，因为它们能够解决长距离通信、低成本连接和低功耗的大规模通信。传统的WBAN系统通常采用短程通信技术和蜂窝网络通信技术进行健康数据通信，例如，由于WBAN中的传感器设备主要依靠电池供电，在对患者状况进行持续监测的过程中会消耗大量能量。因此，为了实现以低功耗实现远程通信、实时数据通信和高效节能的WBAN系统这一长期愿景，LPWAN通信系统有望实现上述WBAN 服务质量需求。因此，本研究工作将LPWAN分为两大类，包括基于专有的通信系统和基于非专有的通信系统的LPWAN。以下讨论不同LPWAN类别下的解决方案。 1) 基于专有通信系统的低功耗广域网 这类LPWAN通信系统也称为基于非蜂窝的LPWAN解决方案，这意味着它们是私有技术，需要专用网关来实现互联网连接。该专有解决方案为无线系统通信提供了大量先进和灵活的基础设施部署。由于基础设施部署中的需求，这些技术可能不是没有成本效益的。因此，本节将探讨基于专利的LPWAN解决方案的类型，包括RPMA、Sigfox和LoRa技术。 a:RPMA/INGUNE网络 ​ Ingenu技术是一种自2008年就存在的无线技术，以前被称为On-Ramp无线技术。Ingenu支持双向通信，即上行通信和下行通信。这种技术当部署在自由许可的2.4GHz工业科学医疗(ISM)频带上时，比部署在低于1GHz的ISM频带上更有优势，由于2.4 GHz频段可以在全球范围内使用，因此具有更宽的频段，没有占空比约束，并且还有额外的天线(文献[89])。RPMA网络在城市地区的通信覆盖范围约为3公里，有可能实现168db的通信链路预算，接收机灵敏度为-142 dBm，信号强度可达建筑物深部，即使是地下也有很高的传输功率(文献[89])。然而，也有一些缺点可以归因于RPMA技术，例如在通信过程中由于使用了自由授权的频带而可能发生的干扰。这一限制可能会影响部署在HCM的WBAN中的RPMA网络在能效、健康数据可靠性和基础设施部署成本方面的有效性。 b:Sigfox网络 ​ Sigfox是LPWAN专有技术范畴内的另一个无线通信网络，旨在满足包括WBANs无线系统在内的物联网需求。Sigfox的设计目的是实现远程通信，方便连接，延长电池待机时间，更好的网络容量，减少设备(即Sigfox模块)的成本。它提供了较高的服务质量要求，具有更好的抗干扰能力。Sigfox技术适用于低成本的设备，这些设备需要在低功耗的情况下工作，并且需要在大的通信范围内传输数据。此外，Sigfox利用的是1GHz以下的非认证ISM频带，在欧洲和美国分别是915 MHz和868 MHz，数据速率极低，约为100bps，因此，Sigfox可以通过采用视线通信方式实现高灵敏度的远程通信。例如，Sigfox在农村地区可以达到约50公里的通信覆盖，在跳频的帮助下可以扩展，而在城市地区由于障碍物的原因，通信覆盖范围缩小到约10公里(文献[90])。所有提到的这种技术的特点,Sigfox可以被认为是一个优秀的无线技术,可以用在WBAN医学应用如远程HCM达到低功耗,长距离通信,良好的安全机制,低电磁辐射对病人的身体(文献[91])。但是，Sigfox有一些限制，包括低数据传输速率、干扰问题和高延迟。另外，根据WBAN应用程序的要求，这种技术的电池寿命大约只有5年。医疗应WBAN中的Sigfox通信系统架构如图8所示。 c:LoRa网络 ​ LoRa Alliance专有LPWAN技术由LoRa和LoRaWAN协议两大部分组成(文献[92])。LoRa指的是远程传输，是一项专利的无线技术，可用于WBAN等无线系统，目标是低功耗设备和一次不需要发送大量数据的设备。因·此，LoRa可以用于延长电池寿命，获得较低的设备成本，实现较长的通信距离，并增强网络容量(文献[93])。LoRa 物理层(PHY)在免费认证的ISM频带上运行，运行频带是868 MHz还是915 MHz，取决于部署区域。类似地，一个LoRa 基站或网关就可以覆盖大约数百公里的城市区域(100公里)视环境和障碍物的存在而定。LoRa的链路预算高于其他任何传统通信技术标准。此外，LoRa的低功耗和远程通信特性使其成为一种令人惊叹的传感和监测系统技术，包括HCM中的WBAN系统，以及用于环境监测、工业应用和智能计量的无线传感器服务网络(WSN)系统(文献[94])。LoRaWAN是一种MAC层广域网协议结合LoRa技术物理层实现网络架构。该协议利用一种简单的ALOHA调制机制，利用星形网络拓扑实现上行通信，从而在远程通信过程中延长电池寿命。文献[95]、[96]和[97]是考虑使用LoRa用于HCM工作的例子。从上述研究中可以推断，LoRa解决方案可以潜在地整合到远程HCM中，但该解决方案存在网络规模有限、数据传输速率低、部署成本高、干扰问题等缺点。与WBAN相关的LoRa体系结构包括传感器设备、LoRa网关、LoRa服务器和一个远程设备包括一台计算机，如图9所示，传感器设备连接到LoRa网关，然后通过回程系统连接到网络服务器，当网络服务器通过互联网协议连接时，医护人员可以从医院数据库服务器检索患者的健康数据，以管理治疗或采取任何进一步的行动。 1) 基于非专有通信系统的低功耗广域网 基于非专有的通信系统的LPWAN网络使用的是蜂窝网络。非专有LPWAN的例子有窄带物联网(NB-IoT), LTE Cat M1, and EC-GSM IoT, 它们构成了新兴5G网络的基本构件。5G代表着第五代蜂窝网络技术，该技术被认为具有与前辈相比更高的数据传输速率、更高的可靠性和更高的带宽。它是一种基于IEEE 802.11ac宽带无线连接标准的技术，而最终标准预计将由国际电信联盟(ITU)制定(文献[98])。5G技术的演进正帮助物联网的应用变得更广泛。因此，5G蜂窝技术将通过数十亿个智能对象(如传感器设备)的大规模连接，为下一代WBAN系统做出巨大贡献，实现一个惊人的生态系统。据设想，5G技术应该能够在城市地区以大约10,000 Mbps的数据速率传输，在农村地区以1,000 Mbps的数据速率传输。5G将在其架构中集成传输网络需求，通过采用自回程技术来提高数据通信的可持续性(文献[99])。5G还应该能够提供更宽的带宽,在3GHz到5GHz能提供100MHz的宽带。5G技术还有望提供一个快速、灵活、可靠的网络(文献[100])，这将有助于WBAN更好地远程监测患者的健康状况。此外，它还应能够协助医务人员以无缝和远程的方式对患者进行治疗。5G有望促进数据和视频的快速传输，这可能有利于在远程医疗领域帮助外科医生使用机器人手术刀进行手术。 与专用LPWAN解决方案相比，非专用LPWAN解决方案使用现有的蜂窝网络基础设施进行互联网连接。因此，就基础设施部署成本而言，这类技术可以被认为是具有成本效益的。在此类别中确定的解决方案技术讨论如下。 a:长期演进(LTE)CAT技术 ​ LTE Cat技术也被称为增强型机式通信(eMTEC)，包括WBAN系统在内的无线网络中的LTE Cat M或LTE-M。该技术可以被看作是一个有吸引力和前景的LPWAN解决方案，正如第三代合作伙伴计划（3GPP）在第13版标准中提出的那样，以实现低功耗、扩展通信范围、最小化部署成本和低复杂性。LTE-M采用了一种新的节能方案和扩展的不连续接收(eDRX)方案，将LTE-M使用设备的电池寿命延长至10年以上(文献[101])。此外，LTE-M的上行数据速率峰值可达1mbps，下行数据速率约为384 kbps，延迟在50 - 100ms之间。LTE-M可以实现约11公里的出色通信覆盖，最大吞吐量小于或等于1 Mbps。此外，LTE - M可以应用于大量的物联网用例，包括HCM中的WBAN(如患者监控和可穿戴设备)、安全系统(如家庭安全监控)、工业应用(如资产管理)和交通(文献[101]、[102])。但是,LTE-M的通信覆盖范围有限，在一个基站上只能支持大约20,000台设备。 b:扩充覆盖的全球移动通信系统(EC-GSM)技术 ​ 在EC-GSM技术中，第三代合作伙伴计划(3GPP)提出了GSM覆盖的扩展，通过调整和利用现有的2G基础设施，以在无线网络中提供可靠和高效的物联网连接。该技术采用了两种调制方案，其中包括8进制相移键控(8PSK)，它支持约240kbps的传输速率和高斯最小移位 键控(GMSK)，数据速率约为350bps 到70kbps。此外，EC-GSM通信网络的目标是单个蜂窝内连接约50,000个传感器设备，根据传输功率可支持154到164 dB范围内的链路预算，并采用不连续接受方案(eDRX)调制机制来提高能效(文献[103]、[104])。值得注意的蜂窝是单个基站(BS)在蜂窝网络中可以服务(或覆盖)的地理区域，图10给出了在WBAN环境下EC-GSM技术的典型场景，包括向远程医院传输健康数据。 c:窄带物联网(NB-IoT)技术 ​ 窄带物联网(NB-IoT)技术也被称为LTE Cat-NB1。该技术是第三代合作伙伴计划(3GPP)规范中一个很有前途的标准，其设计目的是实现低功耗通信，以延长传感器设备的电池寿命，改善信号覆盖，并增强灵活部署。此外，窄带物联网(NB-IoT)技术利用现有的蜂窝技术基础设施(如蜂窝基站)，这有助于降低其部署成本，并得到全球30多家移动网络运营商的支持，为约34亿台设备提供通信覆盖，在地理上有能力为超过90%的物联网使用案例提供服务，例如WBAN。窄带物联网(NB-IoT)可应用于多种物联网应用，如无线网络，包括WSNs、WBAN中的eHealth、智能跟踪与计量、新兴产业如智慧城市、智能农业等(文献[105])。此外，窄带物联网(NB-IoT)可以与传统的通用分组无线服务(GPRS)、长期演进计划(LTE)和全球移动通信系统(GSM)技术共存，获得优异的性能。在媒体访问接入(MAC)层,窄带物联网(NB-IoT)技术在上行传输时可以使用单载波时分多址技术，传输数据的速率范围为0.3 kbp 到180 kbps,而在下行传输数据时在物理层(PHY)使用一个正交频分多址(OFDMA)调制技术,传输数据的速率范围为0.5 kbps到 200 kbps (文献[106])。类似地，窄带物联网(NB-IoT)可以实现一个上行数据传输的时延小于10秒。正交频分(OFDM)和单载波正交频分多址(SC-FDMA)调制机制对窄带物联网(NB-IoT)是有利的，因为它们使每个单元能够管理超过50,000个设备的连接，从而为每个家庭的约40个设备提供通信服务(文献[107])。窄带物联网(NB-IoT)解决方案可以提供约35公里的通信距离(文献[95])，实现低功耗，提高信号穿透能力。 ​ 窄带物联网(NB-IoT)工作在认证的频段上，由于认证的频段具有明显的高输出功率限制，相较于其他通信系统常用的ISM频段，该频段更具有优势(文献[106])。此外，认证的带宽使窄带物联网(NB-IoT) 不同于LoRa和Sigfox的解决方案实现高数据吞吐量，同时帮助减少在窄带物联网(NB-IoT)网络干扰的发生，窄带物联网(NB-IoT)设备可以支持大约20 - 23 dBm的传输功率。此外，通过采用电池省电技术包括省电方案和eDRX以实现节能，窄带物联网(NB-IoT)设备的电池寿命可以延长到10年以上。利用省电方案有助于优化功耗，允许传感器设备在不使用时进入睡眠模式，而不连续接受方案(eDRX)被用于延长系统空闲模式的睡眠周期。 ​ 可以使用三种运行模式部署NB-IoT，包括保护带、独立带和内带。保护带模式的运行，使NB-IoT使用现有的LTE运营商的带宽，而独立带使NB-IoT使用超过180KHz的带宽，内带允许NB-IoT在LTE物理资源块(PRB)内运行。需要强调的是，NB-IoT在计算上是高效的，因为它需要少量的微控制器模块资源，如处理器和内存。NB-IoT采用不同的第三代合作伙伴计划(3GPP) S3应用程序和传输层的安全技术。安全方案支持设备标识、身份机密性、数据完整性和身份验证。类似地，当考虑在WBAN中使用NB-IoT技术时，可以使用可选的加密安全机制来进一步保护患者的健康数据不被窃听。 ​ 如图11所示，用于WBAN的NB-IoT架构由NB-IoT医学传感器设备由基站(BS)，一个互联网云平台，不同的WBAN应用场景和远程医疗中心组成。医疗传感器设备将健康数据传输到NB-IoT蜂窝BS，然后BS将健康数据传输到互联网云平台，健康数据将被转发到远程医疗中心。NB-IoT医疗传感器设备通过一个进化的窄带节点 (eNB)连接到互联网云，因为它们安装在现有的蜂窝基础设施技术上，不需要网关连接到互联网云平台。此外，需要指出的是，将医用传感器设备与NB-IoT相结合需要结合WBAN的商业化NB-IoT电路解决方案，以及SIM卡和天线等核心元件结合在一起。考虑到NB-IoT技术的能力，该技术承诺在HCM中推进下一代WBAN，以满足关键的WBAN服务质量需求，包括高能效、远程通信、支持多个传感器设备的能力以及高数据可靠性支持。 1) 低功耗广域网技术总结 因为WBANs健康数据本质上是至关重要的,需要很少或根本没有时延通信,因此,LPWAN解决方案提出了可能的解决方案,是明显的,他们有能力扮演重要的角色在WBAN系统中,特别是在健康问题上数据传输的可靠性、功率效率,和长途远程医疗中心无缝覆盖。此外，不像其他通信解决方案，如ZigBee、蓝牙和传统蜂窝网络，基于LPWAN的传感器设备的电池寿命根据文献[105]中WBAN的用例可以使用大约5年，这对于WBAN系统来说是非常合理的。在通信距方面，LPWAN解决方案通信范围为5到 50公里。为了满足关键的WBAN的需求，必须指出每一个LPWAN技术有其自身的优点和缺点，例如，NB-IoT可以提供更多的带宽，LoRa可能更节能。这表明NBIoT具有比LoRa更好的数据处理能力。 为了便于比较，表六总结了可用于WBAN系统的不同的LPWAN解决方案。必须要强调的是选择通信技术于WBAN系统结合需要综合考虑几个因素，包括低电磁辐射，因为WBAN是以人体为中心的网络。同时为了满足WBAN服务质量需求，还应该考虑数据速率、部署成本、部署基础设施灵活性和健康数据交付可靠性。同样，为了实现有效的健康监测，WBAN是一种非常具有吸引力的和可靠的通信技术。例如，由于传统的中短程无线技术，ZigBee和蓝牙主要是用来收集健康数据发送到HCM邻近中心数据研究分析病人的健康状况然后实行必要的医疗举措,。在紧急情况下于医疗中心通信会成为一个问题,因为可用的和使用的大多是短程和中程WBANs通信技术，这些技术具有覆盖范围有限甚至可能不够节能。因此，采用新兴的LPWAN通信解决方案对于本地和远程HCM环境中的WBAN系统都是非常有益的。 Ⅶ.HCM中下一代WBAN的研究差距和建议 传统的HCM系统所面临的挑战使我们需要更先进、可靠、低成本和高效的医疗系统。为了解决与传统HCM系统相关的挑战，为WBAN解决方案研究提供了一个环境。遗憾的是，HCM中现有的WBAN解决方案受到几个问题的限制，如有限的能源资源、高部署成本、时延和可靠性问题。这一代WBAN系统的这些问题大部分与现有的通信标准有关。为了帮助WBAN实现对患者健康状况的有效、高效、可靠和低成本监测的承诺，目前学术界和业界都在进行研究工作。为了解决WBAN中的一些问题，无线通信技术能够在实现新策略方面扮演重要角色，这些新策略可用于改进HCM中的WBAN解决方案。有趣的是，通信系统的最新进展将为改善WBAN提供新的策略，并在下一代WBAN中以可靠和有效的方式为远程患者的健康监测和治疗提供支持。 然而,很明显从现有WBNAs解决方案,大多数采用短程和中程通信技术,而新兴的LPWAN解决方案的中能源效率、健康数据交付可靠性、低时延,以及远程通信,还可以研究。因此，本研究为开发LPWAN通信系统，HCM中实现下一代WBAN解决方案，以实现能源效率、远距离通信、低时延和健康数据交付可靠性提供了见解。随着新兴的LPWAN通信系统并入WBAN，特别是慢性疾病的早期发现和治疗疾病,如癌症、心血管疾病、帕金森和先天性心脏疾病,可以实现实时监控病人的生活与任何上述疾病包括其他疾病,从而帮助减少死亡率。此外，为实现理想中的WBAN系统，现重点提出以下建议。 1) 改进低功耗广域网的的电磁辐射 由于wban以人体为中心，人体中有不同的电活动，这些电活动在人体的运动、生长、思维和新陈代谢方面起着重要的作用，因此，使用了更高的电磁辐射的LPWAN的医疗传感器设备可以对人体组织包括关键器官产生破坏性的热效应。这些令人担忧的发展可能会扰乱身体功能，最终可能导致严重的健康问题，包括脑瘤、失眠、帕金森症和老年痴呆症。将使用WBAN解决方案监测的患者暴露在持续的电磁辐射下可能会进一步恶化此类患者的健康状况。因此，有必要进一步改善下一代WBAN系统的LPWAN解决方案的电磁辐射以使他们对患者的身体更友好。 2) 为WBAN系统研究高效的数据传输优化方案 开发高效的传输优化方案是WBAN系统的迫切需要。这些优化方案有巨大的需求是因为需要优化WBAN传感器设备的传输功率，因为更高的传输功率会对人体及其组织产生热效应，具有很大的破坏性影响。高效数据传输优化方案的发展不仅要关注的优化WBAN传感器设备的传输功率,还应全面满足规定的在WBAN系统中的传感器的电磁辐射的吸收。为了达到这个目标,一个马尔可夫决策过程(MDP)技术可能利用优化WBAN传感器设备在医疗数据通信的传输功率，来降低能源资源消耗,减少WBAN传感器设备发射机一边的电磁辐射的热效应，降低特定吸收率和射频能量以解决对人体及其组织其负面影响。这可以通过设置每个传感器设备的传输功率不能超过的特定吸收率的限制来实现，并且这种传输功率不应该损害传感器设备可实现的吞吐量性能。因为在传输功率和传感器设备可达到的吞吐量之间有一个权衡，这是因为高传输功率会增加吞吐量，然后才应该寻求最优的传输方案来成功传输健康数据。 3) 考虑用于HCM中WBAN系统传感器的便携性 目前，WBAN系统中传统的传感器设备被认为是宏观传感器设备，其尺寸仍然明显偏大。由于WBAN是以人体为中心的，而且他们使用的宏观传感器设备可以嵌入到病人的身体中，由于目前医疗宏观传感器设备的巨大尺寸，可能会对病人的身体造成潜在的伤害。为了防止病人的身体受到任何形式的伤害，纳米尺寸的医疗传感器设备在WBAN是非常理想的。在WBAN系统中与传统的宏观医疗传感设备相比，在高分辨率传感性能方面，纳米级的医疗传感器设备更有优势。 4) WBAN解决方案中的开发业务循环技术 业务循环技术是一种节能机制，可以在wban中用于优化操作，以管理医疗传感器设备如何消耗电池电量，并根据睡眠/清醒的操作模式最小化其能耗。这种优化技术的适宜性与WBAN系统在要监控的健康状况以及所需的交通模式类型方面的操作要求有很强的关系。 5)考虑节能的调制方案 由于WBAN是电池驱动的系统，因此考虑采用高效节能的调制方案来节省物理层(PHY)和媒体访问接入层(MAC)的能量是非常关键的，因为WBAN医学传感器设备中的电池容量有限。考虑功率感知，即节能调制方案将有助于以低功耗实现数据通信的最优性。通过在WBANs中使用节能调制方案，网络的能效将被提高。 1) 使用能量收集技术 由于电池容量的限制，WBAN传感器设备的节能是WBAN设计中一个至关重要的问题，目的是实现网络功能，避免令人失望的操作和结果。WBAN医疗传感器装置电池的电力可以补充，因此可以探索适当的能量收集技术，以便可能加以利用，这种考虑将加强每个医疗传感器装置的功能。但是能量收集技术仍处于发展阶段，这为进一步研究它们的成熟提供了背景。 2) 开发WBAN系统的功率感知协议 MAC协议主要用于控制网络传感器设备的通信信道分配。因此，设计和实现低能耗WBAN系统的MAC协议是实现节能网络的理想选择。此外，必须指出的是，以一种节能的方式将可植入传感器装置安装到患者体内是目前一项艰巨的任务。由于植入式医疗传感器装置安装在病人的皮肤下，而不是安装在病人身上的可穿戴式医疗传感器装置，病人体内进行的电子活动的可能会阻碍信号的传播。此外，WBAN系统流量需要复杂的低能耗方法来保证安全、可持续、可靠的网络运行，但目前可用的MAC协议包括Wise-MAC、SMAC、码分多址(CDMA)、时分多址(TMAC)和频分多址(FDMA)还没有完全为WBAN系统的流量提供足够的健康数据通信需求的解决方案，因此开发节能的MAC协议仍然是一个需要更多关注的开放研究问题。 3) 改进低功耗广域网系统的通信时延 从这项研究中可以明显看出，目前的技术水平由于随机访问资源的限制，LPWAN解决方案仍然被认为是时延容忍的。为了有效地利用WBAN医学系统中时延不相容的LPWAN解决方案，该解决方案可以利用低复杂度稀疏码多址(SCMA)译码方案和多用户检测策略来提高新出现的LPWAN解决方案的时延性能。 4) 提高WBAN系统健康数据可靠性 值得注意的是，WBAN系统的可靠性与健康数据传输时时延相关，因为低时延会使得健康数据传输的高可靠性。因此，为了保证下一代WBAN系统的可靠性，通信技术，例如，LPWAN解决方案为医疗视频流、医疗数据通信、医疗视频会议和医疗远程会议提供低数据传输时延是迫切需要的。因此，LPWAN通信系统应该能够支持快速传输健康数据和医疗视频流，以便外科医生能够在机器人手术刀的帮助下无缝地进行手术。 10)开发高效能源资源分配方案 在LPWAN解决方案中，应探索不同的节能资源配置方案，挖掘潜在的开发潜力，优化稀缺的网络资源，包括能源、通信信道时隙和频谱。同样值得注意的是，在这些网络资源的分配过程中，为了提高HCM部署的WBAN的能效，资源的分配应该是公平的。 11)为HCM中WBAN使用节能优化技术提高WBAN能源效率 ​ 优化技术是优化网络资源的有力手段，因此，为了开发节能的WBAN系统，可以对有限的网络资源，如能源资源进行优化利用。这可以通过为HCM中WBAN引入优化算法来实现，如自然启发算法，例如遗传算法，粒子群算法和蚁群优化算法，启发式算法，以及经典的优化方法如拉格朗日方法等。 12)为WBAN系统开发实时通信网络 ​ 重要的是要避免或尽量减少健康数据延迟由于健康数据对远程HCM患者的整体健康和福祉至关重要，因此，本研究中回顾的LPWAN技术可以得到改进，从而实现低延迟和高数据速率。因此，可以考虑在WBAN系统中结合低时延机制以及支持很少或不支持时延的策略，以实现实时健康数据联网。 Ⅷ结语 为了使WBAN解决方案能够实现可持续远程HCM的愿望，解决当前HCM应用程序的WBAN解决方案的缺陷是很重要的。这些缺点包括能源效率问题和向远程医疗中心提供医疗数据的可靠性，这可能是由于短程通信技术通常与WBAN系统相结合造成的。因此，这项研究工作做了一个关于中短程通信网络技术,传统蜂窝网络技术以及新兴的LPWAN技术的调查，包括IEEE 802.15.6标准，ZigBee、蓝牙、Wi-Fi和低功耗Wi-Fi，回顾了包括基于专用和非专用通信系统的LPWAN技术，以确定它们是否适合WBAN。给出了适合于提高下一代WBAN系统效率的建议。值得注意的是,根据本研究中所讨论的LPWAN解决方案低能耗、低延迟、通信覆盖范围宽,和健康数据传输可靠性的独特特性，LPWAN解决方案可以被认为是在远程HCM中WBAN系统实现高效的数据通信的合适方案。但是，要保证WBAN系统中LPWAN解决方案的丰富成果，一些关键问题，包括开发节能的通信协议以及改善数据时延和数据传输速率都需要解决。上述问题将作为开放性研究问题进行讨论。]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>WBAN</tag>
        <tag>5G</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[联邦学习、边缘计算、WBAN结合的一些讨论]]></title>
    <url>%2F2020%2F05%2F15%2F%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E3%80%81%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E3%80%81WBAN%E7%BB%93%E5%90%88%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%A8%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[想不出idea… 无线体域网：WBAN能被描述为由几个智能和小型（大型）传感器设备组成的无线通信系统。这些传感器能植入人体或者可穿戴在人身上持续或间断性的监测重要的身体信号如心电图（ECG）、心率、血压、脉搏、温度而不影响他们正常的日常活动。这些传感器测量的健康数据被发送到远程医疗服务机构，在那里这些数据能被分析用于评估病人的健康状况以便于做出决策。 期刊：通信学报 截止日期：2020.8.15 征文范围： 6G无线网络边缘智能化，包括边缘计算、缓存等 智能6G网络安全和用户隐私保护，包括智能网络带来的新的安全隐患、基于分布式/联邦学习的学习策略等。 问题：用联邦学习解决边缘计算场景下多个无线体域网数据处理的安全问题 用联邦学习来解决边缘计算场景下无线体域网数据处理安全问题的一些想法： idea 参考文献 结合联邦学习和边缘计算来优化卸载和降低能耗、时延 用联邦学习来学习用户的服务偏好和服务类型，优化WBAN边缘云的服务放置 Privacy-aware service placement for mobile edge computing via fe derated learning inter-wban和intra-wban与联邦学习的结合(主要考虑inter-wban)]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>联邦学习</tag>
        <tag>边缘计算</tag>
        <tag>WBAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习笔记-分布式机器学习]]></title>
    <url>%2F2020%2F03%2F13%2F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[分布式机器学习算法和分布式式机器学习系统 基本概述（1）分布式机器学习算法具有的良好属性[1]收敛性[2]加速比：相比对应的单机优化算法，达到同样的模型精度所需要的时间明显降低，甚至随着工作节点数的增加，需要的时间以线性的阶数减少。[3]泛化性（2）通信量下界：为了达到更好的加速比，需要人为减少工作节点之间的通信量。但是想要算法收敛到最小值，一般需要满足最小的通信量，称为通信量下界。（3）在非凸任务中需要注意的点：对非凸任务（比如深度学习），与算法相关的泛化性能分析非常重要，因为不同算法在模型空间中的优化路径不同，停留的局部凸子域也不同，从某种意义上来说，起到了正则化的作用。因此，对于这类机器学习任务，在进行误差分解的时候，优化误差和估计误差应该联合在一起考虑。 收敛性分析（2）收敛性分析中的几个结论[1]优化的难易程度对分布式学习算法的收敛速率影响很大；[2]所选用的优化算法对收敛速率也有显著影响；[3]即使针对同一个优化问题，在选定使用某一个优化算法后，分布式并行框架的各个环节也会对收敛速率产生影响。 加速比分析【注】：该定义表达的是，在相同的时间T内，并行算法所达到的精度相比于串行算法改进的比例。该数值越大，加速效果就会越好。（2）并行算法的加速比影响因素[1] 因素一：收敛速率；[2] 因素二：通信 / 计算的时间比。【注】：如果随着并行程度K的增大，收敛精度相应地以线性速率变好，并且通信时间与计算时间相比可以忽略，那么就说并行算法具有线性的精度加速比。最小通信量定义为使上式中分布式优化达到指定精度时所需要的最少通信次数。每次通信中，工作节点传输的信息量与模型的维度呈线性关系。【注】：除了对单词通信信息量有要求外，最小通信量还依赖于分布式机器学习问题的其他属性，如凸性和光滑性、局部目标关联程度、局部更新方式等。目标函数的凸性和光滑性的改善、存在局部目标关联对降低通信量是有好处的。 泛化分析（1）简介：分布式机器学习算法利用了更多计算资源，从而加快了优化的速度。优化和泛化的互动决定了最后算法的表现。因此需要进行泛化分析，以了解这一作用情况。（2）优化对泛化的局限性：并行算法只能带来优化上的改进，优化只是泛化误差的一部分，改进到一定程度，估计误差会在整个误差中占主导。此时，优化算法再进行下去的意义就不是很大了。（3）非凸问题的优化中考虑泛化：在非凸问题中（尤其是深度学习），当算法不同时，落入的模型空间的区域就不同，对应着不同的泛化能力。在非凸优化算法的设计中应更好地考虑泛化，能够提升最终所学模型的性能。（4）各种随机算法达到最优误差所需的计算复杂度主要对比梯度下降法、牛顿法、随机梯度下降法和随机牛顿法。（5）随机优化算法的最优优化轮数主要对比梯度下降法、随机梯度下降法和随机方差减小梯度法。 分布式机器学习算法（1）简介：根据分布式机器学习框架中的各个组成部分，可以设计出不同的分布式机器学习算法。不同的算法可能对应于不同的数据与模型，使用不同的优化方法，采用不同的通信机制，以及不同的数据与模型聚合方式。（2）常见的分布式机器学习算法及其特点 同步算法（1）简介：其最大特点是在通信过程中会有一个显式的全局同步状态，我们称之为同步屏障。当工作节点运行到同步屏障时，就会进入等待状态，直到其他工作节点均运行到同步屏障为止。接下来不同工作节点的信息就会被聚合并分发回来，然后各个工作节点据此开展下一轮的模型训练。就这样，一次同步接着下一次同步，周而复始的进行下去。（2）同步SGD方法：是将随机梯度下降（SGD）算法套用到同步BSP框架中，所产生的最基本的基于数据并行的算法（也称为SSGD）。SSGD算法实际上是将各个工作节点依据本地训练数据所得到的梯度叠加起来，这个过程其实等价于一个批量大小增大K倍的单机SGD算法。SSGD算法在每一个小批量更新之后都有一个同步过程，因此通信的频率较高，如果每个小批量训练的计算量很大，而模型规模又不大（比如深度神经网络中的卷积神经网络），则同步通信带来的网络传输开销相对较小，可以获得理想的加速性能。但是，如果小批量中样本较少（从而计算量不大），而模型规模又比较大，则可能需要花费数倍于计算事件的代价来进行通信，结果是多机并行运算可能无法得到理想的加速。解决这个问题，一般有两种途径，一是在通信环节中加入时空滤波，二是扩大本地学习的批量大小。（3）MA方法：由于SSGD的通信比较频繁，在通信与计算占比较大时，难以取得理想的加速效果。MA（模型平均）算法是一种通信频率比较低的同步算法。在MA算法中，每个工作节点会根据本地数据对本地模型进行多轮的更新迭代，直到本地模型收敛或者本地迭代轮数超过一个预设的阈值，再进行一次全局的模型平均，并以此均值作为最新的全局模型继续训练。MA算法按照通信间隔的不同，可以分为两种情况，一是只在所有工作节点完成本地训练之后，做一次模型平均；二是在本地完成一定轮数的迭代后，就做一次模型平均，然后用这次平均的模型结果作为接下来的训练起点，继续进行迭代，循环往复。（4）BMUF方法：在MA算法中，不论梯度的本地更新流程是什么策略，在聚合平均时都只是将来自各个工作节点的模型进行简单平均。在单机优化算法中，常常会加入冲量以有效地利用历史更新信息来减少随机梯度下降中梯度噪声的影响。BMUF（块模型更新过滤）算法就是在MA算法中，对每次全局模型的更新引入冲量，即基于数据块的冲量思想对MA进行了改进。BMUF算法实际上是利用了全局的冲量，使得历史上本地迭代对全局模型的更新的影响有一定的延续性，从而达到加速模型优化进程的作用。（5）ADMM方法：在MA算法中，来自各个工作节点的模型被简单地进行平均。ADMM算法则采用了一种更优雅的方式，其通过求解一个全局一致性的优化问题进行模型聚合。该方法利用全局共享的对偶变量，将各个工作节点的模型有效地联系起来。（6）EASGD方法：无论本地模型使用什么方法更新，前几种算法都会在某个时刻聚合出一个全局模型，并且用其替代本地模型，但是这种处理方法像对于深度学习这种有很多个局部极小值点的优化问题而言，不一定是最优选择。因此，可以采用非完全一致的分布式机器学习算法，如EASGD（弹性平均SGD）算法。该算法的出发点和ADMM算法类似，但是并不强求各个工作节点继承全局模型。其分布式优化的目标有两个，一是使得各个工作节点本身的损失函数得到最小化；二是希望各个工作节点上的本地模型和全局模型之间的差异比较小。EASGD方法相比于SSGD或MA，在本地模型和服务器更新时能同时兼顾全局一致性和本地模型的独立性。具体而言，就是两个方面，第一个方面是对本地模型进行更新时，在按照本地模型计算梯度的同时，也力求用全局模型来约束本地模型不要偏离的太远；第二个方面是在对全局模型进行更新时，并不是直接把各个本地模型的平均值作为下一轮的全局模型，而是部分保留了历史上全局模型的参数信息。总而言之，这种弹性更新的方法，既可以保留工作节点各自的探索方向，同时也不会让它们彼此相差太远。实验表明，EASGD在精度和稳定性方面都有较好的表现。（7）一些总结[1]SSGD有着与单机算法类似的理论性质，但是在实践中多少有些限制，比如小批量不能太大，要注意通信和计算的比例平衡等。MA允许工作节点在本地进行更多轮次的迭代，因而更高效，但是MA通常会带来精度损失，实践中需要仔细调整参数设置，或者通过增加数据粒度块的冲量（即采用BMUF方法）来获得更好的效果。ADMM算法使用全局一致性优化来决定模型聚合，在本地更新时也引入了一些约束条件，通常会带来测试精度增益。EASGD方法则不强求全局模型的一致性，而是为每个工作节点保持独立探索的能力；[2]同步算法的共性是，所有工作节点都会以一定的频率进行同步。因此，当工作节点的计算性能存在差异，或者某些工作节点无法正常完成工作（比如死机）的时候，分布式系统的整体运行效率不好，甚至无法完成训练任务，因此可以采用异步算法进行改善。 异步算法（1）简介：在异步的通信模式下，各个工作节点不再需要互相等待，而是以一个或多个全局服务器作为中介，实现对全局模型的更新和读取。这样可以显著减少通信时间，从而获得更好的多机扩展性。（2）异步SGD方法：异步SGD算法（ASGD）是最基础的异步算法。ASGD的参数梯度计算发生在工作节点，而模型的更新则发生在参数服务器端。当参数服务器接收到来自某个工作节点的参数梯度时，就直接将其加到全局模型上，而无需等待其他工作节点的梯度信息。ASGD避免了同步开销，但是会给模型的更新带来一些延迟。而延迟会使得ASGD与SGD在参数更新规则上存在偏差，可能导致模型在某些特定的更新点上存在严重抖动，甚至优化出错，无法收敛，因此还需要对算法进行一定程度的改进。（3）Hogwid!方法：由于异步并行算法既可以在多机集群上展开，也可以在多核系统下通过多线程开展。所以，当把ASGD算法应用到多线程的环境中时，因为不再有参数服务器这个角色，算法的细节会发生一些变化。特别地，因为全局模型存储在共享内存中，所以当异步的模型更新发生时，需要讨论是否将内存加锁，以保证模型写入的一致性。Hogwild！算法为了提高训练过程中的数据吞吐量，选择了无锁的全局模型访问。当对模型访问稀疏性做一定的限定后，访问冲突实际上是很有限的，这样Hogwild！算法就可以具有收敛的性质。（4）Cyclades方法：是Hogwild！算法的改进算法。其针对Hogwild！算法在实际使用中的一些不足之处做了改善。Cyclades算法的核心思想是，尽量从算法设计的角度减少不同线程之间的冲突，如果各个线程的运算本身就没有多少冲突，则它们自然可以安全地异步执行，从而不用担心整体的收敛性。（5）带延迟处理的异步方法[1]AdaDelay算法：其基本思想是惩罚待延迟的梯度。将模型更新的学习率（步长）与延迟联系起来的算法。这种方法可以对有延迟的梯度进行一定程度的惩罚（因为这些梯度有延迟，所以有必要降低对它们的信任度，即它们与当前的全局模型失配）。[2]带有延迟补偿的ASGD算法（DC-ASGD）：是针对AdaDelay算法的一种改进算法。（6）一些总结[1]异步算法将整个分布式机器学习系统从全局同步的局限性中解放出来，允许速度比较快的工作节点更好地发挥自己的效能；[2]异步并行也是一把双刃剑，一方面可以带来更高的吞吐率，但另一方面也带来了延迟更新的问题，使得整体优化过程中的收敛速率受到影响；[3]若可以在算法层面对于延迟进行合理的处理，速度的优势将会成为主导因素。因此，异步并行算法可以在大规模的分布式环境中具有用武之地。 同步和异步的融合（1）简介：同步和异步算法有各自的优缺点和适用场景，如果可以把它们结合起来应用，取长补短，或许可以达到更好的收敛速率与收敛精度的平衡。例如，对于机器数目很多、本地工作节点负载不均衡的集群，可以考虑按照工作节点的运算速度和网络连接情况进行聚类分组，将性能相近的节点分为一组，由于组内的工作节点性能相近，在组内训练时，可以采用同步并行的方式进行训练。对于组间来说，由于各组间运行速度差异大，更合适采用异步并行的方式进行训练。这种混合并行的方式既不会让运行速度慢的本地工作节点过度拖累全局训练速度，也不会引入过大的异步延迟从而影响收敛精度。下图是一个能完成这种混合并行的原型系统框架：（2）常见融合方法：混合SGD。（3）混合并行算法的核心挑战：如何找到一种合理的工作节点分组方式。 模型并行算法（1）简介：模型并行通常用来解决大模型的挑战。当模型太大以至于单机内存不能完全存储时，需要将模型划分并存储在不同机器上，并利用这些机器协同完成大模型的训练。基于模型的并行算法从直观上可以理解成把多个工作节点虚拟化成为一个巨大的计算节点，在计算过程中模型划分越多，交互和通信也将越多，并且任何一个工作节点出现问题，整个计算都会受到影响，因此鲁棒性欠佳。（2）DistBelief方法：主要针对大型神经网络。是既采用数据并行，又使用模型并行的算法。该算法主要针对系统，由多个模型副本和参数服务器组成。在算法中，首先利用参数服务器进行数据并行，对每个模型副本使用ASGD算法进行异步训练，然后每个副本又由一组模型并行的节点来完成训练。 常用的分布式机器学习算法中的一些结论[1]同步算法的学习流程比较可控，但需要考虑如何有效缩小同步带来的通信代价（包括传输和等待）；[2]异步方法在运行过程中不存在等待问题，但需考虑异步并行带来的延迟；[3]同步和异步方法各有利弊，并且很大程度上受到硬件资源情况的影响。 分布式机器学习系统Ⅰ.基本概述（1）简介：分布式机器学习不仅关乎算法和理论，更重要的是应用与实践。为了最终利用分布式集群解决大规模机器学习问题，需将分布式机器学习算法实现为分布式机器学习系统。面对一个实际问题，可为其选择一个合适的算法，并针对其特点设计开发一套系统加以实现。这种直接实现可对算法特性做直接优化，从而最大限度利用硬件资源以达到最优效率。（2）三种主流的分布式机器学习架构[1] 基于IMR（迭代式MapReduce）的架构：主要适用场景是“同步 + 数据并行”。它从大数据处理平台演化而来，运行逻辑比较简单，且有很多成熟的实际系统可以使用。[2] 基于参数服务器的架构：可以同时支持同步和异步的并行算法。它的接口简单明了、逻辑清晰，可以很方便、灵活地与单机算法相结合。[3] 基于数据流的架构：由一个有向无环图定义，可以灵活地描述复杂的并行模式，比如数据并行、模型并行、混合并行等。TensorFlow是这类分布式机器学习系统的代表。（3）分布式机器学习架构概况 Ⅱ.基于IMR的分布式机器学习系统（1）简介：MapReduce的模式过于简单，IMR是对传统MapReduce系统的一种改进。（2）传统MapReduce模式的弱点[1] 弱点一：Map + Reduce的抽象过于简单。复杂计算逻辑常需要用很长的Map + Reduce的序列来描述。而机器学习过程通常需要对训练数据进行多轮迭代处理，用MapReduce序列来完成效率愈发低下；[2] 弱点二：MapReduce对于中间数据处理的灵活性和效率比较低。由于MapReduce通常使用HDFS这类硬盘存储作为所有数据（包括中间数据）的存储媒介，因此对于有大量中间数据生成的迭代式机器学习任务而言效率低下。（3）Spark与传统MapReduce系统的对比（4）Spark Mllib[1] 简介：Spark MLlib封装了一系列常用的机器学习算法，并利用Spark本身的分布式优势为这些算法提供了分布式的解决方案。[2] 在Spark中存在的典型机器学习算法 Ⅲ.基于参数服务器的分布式机器学习系统（1）简介：参数服务器的设计初衷是为了解决IMR分布式机器学习系统中存在的局限性，例如同步方法效率和鲁棒性欠佳等。参数服务器最早出现在大规模主题模型系统，以及大规模深度神经网络系统中，这些系统有着不俗的性能，也验证了参数服务器架构的优势。后来，人们把参数服务器实现成了通用系统，用于支持更多的机器学习任务。（3）对参数进行分布式存储的主要原因[1] 原因一：通过使用多台实体服务器来分担大规模模型参数的存储和计算，从而更快地响应来自客户端的参数更新和访问请求；[2] 原因二：多个实体服务器可以减少网络拥堵，具有更好的可扩展性；[3] 原因三：可以利用多个实体服务器实现系统容错。（4）工作节点[1] 作用：负责本地模型训练，并利用参数服务器提供的API对全局模型进行获取和更新。[2] 能访问的API类型：从参数服务器获取模型参数，或更新处于参数服务器上的模型参数；[3] 常见操作操作一：当工作节点有获取请求时，参数服务器API按照事先约定好的数据划分和存储协议，将请求转发给相应的实体服务器，然后等待来自这些实体服务器的回应消息，并重新整理成用户需要的格式后返回给用户。操作二：当工作结点有了更新请求时，参数服务器API将要更新的参数和对应的数值信息按照数据划分和存储协议进行拆分，再分别发送给相应的实体服务器。实体服务器接收到请求后依据相应的聚合算法，更新全局模型。 Ⅳ.基于数据流的分布式机器学习系统（1）简介：基于数据流的分布式机器学习系统借鉴了基于DAG的大数据处理系统的灵活性，将计算任务描述成一个有向无环的数据流图，图中的节点表示对数据的操作（计算或者是通信），图中的边表示操作的依赖关系。系统自动提供对数据流图的分布式执行，因此用户只需要关心如何设计出适当的数据流图来表示想要执行的算法逻辑。（2）TensorFlow中的数据流图（3）TensorFlow数据流系统[1] 关于TensorFlow：是在2015年11月正式对外开源的一个机器学习系统，可以对深度学习模型的训练提供很好的支持。[2] 存在于TensorFlow中的两种数据对象：张量（Tensor）和变量（Variable）。模型参数在机器学习的训练过程中不断被更新，因此属于变量。TensorFlow运算过程中所有需要存储下来的变量合在一起被称为图的状态。[3] 包含在TensorFlow中的算子[4] 几个TensorFlow执行过程中起作用的重要角色角色一：Client（客户端）。其用来启动任务，通过Session接口与Master取得联系，并告知整个系统要运行的任务内容以及所需的资源状况；角色二：Master（主控制结点）。其负责分发任务、调度资源，并且把计算结果返回给客户端。Master是一个执行引擎，拿到数据流图的信息后，会结合数据流图和计算资源的情况，将具体的计算分配给工作节点来完成；角色三：Worker（工作节点）。其负责管理和使用计算设备，具体而言就是机器中的GPU和CPU等设备。Master将计算算子发送给Worker，然后Worker负责用其管理的设备来执行这些算子，并最终返回结果给Master。（4）TensorFlow中的跨设备传输机制]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>分布式机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch-Day05]]></title>
    <url>%2F2020%2F02%2F19%2FPytorch-Day05%2F</url>
    <content type="text"><![CDATA[卷积神经网络基础；LeNet；卷积神经网络进阶 卷积神经网络基础图1 二维互相关运算 卷积层得名于卷积运算，但卷积层中用到的并非卷积运算而是互相关运算。我们将核数组上下翻转、左右翻转，再与输入数组做互相关运算，这一过程就是卷积运算。由于卷积层的核数组是可学习的，所以使用互相关运算与使用卷积运算并无本质区别。 感受野以图1为例，输入中阴影部分的四个元素是输出中阴影部分元素的感受野。我们将图中形状为2x2的输出记为Y，将Y与另一个形状为2x2的核数组做互相关运算，输出单个元素z。那么，z在Y上的感受野包括的全部四个元素，在输入上的感受野包括其中全部9个元素。可见，我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。 输入和输出还可以是多通道（维）的。 卷积层与全连接层的对比 卷积层的简洁实现：我们使用Pytorch中的nn.Conv2d类来实现二维卷积层，主要关注以下几个构造函数参数： in_channels (python:int) – Number of channels in the input imag out_channels (python:int) – Number of channels produced by the convolution kernel_size (python:int or tuple) – Size of the convolving kernel stride (python:int or tuple, optional) – Stride of the convolution. Default: 1 padding (python:int or tuple, optional) – Zero-padding added to both sides of the input. Default: 0 bias (bool, optional) – If True, adds a learnable bias to the output. Default: True 池化池化层主要用于缓解卷积层对位置的过度敏感性。池化层直接对窗口内的元素求最大值或平均值，并没有模型参数参与计算.我们使用Pytorch中的nn.MaxPool2d实现最大池化层，使用nn.AvgPool2d实现平均池化层 LeNetLeNet分为卷积层块和全连接层块两个部分，90%以上的参数集中在全连接层，卷积层块中交替使用卷积层和池化层在连接卷积层和全连接层是，需要做一次展平操作。卷积神经网络通过使用滑动窗口在输入的不同位置重复计算，减小参数数量在通过卷积层或池化层后，输出的高和宽可能减小，为了尽可能保留输入的特征，我们可以增加通道数 卷积神经网络进阶LeNet: 在大的真实数据集上的表现并不尽如⼈意。 神经网络计算复杂。 还没有⼤量深⼊研究参数初始化和⾮凸优化算法等诸多领域。 机器学习的特征提取:手工定义的特征提取函数神经网络的特征提取：通过学习得到数据的多级表征，并逐级表⽰越来越抽象的概念或模式。 神经网络发展的限制:数据、硬件 AlexNet(深度卷积神经网络)首次证明了学习到的特征可以超越手工设计的特征，从而一举打破计算机视觉研究的前状特征： 8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。 将sigmoid激活函数改成了更加简单的ReLU激活函数。 用Dropout来控制全连接层的模型复杂度。 引入数据增强，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。 VGG（使用重复元素的网络）（图中间有一处错误，应为接上一个步幅为2、窗口形状为2*2的最大池化层） NIN（网络中的网络）LeNet、AlexNet和VGG：先以由卷积层构成的模块充分抽取 空间特征，再以由全连接层构成的模块来输出分类结果。NiN：串联多个由卷积层和“全连接”层构成的小⽹络来构建⼀个深层⽹络。⽤了输出通道数等于标签类别数的NiN块，然后使⽤全局平均池化层对每个通道中所有元素求平均并直接⽤于分类。1×1卷积核作用1.放缩通道数：通过控制卷积核的数量达到通道数的放缩。2.增加非线性。1×1卷积核的卷积过程相当于全连接层的计算过程，并且还加入了非线性激活函数，从而可以增加网络的非线性。3.计算参数少NiN重复使⽤由卷积层和代替全连接层的1×1卷积层构成的NiN块来构建深层⽹络。NiN去除了容易造成过拟合的全连接输出层，而是将其替换成输出通道数等于标签类别数 的NiN块和全局平均池化层。NiN的以上设计思想影响了后⾯⼀系列卷积神经⽹络的设计。 GoogLeNet 由Inception基础块组成。 nception块相当于⼀个有4条线路的⼦⽹络。它通过不同窗口形状的卷积层和最⼤池化层来并⾏抽取信息，并使⽤1×1卷积层减少通道数从而降低模型复杂度。 可以⾃定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。完整模型结构： 小结卷积层通过填充、步幅、输入通道数、输出通道数等调节输出形状卷积神经网络就是含卷积层的网络。 LeNet交替使用卷积层和最大池化层后接全连接层来进行图像分类。conv_2d 宽的计算公式: H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[0] - \text{dilation}[0] \times (\text{kernel_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloorpool_2d 宽的计算公式: H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[0] - \text{kernel_size}[0]}{\text{stride}[0]} + 1\right\rfloor]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>卷积神经网络</tag>
        <tag>LeNet</tag>
        <tag>AlexNet</tag>
        <tag>VGG</tag>
        <tag>NIN</tag>
        <tag>GoogLeNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch-Day04]]></title>
    <url>%2F2020%2F02%2F19%2FPytorch-Day04%2F</url>
    <content type="text"><![CDATA[机器翻译及相关技术；注意力机制与Seq2seq模型；Transformer 机器翻译用神经网络解决机器翻译问题称为神经机器翻译（NMT）数据预处理：将数据集清洗、转化为神经网络的输入minbatch分词：字符串—-单词组成的列表建立词典：单词组成的列表—-单词id组成的列表载入数据集，得到数据生成器 Encoder-Decoder输出序列的长度可能与源序列的长度不同。Sequence to Sequence模型训练：预测：具体结构： 集束搜索(Beam Search)集束搜索是维特比算法（选择整体分数最高的句子，搜索空间太大）的贪心形式，不能得到全局最优解 注意力机制和Seq2seq模型编码器和解码器本质上是两个RNN，其中编码器对输入序列进行分析编码成一个上下文向量(Context vector)，解码器利用这个编码器生成的向量根据具体任务来进行解码，得到一个新的序列。 编码器如下图就是一个典型的编码器，最终的上下文向量c可以是最后一个时间步的隐藏状态，也可以是编码器每个 解码器下图是两种比较常见的Seq2Seq模型的结构，两个图的左半部分都是上面所说的编码器部分，而右半部分就是解码器部分了。图一是直接将编码器的输出作为解码器的初始隐藏状态，然后直接进行解码。图二是直接将编码器得到的上下文向量输入到解码器的每个时间步中，并且每个时间步的上下文向量是相同，换句话说就是解码器每个时间步都使用了相同的上下文向量。这两种情况可能带来的问题是，当需要编码的句子太长的时候，由于上下文向量能够存储信息的容量是有限的，所以可能会导致信息的丢失，此外，解码器每个时间步的上下文向量都是一个相同的对输入序列的表征，对于上面两种问题，基于注意力机制的Seq2Seq模型给了很好的解决办法。 Attention机制的Seq2Seq在Encoder-Decoder结构中，Encoder把所有的输入序列都编码成一个统一的语义特征c再解码，因此， c中必须包含原始序列中的所有信息，它的长度就成了限制模型性能的瓶颈。如机器翻译问题，当要翻译的句子较长时，一个c可能存不下那么多信息，就会造成翻译精度的下降。 Attention机制通过在每个时间输入不同的c来解决这个问题，下图是带有Attention机制的Decoder： 每一个c会自动去选取与当前所要输出的y最合适的上下文信息。具体来说，我们用$a_{ij}$衡量Encoder中第j阶段的$h_j$和解码时第i阶段的相关性，最终Decoder中第i阶段的输入的上下文信息$c_i$就来自于所有$h_j$对$a_{ij}$的加权和。以机器翻译为例（将中文翻译成英文）：输入的序列是“我爱中国”，因此，Encoder中的h1、h2、h3、h4就可以分别看做是“我”、“爱”、“中”、“国”所代表的信息。在翻译成英语时，第一个上下文c1应该和“我”这个字最相关，因此对应的$a_{11}$就比较大，而相应的$a_{12}$、$a_{13}$、$a_{14}$就比较小。c2应该和“爱”最相关，因此对应的$a_{22}$就比较大。最后的c3和h3、h4最相关，因此 $a_{33}$、$a_{34}$的值就比较大。 至此，关于Attention模型，我们就只剩最后一个问题了，那就是：这些权重$a_{ij}$是怎么来的？ 事实上，$a_{ij}$同样是从模型中学出的，它实际和Decoder的第i-1阶段的隐状态、Encoder第j个阶段的隐状态有关。 同样还是拿上面的机器翻译举例，$a_{1j}$的计算（此时箭头就表示对h’和$h_j$同时做变换）： 基于注意力的Seq2Seq模型可以用下图表示： Transformer]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>机器翻译</tag>
        <tag>Seq2seq</tag>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch-Day03]]></title>
    <url>%2F2020%2F02%2F18%2FPytorch-Day03%2F</url>
    <content type="text"><![CDATA[过拟合、欠拟合及其解决方案；梯度消失、梯度爆炸；循环神经网络进阶 过拟合、欠拟合及其解决方案几个概念 训练误差（training error）：指在训练集上表现出来的误差 泛化误差（generalizetion error）：指在任意一个测试数据样本上表现出来的误差的期望，并常常通过测试数据集上的误差来近似 验证数据集：预留的在训练数据集和测试数据集以外的数据，用来进行模型选择 K折交叉验证：在K折交叉验证中，我们把原始训练数据集分割成K个不重合的子数据集，然后我们做K次模型训练和验证。每一次，我们使用一个子数据集验证模型，并使用其他K-1个子数据集来训练模型。最后，我们对这K次训练误差和验证误差分别求平均。 欠拟合：指训练误差和泛化误差都不能达到一个较低的水平。 过拟合：指训练误差达到一个较低的水平，而泛化误差依然较大。 产生欠拟合、过拟合的原因主要有两个因素：模型复杂度和序训练数据集大小 当训练数据集中样本数过少，特别是比模型参数数量（按元素计）更少时，过拟合更容易发生。 解决方案过拟合： L2范数正则化（regularization）即权重衰减：L2范数正则化在模型原损失函数基础上添加L2范数惩罚项，从而得到训练所需要最小化的函数。范数惩罚项指的是模型权重参数每个元素的平方和与一个正的常数的乘积。 丢弃法 解决欠拟合可以考虑增加模型复杂度 错题总结测试数据集不可用来调整模型参数，如果使用测试数据集调整模型参数，可能在测试数集上发生一定程度的过拟合现象，此时将不能用测试误差来近似泛化误差。 梯度消失、梯度爆炸模型训练实战步骤顺序： 获取数据集 数据预处理 模型设计 模型验证和模型调整（调参） 模型预测及提交 题目总结梯度消失会导致模型训练困难，对参数的优化步长过小，收效甚微，模型收敛十分缓慢梯度爆炸会导致模型训练困难，对参数的优化步长过大，难以收敛 循环神经网络进阶RNN： GRU RNN存在的问题：梯度较容易出现衰减或爆炸（BPTT） ⻔控循环神经⽹络：捕捉时间序列中时间步距离较⼤的依赖关系 重置⻔有助于捕捉时间序列⾥短期的依赖关系 更新⻔有助于捕捉时间序列⾥⻓期的依赖关系 9个权重和偏置参数，外加2个输出层参数和状态初始化（-1）参数初始化参数代码： num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size print(&#39;will use&#39;, device) def get_params(): def _one(shape): ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32) #正态分布 return torch.nn.Parameter(ts, requires_grad=True) def _three(): return (_one((num_inputs, num_hiddens)), _one((num_hiddens, num_hiddens)), torch.nn.Parameter(torch.zeros(num_hiddens, device=device, dtype=torch.float32), requires_grad=True)) W_xz, W_hz, b_z = _three() # 更新门参数 W_xr, W_hr, b_r = _three() # 重置门参数 W_xh, W_hh, b_h = _three() # 候选隐藏状态参数 # 输出层参数 W_hq = _one((num_hiddens, num_outputs)) b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, dtype=torch.float32), requires_grad=True) return nn.ParameterList([W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]) def init_gru_state(batch_size, num_hiddens, device): #隐藏状态初始化 return (torch.zeros((batch_size, num_hiddens), device=device), ) LSTM长短期记忆long short-term memory 遗忘门:控制上一时间步的记忆细胞 输入门:控制当前时间步的输入 输出门:控制从记忆细胞到隐藏状态 记忆细胞：⼀种特殊的隐藏状态的信息的流动 深层RNN实现时只需在传统RNN基础上改num_layers参数深层神经网络并非越深越好，层数的加深会导致模型的收敛变得困难，具体选用什么模型还是要看实践效果 双向RNN实现时在传统RNN基础上使bidirectional=True双向循环神经网络在文本任务里能做到同时考虑上下文和当前词之间的依赖前向和后向RNN连结的方式使前面的Ht和后面的Ht用contact进行连结]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>拟合</tag>
        <tag>梯度</tag>
        <tag>循环神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch-Day02]]></title>
    <url>%2F2020%2F02%2F13%2FPytorch-Day02%2F</url>
    <content type="text"><![CDATA[《动手学深度学习》Pytorch学习:文本预处理、语言模型、循环神经网络基础 文本预处理包括四个步骤： 读入文本 分词（将一个句子转换为若干个词（token）） 建立字典，将每个词映射到一个唯一的索引 将文本从词的序列转换为索引的序列，方便输入模型 可用现有工具进行分词，spaCy,NLTK 语言模型n元语法n元语法具有以下缺陷： 参数空间过大 数据稀疏 读取数据集with open(&#39;/home/kesci/input/jaychou_lyrics4703/jaychou_lyrics.txt&#39;) as f: corpus_chars = f.read() print(len(corpus_chars)) print(corpus_chars[: 40]) corpus_chars = corpus_chars.replace(&#39;\n&#39;, &#39; &#39;).replace(&#39;\r&#39;, &#39; &#39;) corpus_chars = corpus_chars[: 10000] 建立字符索引idx_to_char = list(set(corpus_chars)) # 去重，得到索引到字符的映射 char_to_idx = {char: i for i, char in enumerate(idx_to_char)} # 字符到索引的映射 vocab_size = len(char_to_idx) print(vocab_size) corpus_indices = [char_to_idx[char] for char in corpus_chars] # 将每个字符转化为索引，得到一个索引的序列 sample = corpus_indices[: 20] print(&#39;chars:&#39;, &#39;&#39;.join([idx_to_char[idx] for idx in sample])) print(&#39;indices:&#39;, sample) #定义load_data_jay_lyrices函数 def load_data_jay_lyrics(): with open(&#39;/home/kesci/input/jaychou_lyrics4703/jaychou_lyrics.txt&#39;) as f: corpus_chars = f.read() corpus_chars = corpus_chars.replace(&#39;\n&#39;, &#39; &#39;).replace(&#39;\r&#39;, &#39; &#39;) corpus_chars = corpus_chars[0:10000] idx_to_char = list(set(corpus_chars)) char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)]) vocab_size = len(char_to_idx) corpus_indices = [char_to_idx[char] for char in corpus_chars] return corpus_indices, char_to_idx, idx_to_char, vocab_size 时序数据的采样有以下两种方法： 随机采样每个样本是原始序列上任意截取的一段序列，相邻的两个随机小批量在原始序列上的位置不一定相毗邻。 相邻采样相邻的两个随机小批量在原始序列上的位置相毗邻。 语言模型做错的题 循环神经网络基础做错的题]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch-Day01]]></title>
    <url>%2F2020%2F02%2F12%2FPytorch-Day01%2F</url>
    <content type="text"><![CDATA[《动手学深度学习》Pytorch学习:线性回归、Softmax与分类模型、多层感知机 线性回归线性回归模型从零开始的实现# import packages and modules %matplotlib inline import torch from IPython import display from matplotlib import pyplot as plt import numpy as np import random # 生成数据集 # set input feature number num_inputs = 2 # set example number num_examples = 1000 # set true weight and bias in order to generate corresponded label true_w = [2, -3.4] true_b = 4.2 features = torch.randn(num_examples, num_inputs, dtype=torch.float32) labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float32) # 使用图像来展示生成数据 plt.scatter(features[:, 1].numpy(), labels.numpy(), 1); def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) random.shuffle(indices) # random read 10 samples for i in range(0, num_examples, batch_size): j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # the last time may be not enough for a whole batch yield features.index_select(0, j), labels.index_select(0, j) batch_size = 10 for X, y in data_iter(batch_size, features, labels): print(X, &#39;\n&#39;, y) break # 初始化模型参数 w = torch.tensor(np.random.normal(0, 0.01, (num_inputs, 1)), dtype=torch.float32) b = torch.zeros(1, dtype=torch.float32) w.requires_grad_(requires_grad=True) b.requires_grad_(requires_grad=True) # 定义模型 def linreg(X, w, b): return torch.mm(X, w) + b # 定义损失函数 def squared_loss(y_hat, y): return (y_hat - y.view(y_hat.size())) ** 2 / 2 # 定义优化函数 def sgd(params, lr, batch_size): for param in params: param.data -= lr * param.grad / batch_size # ues .data to operate param without gradient track # 训练 # super parameters init lr = 0.03 num_epochs = 5 net = linreg loss = squared_loss # training for epoch in range(num_epochs): # training repeats num_epochs times # in each epoch, all the samples in dataset will be used once # X is the feature and y is the label of a batch sample for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y).sum() # calculate the gradient of batch sample loss l.backward() # using small batch random gradient descent to iter model parameters sgd([w, b], lr, batch_size) # reset parameter gradient w.grad.data.zero_() b.grad.data.zero_() train_l = loss(net(features, w, b), labels) print(&#39;epoch %d, loss %f&#39; % (epoch + 1, train_l.mean().item())) 使用pytorch的简洁实现import torch from torch import nn import numpy as np torch.manual_seed(1) print(torch.__version__) torch.set_default_tensor_type(&#39;torch.FloatTensor&#39;) # 生成数据集 num_inputs = 2 num_examples = 1000 true_w = [2, -3.4] true_b = 4.2 features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float) labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float) # 读取数据集 import torch.utils.data as Data batch_size = 10 # combine featues and labels of dataset dataset = Data.TensorDataset(features, labels) # put dataset into DataLoader data_iter = Data.DataLoader( dataset=dataset, # torch TensorDataset format batch_size=batch_size, # mini batch size shuffle=True, # whether shuffle the data or not num_workers=2, # read data in multithreading ) for X, y in data_iter: print(X, &#39;\n&#39;, y) break # 定义模型 class LinearNet(nn.Module): def __init__(self, n_feature): super(LinearNet, self).__init__() # call father function to init self.linear = nn.Linear(n_feature, 1) # function prototype: `torch.nn.Linear(in_features, out_features, bias=True)` def forward(self, x): y = self.linear(x) return y net = LinearNet(num_inputs) print(net) # ways to init a multilayer network # method one net = nn.Sequential( nn.Linear(num_inputs, 1) # other layers can be added here ) # method two net = nn.Sequential() net.add_module(&#39;linear&#39;, nn.Linear(num_inputs, 1)) # net.add_module ...... # method three from collections import OrderedDict net = nn.Sequential(OrderedDict([ (&#39;linear&#39;, nn.Linear(num_inputs, 1)) # ...... ])) print(net) print(net[0]) # 初始化模型参数 from torch.nn import init init.normal_(net[0].weight, mean=0.0, std=0.01) init.constant_(net[0].bias, val=0.0) # or you can use `net[0].bias.data.fill_(0)` to modify it directly for param in net.parameters(): print(param) # 定义损失函数 loss = nn.MSELoss() # nn built-in squared loss function # function prototype: `torch.nn.MSELoss(size_average=None, reduce=None, reduction=&#39;mean&#39;)` # 定义优化函数 import torch.optim as optim optimizer = optim.SGD(net.parameters(), lr=0.03) # built-in random gradient descent function print(optimizer) # function prototype: `torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)` # 训练 num_epochs = 3 for epoch in range(1, num_epochs + 1): for X, y in data_iter: output = net(X) l = loss(output, y.view(-1, 1)) optimizer.zero_grad() # reset gradient, equal to net.zero_grad() l.backward() optimizer.step() print(&#39;epoch %d, loss: %f&#39; % (epoch, l.item())) # result comparision dense = net[0] print(true_w, dense.weight.data) print(true_b, dense.bias.data) 做错的两个题 两题都涉及到广播机制，即当对两个形状不同的Tensor按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个Tensor形状相同后再按元素运算。具体可参考以下两个链接： https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter02_prerequisite/2.2_tensor https://pytorch.org/docs/stable/notes/broadcasting.html 关于公式的推导参见以下文章https://mp.weixin.qq.com/s/axFly1Zmw8baifYQF_RnTA 小结视频中用了许多pytorch的函数，由于不是太了解pytorch内的函数，因此查询记录了一下。torch.ones()/torch.zeros()，与MATLAB的ones/zeros很接近。初始化生成均匀分布torch.rand(sizes, out=None) → Tensor返回一个张量，包含了从区间[0, 1)的均匀分布中抽取的一组随机数。张量的形状由参数sizes定义。标准正态分布torch.randn(sizes, out=None) → Tensor返回一个张量，包含了从标准正态分布（均值为0，方差为1，即高斯白噪声）中抽取的一组随机数。张量的形状由参数sizes定义。torch.mul(a, b)是矩阵a和b对应位相乘，a和b的维度必须相等，比如a的维度是(1, 2)，b的维度是(1, 2)，返回的仍是(1, 2)的矩阵torch.mm(a, b)是矩阵a和b矩阵相乘，比如a的维度是(1, 2)，b的维度是(2, 3)，返回的就是(1, 3)的矩阵torch.Tensor是一种包含单一数据类型元素的多维矩阵，定义了7种CPU tensor和8种GPU tensor类型。random.shuffle(a)：用于将一个列表中的元素打乱。shuffle() 是不能直接访问的，需要导入 random 模块，然后通过 random 静态对象调用该方法。backward()是pytorch中提供的函数，配套有require_grad：1.所有的tensor都有.requires_grad属性,可以设置这个属性.x = tensor.ones(2,4,requires_grad=True)2.如果想改变这个属性，就调用tensor.requires_grad_()方法： x.requires_grad_(False) 和大多数深度学习模型一样，对于线性回归这样一种单层神经网络，它的基本要素包括模型、训练数据、损失函数和优化算法。 既可以用神经网络图表示线性回归，又可以用矢量计算表示该模型。 应该尽可能采用矢量计算，以提升计算效率。 Softmax与分类模型Softmax的基本形式Softmax通过下式将输出值变换成值为正且和为1的概率分布： 交叉熵损失函数我们并不需要预测概率完全等于标签概率，而平方损失过于严格。 获取Fashion-MNIST训练集和读取数据这里用到了torchvision包： torchvision.datasets: 一些加载数据的函数及常用的数据集接口； torchvision.models: 包含常用的模型结构（含预训练模型），例如AlexNet、VGG、ResNet等； torchvision.transforms: 常用的图片变换，例如裁剪、旋转等； torchvision.utils: 其他的一些有用的方法。 以下代码在kesci平台运行 # import needed package %matplotlib inline from IPython import display import matplotlib.pyplot as plt import torch import torchvision import torchvision.transforms as transforms import time import sys sys.path.append(&quot;/home/kesci/input&quot;) import d2lzh1981 as d2l # get datasheet mnist_train = torchvision.datasets.FashionMNIST(root=&#39;/home/kesci/input/FashionMNIST2065&#39;, train=True, download=True, transform=transforms.ToTensor()) mnist_test = torchvision.datasets.FashionMNIST(root=&#39;/home/kesci/input/FashionMNIST2065&#39;, train=False, download=True, transform=transforms.ToTensor()) # show result print(type(mnist_train)) print(len(mnist_train), len(mnist_test)) feature, label = mnist_train[0] print(feature.shape, label) # Channel x Height x Width # 如果不做变换输入的数据是图像，我们可以看一下图片的类型参数： mnist_PIL = torchvision.datasets.FashionMNIST(root=&#39;/home/kesci/input/FashionMNIST2065&#39;, train=True, download=True) PIL_feature, label = mnist_PIL[0] print(PIL_feature) mnist_PIL = torchvision.datasets.FashionMNIST(root=&#39;/home/kesci/input/FashionMNIST2065&#39;, train=True, download=True) PIL_feature, label = mnist_PIL[0] print(PIL_feature) def show_fashion_mnist(images, labels): d2l.use_svg_display() # 这里的_表示我们忽略（不使用）的变量 _, figs = plt.subplots(1, len(images), figsize=(12, 12)) for f, img, lbl in zip(figs, images, labels): f.imshow(img.view((28, 28)).numpy()) f.set_title(lbl) f.axes.get_xaxis().set_visible(False) f.axes.get_yaxis().set_visible(False) plt.show() X, y = [], [] for i in range(10): X.append(mnist_train[i][0]) # 将第i个feature加到X中 y.append(mnist_train[i][1]) # 将第i个label加到y中 show_fashion_mnist(X, get_fashion_mnist_labels(y)) X, y = [], [] for i in range(10): X.append(mnist_train[i][0]) # 将第i个feature加到X中 y.append(mnist_train[i][1]) # 将第i个label加到y中 show_fashion_mnist(X, get_fashion_mnist_labels(y)) start = time.time() for X, y in train_iter: continue print(&#39;%.2f sec&#39; % (time.time() - start)) Softmax从零开始实现import torch import torchvision import numpy as np import sys sys.path.append(&quot;/home/kesci/input&quot;) import d2lzh1981 as d2l batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, root=&#39;/home/kesci/input/FashionMNIST2065&#39;) num_inputs = 784 print(28*28) num_outputs = 10 W = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_outputs)), dtype=torch.float) b = torch.zeros(num_outputs, dtype=torch.float) # 对多维Tensor按维度操作 X = torch.tensor([[1, 2, 3], [4, 5, 6]]) print(X.sum(dim=0, keepdim=True)) # dim为0，按照相同的列求和，并在结果中保留列特征 print(X.sum(dim=1, keepdim=True)) # dim为1，按照相同的行求和，并在结果中保留行特征 print(X.sum(dim=0, keepdim=False)) # dim为0，按照相同的列求和，不在结果中保留列特征 print(X.sum(dim=1, keepdim=False)) # dim为1，按照相同的行求和，不在结果中保留行特征 def softmax(X): X_exp = X.exp() partition = X_exp.sum(dim=1, keepdim=True) # print(&quot;X size is &quot;, X_exp.size()) # print(&quot;partition size is &quot;, partition, partition.size()) return X_exp / partition # 这里应用了广播机制 X = torch.rand((2, 5)) X_prob = softmax(X) print(X_prob, &#39;\n&#39;, X_prob.sum(dim=1)) # Softmax回归模型 def net(X): return softmax(torch.mm(X.view((-1, num_inputs)), W) + b) # 定义损失函数 y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]]) y = torch.LongTensor([0, 2]) y_hat.gather(1, y.view(-1, 1)) def cross_entropy(y_hat, y): return - torch.log(y_hat.gather(1, y.view(-1, 1))) # 定义准确率 def accuracy(y_hat, y): return (y_hat.argmax(dim=1) == y).float().mean().item() print(accuracy(y_hat, y)) # 训练模型 num_epochs, lr = 5, 0.1 # 本函数已保存在d2lzh_pytorch包中方便以后使用 def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params=None, lr=None, optimizer=None): for epoch in range(num_epochs): train_l_sum, train_acc_sum, n = 0.0, 0.0, 0 for X, y in train_iter: y_hat = net(X) l = loss(y_hat, y).sum() # 梯度清零 if optimizer is not None: optimizer.zero_grad() elif params is not None and params[0].grad is not None: for param in params: param.grad.data.zero_() l.backward() if optimizer is None: d2l.sgd(params, lr, batch_size) else: optimizer.step() train_l_sum += l.item() train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item() n += y.shape[0] test_acc = evaluate_accuracy(test_iter, net) print(&#39;epoch %d, loss %.4f, train acc %.3f, test acc %.3f&#39; % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc)) train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr) # 模型预测 X, y = iter(test_iter).next() true_labels = d2l.get_fashion_mnist_labels(y.numpy()) pred_labels = d2l.get_fashion_mnist_labels(net(X).argmax(dim=1).numpy()) titles = [true + &#39;\n&#39; + pred for true, pred in zip(true_labels, pred_labels)] d2l.show_fashion_mnist(X[0:9], titles[0:9]) Softmax的简洁实现# 加载各种包或者模块 import torch from torch import nn from torch.nn import init import numpy as np import sys sys.path.append(&quot;/home/kesci/input&quot;) import d2lzh1981 as d2l #初始化参数和获取数据 batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, root=&#39;/home/kesci/input/FashionMNIST2065&#39;) #定义网络模型 num_inputs = 784 num_outputs = 10 class LinearNet(nn.Module): def __init__(self, num_inputs, num_outputs): super(LinearNet, self).__init__() self.linear = nn.Linear(num_inputs, num_outputs) def forward(self, x): # x 的形状: (batch, 1, 28, 28) y = self.linear(x.view(x.shape[0], -1)) return y # net = LinearNet(num_inputs, num_outputs) class FlattenLayer(nn.Module): def __init__(self): super(FlattenLayer, self).__init__() def forward(self, x): # x 的形状: (batch, *, *, ...) return x.view(x.shape[0], -1) from collections import OrderedDict net = nn.Sequential( # FlattenLayer(), # LinearNet(num_inputs, num_outputs) OrderedDict([ (&#39;flatten&#39;, FlattenLayer()), (&#39;linear&#39;, nn.Linear(num_inputs, num_outputs))]) # 或者写成我们自己定义的 LinearNet(num_inputs, num_outputs) 也可以 ) # 初始化模型参数 init.normal_(net.linear.weight, mean=0, std=0.01) init.constant_(net.linear.bias, val=0) #定义损失函数 loss = nn.CrossEntropyLoss() # 下面是他的函数原型 # class torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction=&#39;mean&#39;) #定义优化函数 optimizer = torch.optim.SGD(net.parameters(), lr=0.1) # 下面是函数原型 # class torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False) #训练 num_epochs = 5 d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer) 多层感知机无论添加多少隐藏层，都等价于单层神经网络。解决方法是引入非线性变换，这个非线性函数就叫做激活函数。激活函数主要有以下三种： ReLU函数 Sigmoid函数，(0,1) tanh函数，(-1,1) 关于激活函数的选择： ReLu函数是一个通用的激活函数，目前在大多数情况下使用。但是，ReLU函数只能在隐藏层中使用。 用于分类器时，sigmoid函数及其组合通常效果更好。由于梯度消失问题，有时要避免使用sigmoid和tanh函数。 在神经网络层数较多的时候，最好使用ReLu函数，ReLu函数比较简单计算量少，而sigmoid和tanh函数计算量大很多。 在选择激活函数的时候可以先选用ReLu函数如果效果不理想可以尝试其他激活函数。pytorch实现： import torch from torch import nn from torch.nn import init import numpy as np import sys sys.path.append(&quot;/home/kesci/input&quot;) import d2lzh1981 as d2l # 初始化模型和各个参数 num_inputs, num_outputs, num_hiddens = 784, 10, 256 net = nn.Sequential( d2l.FlattenLayer(), nn.Linear(num_inputs, num_hiddens), nn.ReLU(), nn.Linear(num_hiddens, num_outputs), ) for params in net.parameters(): init.normal_(params, mean=0, std=0.01) # 训练 batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size,root=&#39;/home/kesci/input/FashionMNIST2065&#39;) loss = torch.nn.CrossEntropyLoss() optimizer = torch.optim.SGD(net.parameters(), lr=0.5) num_epochs = 5 d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>线性回归</tag>
        <tag>Softmax与分类模型</tag>
        <tag>多层感知机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于边缘智能的几篇论文的学习笔记]]></title>
    <url>%2F2020%2F02%2F03%2F%E5%85%B3%E4%BA%8E%E8%BE%B9%E7%BC%98%E6%99%BA%E8%83%BD%E7%9A%84%E5%87%A0%E7%AF%87%E8%AE%BA%E6%96%87%2F</url>
    <content type="text"><![CDATA[边缘计算(Edge computing)指的是接近于事物，数据和行动源头处的计算。用更通用的术语来表示即：邻近计算或者接近计算(Proximity Computing)。如果云计算是集中式大数据处理，边缘计算则可以理解为边缘式大数据处理。边缘计算已经逐步在物联网、AR/VR场景以及大数据和人工智能行业有所应用。 什么是边缘计算首先，我们仔细观察Edge Computing这个词，其中的edge是和Cloud Computing中的cloud相对应的概念。目前云计算几乎是所有应用程序的主流解决方案，我们的移动端在大多数场景中仅负责发送请求、接收返回数据、渲染画面等操作。在云计算中，庞大的、来自地理位置各异的移动用户终端的服务请求首先通过有线或无线的方式传入接入网(access network)，再经过主干网传播(backbone)传送给服务所在的数据中心进行处理。在这个过程中，位于云端的数据中心才是真正负责处理用户服务请求的地方，而主干网的传播是相对耗时的，这对于那些对延迟极其敏感的应用程序来说是非常不友好的。例如，超高清视频的下载、在线的超高清视频游戏、在线的AR\VR应用程序、自动驾驶等。 我们想办法降低延迟，有两种途径。第一种，也是最常见的一种，怼硬件怼带宽就完事了。显然，这种方式必然是奢侈的。第二种方法则直接改变了计算方式，也就是：尽可能取消请求和数据在主干网的路由。如何做到这一点呢？直接把计算和处理能力从远在天边的云数据中心下沉到距离用户非常近的接入网不就可以了吗！这正是边缘计算的思路。随着5G的到来，这种计算范式上的转变势在必行。我们知道，5G使用了更高的频带，因此无线信号的覆盖范围将会大大受限，为了做到全面覆盖，需要部署很多的微基站。我们有十足的理由赋予这些微基站一定的计算能力，甚至可以在周围建立小型数据中心，直接处理来自微基站转发来的服务请求。这样就完全杜绝了在主干网上极其耗时的路由开销。 当然，以上仅仅是最理想的情况，目前更多的研究人员推崇的是device-edge-cloud synergy，也就是“云-边-端协同处理”。至于怎么个协同法，具体问题具体分析。但是，至少要依据以下特征来定：端通常是计算受限、电池受限的，边和端相比计算能力更强，但是和云相比则是小巫见大巫。但是用户体验的延迟则是正好相反。举个栗子，如果要在移动端完成一个DNN分类的任务，我们可以将已经训练好的DNN模型进行切分，前一半网络层（假设是计算不密集的）放在边缘服务器上，后一半计算密集型的网络层放到云数据中心。用户作为端将待分类的图片发送给边，边将前半部分返回的结果发送给云，由云来完成后半部分，最后的结果再回传给端。这个过程需要在计算开销和通信开销之间做权衡。（注：该案例来自论文Edge Intelligence: On-demand Deep Learning Model Co-inference with Device-edge Synergy） 我们不能将边缘计算剥离出来单独看待。边缘计算更多的是针对物理场景下的考虑，也不是所有的应用程序都需要边缘计算。但是，计算下沉、边端赋能一定是必然会发生的未来。最后，关于边缘计算、雾计算、Cloudlet之间的关系可以参考下面这一页slide: 边缘计算和雾计算的区别随着边缘计算的兴起，理解边缘设备所涉及的另一项技术也很重要，它就是雾计算。 边缘计算具体是指在网络的”边缘”处或附近进行的计算过程，而雾计算则是指边缘设备和云端之间的网络连接。 虽然边缘计算给云计算带来补充，并且与雾计算一起非常紧密地运作，但它绝不是二者的替代者。 如何开展边缘计算的研究优化与设计自底向上可以划分为：Topology、Content、Service。顾名思义，Topology研究的就是边缘计算的架构，这涉及边缘站点的放置及部署(edge site orchestration)、无线网络规划和路由(network planning)等。此处的研究工作与radio access network方向有很大重叠(灌水的快乐源泉:-D)。Content是建立在Topology基础上的：既然我们已经搭建好了边缘网络，接下来要做的就是内容(数据+服务)的部署和放置。这就会涉及到许多问题。例如，要采用哪一种服务架构？以微服务器架构为例，我们需要为各类服务选择合适的边缘站点部署实例，这就得面临服务器选择(server selectioin)、服务放置/部署(service placement/deployment)等问题。如果待部署的服务有复杂的组合结构，那么也会涉及到服务组合的问题(service selection for compositin)等。Content与服务计算关联密切。Service是建立在物理架构和内容放置的基础上的，研究的是如何合理调度资源以提供更加优秀的服务质量何用户体验。包括计算卸载方案的设计(coputing offloading)、用户数据在不同边缘站点之间的同步与迁移(synchronization &amp; migration)、移动性管理(mobility management)等。 以上内容并非是割裂开来的。实际上，许多工作针对以上目标组合式地建模，求解。以上述感兴趣的名词+edge computing作为关键词在谷歌上检索就可以找到许多工作，从模仿开始。对于一个子方向而言，所需要的研究基础差异不大，多读几篇就可以大致建立基本的框架和观念。这类工作其实是非常容易灌水的，因而催生了一大批褒贬不一的、同质的论文。 边缘计算与人工智能结合，也即是边缘智能(Edge Itelligence)，是目前学术界的热点研究方向。这部分的工作自顶向下可分类为模型适配(model adaptation)、框架设计(framework design)和硬件加速(processor acceleration)。边缘智能主要研究如何将人工智能模型(统计学习、深度学习及强化学习均有包含)放在网络边缘端执行。以深度神经网络为例，联邦学习就是一个极佳的训练框架，可以尝试性地放置在资源受限地终端及边缘设备上执行。基于联邦学习这一分布式训练框架，许多工作研究如何通过模型压缩等手段降低DNN模型的资源占用，让其适配计算资源相对受限的网络边缘。 系统与工程这一部分的研究通常与实际问题紧密结合。例如视频监控的实时处理（目标检测、嫌疑行为识别等）、车联网和自动驾驶中的数据实时感知与处理、无人机的实时路径规划与农业灌溉等。即使是研究资源调度和优化的工作，也与从优化角度入手的论文完全不同。这些工作通常借助一些单片机作为边缘设备，借助Docket和Kubernetes搭建benchmarks，并开发相应的中间件来解决这些实际问题。和优化类的工作相比，这类工作研究周期长、设计到要解决的问题所在领域的专业知识，不容易灌水。但是，在理论和模型上难有创新。因此，该问题中的研究基础不好界定。目前SEC（ACM/IEEE Symposium on Edge Computing）这几年的论文偏系统的居多，感兴趣的可以从这个会议上找文献。 做研究的步骤分析问题、建立模型、设计算法求解并做实验验证。从模仿起步是很重要的，当自己没有思路的时候，就可以去顶会顶刊上看看别人是怎么做的，有哪些可以学习的技巧。撰写英文学术论文最主要的是要克服自己的恐惧心理，大大方方去面对这件事情。 这里引用袁、刘老师的几句建议： 我们现在要做的就是找问题找方法，一篇论文要看的是针对哪个领域或者方向的什么问题，目前有哪些挑战，有什么解决方案和方法，创新点是什么，能达到什么效果，还有什么待改进和值得研究的方面。阅读文献有套路（1）看摘要应该注意：思考这一整段文字中的三段逻辑，即，该论文针对1）什么背景下的什么问题，2）提出了自己的什么解决方案，3）效果如何，这三部曲。（2）看概述应该注意：这部分表面看，似乎是个故事的铺垫，不痛不痒，甚至你会感觉可有可无，实则不然，恰恰相反，这部分内容非常非常非常的重要，也最不好写，不好写的原因在于，这部分对问题的全局性进行梳理，逻辑要一环扣一环，需要非常严谨，梳理归纳出问题所在，出如同耍把式卖艺的“打场子”阶段，有了场子，后面就是具体表演了。。。 目前正在看的几篇论文资源约束边缘计算系统中的自适应联邦学习（Adaptive Federated Leaning in Resource Constrainen Edge Computing Systems） 摘要：新兴的技术和应用，包括物联网、社交网络、和众包，在网络边缘产生了大量的数据。机器学习模式往往从收集的数据处建立起来，使检测，分类和预测未来的事件。由于带宽、存储和隐私问题，将所有数据发送到一个集中的地点通常是不切实际的。在本文中，我们考虑了从分布在多个边缘节点上的数据中学习模型参数的问题，而不将原始数据发送到集中的地方。我们的重点是在一类通用的机器学习模型上，使用基于梯度的方法进行训练。从理论角度分析了分布式梯度下降的收敛性。在此基础上，我们提出了一种控制算法，该算法确定了局部更新和全局参数聚合之间的最佳权衡，以最小化给定资源预算下的损失函数。通过对真实数据集的广泛实验，在网络原型系统和更大规模的模拟环境中，对所提出的算法的性能进行了评估。实验结果表明，我们提出的方法在不同的机器学习模型和不同的数据分布下，性能接近最优。 这篇文章得到了一个基于梯度下降的联合学习的新的收敛界，它包含了非独立的和识别的两个界(非i.i.d)节点之间的数据分布和两个全局聚合之间的任意数量的本地更新。 利用上述理论收敛边界，提出了一种学习数据分布、系统力学和模型特征的控制算法，并在此基础上对全局聚合频率和实时性进行了动态适应，研究了全局聚合频率对具有资源约束的联邦学习的适应性，以尽量减少固定资源预算下的学习损失。 今后的研究可以集中在如何充分利用分布式学习的异构资源，以及代表深层神经网络某种形式的的非凸损失函数的理论收敛分析。 边缘AI：通过联合学习对移动边缘计算，缓存和通信进行智能化（In-Edge AI: Intelligentizing Mobile Edge Computing, Caching and Communication by Federated Learning） 摘要： 近年来，随着移动通信技术的飞速发展，边缘计算理论和技术受到了全球研究人员和工程师的越来越多的关注，它们可以通过网络边缘显着地弥合云的容量和对设备的需求，并且因此可以加速内容交付并提高移动服务的质量。与传统的优化方法相比，在当前的深度学习技术的驱动下，为了给边缘系统带来更多的智能，我们建议将深度强化学习技术和联合学习框架与移动边缘系统相集成，以优化移动边缘计算，缓存和通讯。因此，我们设计了“ In-Edge AI”框架，以便智能地利用设备和边缘节点之间的协作来交换学习参数，以更好地训练和推断模型，从而进行动态系统级优化和应用程序级增强，同时减少不必要的系统通信负载。对“ In-Edge AI”进行了评估，并证明其具有近乎最佳的性能，但学习开销相对较低，而该系统具有认知性并且适用于移动通信系统。最后，我们讨论了一些相关的挑战和机遇，以揭示有前途的“ In-Edge AI”的未来。 相关工作中考虑的不多的问题： 应该以何种形式收集训练数据（无论是分布式还是集中式） 应该在哪里放置和训练强化学习智能体（无论是在UE，边缘节点还是远程云基础架构中） 强化学习智能体的更新过程应如何进行、协作。 训练数据的隐私保护 这篇文章的创新点： 将DRL与联合学习相结合用于MEC系统中通信和计算的智能联合资源管理，讨论利用DRL的方法（特别是深度Q学习）和分布式DRL，以优化边缘缓存和计算。 提出了”边缘AI”框架，以进一步利用”联合学习”在MEC系统中更好地部署智能资源管理 参考链接： https://www.zhihu.com/question/35792003 https://www.zhihu.com/question/319330609]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>MEC</tag>
        <tag>Federated Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm学习笔记]]></title>
    <url>%2F2020%2F02%2F02%2Fnpm%E6%98%AF%E5%B9%B2%E4%BB%80%E4%B9%88%E7%9A%84%2F</url>
    <content type="text"><![CDATA[最近学习前端碰到很多使用npm的情况，却不知道为什么要使用npm，用这篇博客来详细介绍一下npm。 社区程序员自古以来就有社区文化： 社区的意思是：拥有共同职业或兴趣的人们，自发组织在一起，通过分享信息和资源进行合作。虚拟社区的参与者经常会在线讨论相关话题，或访问某些网站。 前端程序员也有社区，世界上最大的前端社区应该就是 GitHub 了。前端通过 GitHub 来 分享源代码（线上代码仓库） 讨论问题（Issue 列表） 收集学习资源和常去的网站 加入社区最大的好处之一是，你可以使用别人贡献的代码，你也可以贡献代码给别人用。 共享代码前端是怎么共享代码的呢？ 在 GitHub 还没有兴起的年代，前端是通过网址来共享代码 比如你想使用 jQuery，那么你点击 jQuery 网站上提供的链接就可以下载 jQuery，放到自己的网站上使用 GItHub 兴起之后，社区中也有人使用 GitHub 的下载功能： 麻烦当一个网站依赖的代码越来越多，程序员发现这是一件很麻烦的事情： 去 jQuery 官网下载 jQuery 去 BootStrap 官网下载 BootStrap 去 Underscore 官网下载 Underscore …… 有些程序员就受不鸟了，一个拥有三大美德的程序员Isaac Z. Schlueter（以下简称 Isaaz）给出一个解决方案：用一个工具把这些代码集中到一起来管理吧！ 这个工具就是他用 JavaScript （运行在 Node.js 上）写的 npm，全称是 Node Package Manager 具体步骤NPM 的思路大概是这样的： 买个服务器作为代码仓库（registry），在里面放所有需要被共享的代码 发邮件通知 jQuery、Bootstrap、Underscore 作者使用 npm publish 把代码提交到 registry 上，分别取名 jquery、bootstrap 和 underscore（注意大小写） 社区里的其他人如果想使用这些代码，就把 jquery、bootstrap 和 underscore 写到 package.json 里，然后运行 npm install ，npm 就会帮他们下载代码 下载完的代码出现在 node_modules 目录里，可以随意使用了。 这些可以被使用的代码被叫做「包」（package），这就是 NPM 名字的由来：Node Package(包) Manager(管理器)。 发展Isaaz 通知 jQuery 作者 John Resig，他会答应吗？这事儿不一定啊，对不对。 只有社区里的人都觉得 「npm 是个宝」的时候，John Resig 才会考虑使用 npm。 那么 npm 是怎么火的呢？ npm 的发展是跟 Node.js 的发展相辅相成的。 Node.js 是由一个在德国工作的美国程序员 Ryan Dahl 写的。他写了 Node.js，但是 Node.js 缺少一个包管理器，于是他和 npm 的作者一拍即合、抱团取暖，最终 Node.js 内置了 npm。 后来的事情大家都知道，Node.js 火了。 随着 Node.js 的火爆，大家开始用 npm 来共享 JS 代码了，于是 jQuery 作者也将 jQuery 发布到 npm 了。 所以现在，你可以使用 npm install jquery 来下载 jQuery 代码。 现在用 npm 来分享代码已经成了前端的标配。 后续Node.js 目前由 Ryan Dahl 当时所在的公司 joyent 继续开发。Ryan Dahl 现在已经去研究 AI 和机器学习了，并且他把 Node.js 的维护权交给了 Isaaz。（我是不是也应该去研究 AI 和机器学习啊教练） 而 Isaaz 维护了一段时间后，辞职了，成立了一个公司专门维护 npm 的 registry，公司名叫做npm 股份有限公司……谁说开源不能赚钱的~ 社区的力量回顾前端的发展是你会发现，都是社区里的某个人，发布了一份代码，最终影响前端几年的走向。比如 jQuery，比如 Node.js，比如 npm。（其实其他语言也是这样的） 所以，社区的力量是巨大的。 如何使用 NPM安装npm 不需要单独安装。在安装 Node 的时候，会连带一起安装 npm 。但是，Node 附带的 npm 可能不是最新版本，最后用下面的命令，更新到最新版本。$ sudo npm install npm@latest -g 如果是 Window 系统使用以下命令即可： npm install npm -g 也就是使用 npm 安装自己。之所以可以这样，是因为 npm 本身与 Node 的其他模块没有区别。 然后，运行下面的命令，查看各种信息。 # 查看 npm 命令列表 $ npm help # 查看各个命令的简单用法 $ npm -l # 查看 npm 的版本 $ npm -v # 查看 npm 的配置 $ npm config list -l 使用npm initnpm init 用来初始化生成一个新的 package.json 文件。它会向用户提问一系列问题，如果你觉得不用修改默认配置，一路回车就可以了。如果使用了 -f（代表force）、-y（代表yes），则跳过提问阶段，直接生成一个新的 package.json 文件。$ npm init -y npm setnpm set 用来设置环境变量 $ npm set init-author-name &#39;Your name&#39; $ npm set init-author-email &#39;Your email&#39; $ npm set init-author-url &#39;http://yourdomain.com&#39; $ npm set init-license &#39;MIT&#39; 上面命令等于为 npm init 设置了默认值，以后执行 npm init 的时候，package.json 的作者姓名、邮件、主页、许可证字段就会自动写入预设的值。这些信息会存放在用户主目录的 ~/.npmrc文件，使得用户不用每个项目都输入。如果某个项目有不同的设置，可以针对该项目运行 npm config。 npm infonpm info 命令可以查看每个模块的具体信息。比如，查看 underscore 模块的信息。$ npm info underscore上面命令返回一个 JavaScript 对象，包含了 underscore 模块的详细信息。这个对象的每个成员，都可以直接从 info 命令查询。 $ npm info underscore description $ npm info underscore homepage $ npm info underscore version npm searchnpm search 命令用于搜索 npm 仓库，它后面可以跟字符串，也可以跟正则表达式。$ npm search &lt;搜索词&gt; npm listnpm list 命令以树形结构列出当前项目安装的所有模块，以及它们依赖的模块。 $ npm list # 加上 global 参数，会列出全局安装的模块 $ npm list -global # npm list 命令也可以列出单个模块 $ npm list underscore npm install使用 npm 安装包的命令格式为：npm install/i &lt;package_name&gt; 本地模式和全局模式npm 在默认情况下会从 http://npmjs.org 搜索或下载包，将包安装到当前目录的 node_modules 子目录下。 如果你熟悉 Ruby 的 gem 或者 Python 的 pip，你会发现 npm 与它们的行为不同，gem 或 pip 总是以全局模式安装，使包可以供所有的程序使用，而 npm 默认会把包安装到当前目录下。这反映了 npm 不同的设计哲学。如果把包安装到全局，可以提供程序的重复利用程度，避免同样的内容的多分副本，但坏处是难以处理不同的版本依赖。如果把包安装到当前目录，或者说本地，则不会有不同程序依赖不同版本的包的冲突问题，同时还减轻了包作者的 API 兼容性压力，但缺陷则是同一个包可能会被安装许多次。 我们在使用 supervisor 的时候使用了npm install -g supervisor命令，就是以全局模式安装 supervisor 。 这里注意一点的就是，supervisor 必须安装到全局，如果你不安装到全局，错误命令会提示你安装到全局。如果不想安装到默认的全局，也可以自己修改全局路径到当前路径 npm config set prefix &quot;路径&quot;安装完以后就可以用 supervisor 来启动服务了。 supervisor 可以帮助你实现这个功能，它会监视你对代码的驱动，并自动重启 Node.js 。 一般来说，全局安装只适用于工具模块，比如 eslint 和 gulp 。关于使用全局模式，多数时候并不是因为许多程序都有可能用到了它，为了减少多重副本而使用全局模式，而是因为本地模式不会注册 PATH 环境变量。 “本地安装”指的是将一个模块下载到当前项目的 node_modules 子目录，然后只有在项目目录之中，才能调用这个模块。 本地模式和全局模式的特点如下： 模式 可通过 require 使用 注册 PATH 本地模式 是 否 全局模式 否 是 # 本地安装 $ npm install &lt;package name&gt; # 全局安装 $ sudo npm install -global &lt;package name&gt; $ sudo npm install -g &lt;package name&gt; npm install 也支持直接输入 Github 代码库地址。 $ npm install git://github.com/package/path.git $ npm install git://github.com/package/path.git#0.1.0 安装之前，npm install 会先检查，node_modules目录之中是否已经存在指定模块。如果存在，就不再重新安装了，即使远程仓库已经有了一个新版本，也是如此。 如果你希望，一个模块不管是否安装过， npm 都要强制重新安装，可以使用 -f 或 —force 参数。 $ npm install &lt;packageName&gt; --force 安装不同版本install 命令总是安装模块的最新版本，如果要安装模块的特定版本，可以在模块名后面加上 @ 和版本号。 $ npm install sax@latest $ npm install sax@0.1.1 $ npm install sax@&quot;&gt;=0.1.0 &lt;0.2.0&quot; install 命令可以使用不同参数，指定所安装的模块属于哪一种性质的依赖关系，即出现在 packages.json 文件的哪一项中。 –save：模块名将被添加到 dependencies，可以简化为参数-S。–save-dev：模块名将被添加到 devDependencies，可以简化为参数-D。 $ npm install sax --save $ npm install node-tap --save-dev # 或者 $ npm install sax -S $ npm install node-tap -D dependencies 依赖这个可以说是我们 npm 核心一项内容，依赖管理，这个对象里面的内容就是我们这个项目所依赖的 js 模块包。下面这段代码表示我们依赖了 markdown-it 这个包，版本是 ^8.1.0 ，代表最小依赖版本是 8.1.0 ，如果这个包有更新，那么当我们使用 npm install 命令的时候，npm 会帮我们下载最新的包。当别人引用我们这个包的时候，包内的依赖包也会被下载下来。 &quot;dependencies&quot;: { &quot;markdown-it&quot;: &quot;^8.1.0&quot; } devDependencies 开发依赖在我们开发的时候会用到的一些包，只是在开发环境中需要用到，但是在别人引用我们包的时候，不会用到这些内容，放在 devDependencies 的包，在别人引用的时候不会被 npm 下载。 &quot;devDependencies&quot;: { &quot;autoprefixer&quot;: &quot;^6.4.0&quot;,0&quot;, &quot;babel-preset-es2015&quot;: &quot;^6.0.0&quot;, &quot;babel-preset-stage-2&quot;: &quot;^6.0.0&quot;, &quot;babel-register&quot;: &quot;^6.0.0&quot;, &quot;webpack&quot;: &quot;^1.13.2&quot;, &quot;webpack-dev-middleware&quot;: &quot;^1.8.3&quot;, &quot;webpack-hot-middleware&quot;: &quot;^2.12.2&quot;, &quot;webpack-merge&quot;: &quot;^0.14.1&quot;, &quot;highlightjs&quot;: &quot;^9.8.0&quot; } 当你有了一个完整的 package.json 文件的时候，就可以让人一眼看出来，这个模块的基本信息，和这个模块所需要依赖的包。我们可以通过 npm install 就可以很方便的下载好这个模块所需要的包。 npm install 默认会安装 dependencies 字段和 devDependencies 字段中的所有模块，如果使用 —production 参数，可以只安装 dependencies 字段的模块。 $ npm install --production # 或者 $ NODE_ENV=production npm install 一旦安装了某个模块，就可以在代码中用 require 命令加载这个模块。 var backbone = require(&#39;backbone&#39;) console.log(backbone.VERSION) npm runnpm 不仅可以用于模块管理，还可以用于执行脚本。package.json 文件有一个 scripts 字段，可以用于指定脚本命令，供 npm 直接调用。package.json { &quot;name&quot;: &quot;myproject&quot;, &quot;devDependencies&quot;: { &quot;jshint&quot;: &quot;latest&quot;, &quot;browserify&quot;: &quot;latest&quot;, &quot;mocha&quot;: &quot;latest&quot; }, &quot;scripts&quot;: { &quot;lint&quot;: &quot;jshint **.js&quot;, &quot;test&quot;: &quot;mocha test/&quot; } } scripts 脚本顾名思义，就是一些脚本代码，可以通过npm run script-key来调用，例如在这个 package.json 的文件夹下使用npm run dev就相当于运行了 node build/dev-server.js 这一段代码。使用 scripts 的目的就是为了把一些要执行的代码合并到一起，使用 npm run 来快速的运行，方便省事。npm run 是 npm run-script 的缩写，一般都使用前者，但是后者可以更好的反应这个命令的本质。 // 脚本 &quot;scripts&quot;: { &quot;dev&quot;: &quot;node build/dev-server.js&quot;, &quot;build&quot;: &quot;node build/build.js&quot;, &quot;docs&quot;: &quot;node build/docs.js&quot;, &quot;build-docs&quot;: &quot;npm run docs &amp; git checkout gh-pages &amp; xcopy /sy dist\\* . &amp; git add . &amp; git commit -m &#39;auto-pages&#39; &amp; git push &amp; git checkout master&quot;, &quot;build-publish&quot;: &quot;rmdir /S /Q lib &amp; npm run build &amp;git add . &amp; git commit -m auto-build &amp; npm version patch &amp; npm publish &amp; git push&quot;, &quot;lint&quot;: &quot;eslint --ext .js,.vue src&quot; } npm run 如果不加任何参数，直接运行，会列出 package.json 里面所有可以执行的脚本命令。npm 内置了两个命令简写，npm test等同于执行 npm run test``，``npm start 等同于执行 npm run start。 &quot;build&quot;: &quot;npm run build-js &amp;&amp; npm run build-css&quot; 上面的写法是先运行 npm run build-js ，然后再运行 npm run build-css ，两个命令中间用 &amp;&amp; 连接。如果希望两个命令同时平行执行，它们中间可以用 &amp; 连接。 写在 scripts 属性中的命令，也可以在 node_modules/.bin 目录中直接写成 bash 脚本。下面是一个 bash 脚本。 #!/bin/bash cd site/main browserify browser/main.js | uglifyjs -mc &gt; static/bundle.js 假定上面的脚本文件名为 build.sh ，并且权限为可执行，就可以在 scripts 属性中引用该文件。 &quot;build-js&quot;: &quot;bin/build.sh&quot; pre- 和 post- 脚本npm run为每条命令提供了pre-和post-两个钩子（hook）。以npm run lint为例，执行这条命令之前，npm 会先查看有没有定义 prelint 和 postlint 两个钩子，如果有的话，就会先执行npm run prelint，然后执行npm run lint，最后执行npm run postlint。 { &quot;name&quot;: &quot;myproject&quot;, &quot;devDependencies&quot;: { &quot;eslint&quot;: &quot;latest&quot; &quot;karma&quot;: &quot;latest&quot; }, &quot;scripts&quot;: { &quot;lint&quot;: &quot;eslint --cache --ext .js --ext .jsx src&quot;, &quot;test&quot;: &quot;karma start --log-leve=error karma.config.js --single-run=true&quot;, &quot;pretest&quot;: &quot;npm run lint&quot;, &quot;posttest&quot;: &quot;echo &#39;Finished running tests&#39;&quot; } } 上面代码是一个 package.json 文件的例子。如果执行 npm test，会按下面的顺序执行相应的命令。 pretesttestposttest如果执行过程出错，就不会执行排在后面的脚本，即如果 prelint 脚本执行出错，就不会接着执行 lint 和 postlint 脚本。 npm binnpm bin 命令显示相对于当前目录的，Node 模块的可执行脚本所在的目录（即 .bin 目录）。 # 项目根目录下执行 $ npm bin ./node_modules/.bin 创建全局链接npm 提供了一个有趣的命令 npm link，它的功能是在本地包和全局包之间创建符号链接。我们说过使用全局模式安装的包不能直接通过 require 使用。但通过 npm link 命令可以打破这一限制。举个例子，我们已经通过 npm install -g express 安装了 express，这时在工程的目录下运行命令： npm link express ./node_modules/express -&gt; /user/local/lib/node_modules/express 我们可以在 node_modules 子目录中发现一个指向安装到全局的包的符号链接。通过这种方法，我们就可以把全局包当做本地包来使用了。 除了将全局的包链接到本地以外，使用 npm link 命令还可以将本地的包链接到全局。使用方法是在包目录（package.json 所在目录）中运行 npm link 命令。如果我们要开发一个包，利用这种方法可以非常方便地在不同的工程间进行测试。 创建包包是在模块基础上更深一步的抽象，Node.js 的包类似于 C/C++ 的函数库或者 Java、.Net 的类库。它将某个独立的功能封装起来，用于发布、更新、依赖管理和版本控制。Node.js 根据 CommonJS 规范实现了包机制，开发了 npm 来解决包的发布和获取需求。Node.js 的包是一个目录，其中包含了一个 JSON 格式的包说明文件 package.json。严格符合 CommonJS 规范的包应该具备以下特征：。package.json 必须在包的顶层目录下；。二进制文件应该在 bin 目录下；。JavaScript 代码应该在 lib 目录下；。文档应该在 doc 目录下；。单元测试应该在 test 目录下。 Node.js 对包的要求并没有这么严格，只要顶层目录下有 package.json，并符合一些规范即可。当然为了提高兼容性，我们还是建议你在制作包的时候，严格遵守 CommonJS 规范。 我们也可以把文件夹封装为一个模块，即所谓的包。包通常是一些模块的集合，在模块的基础上提供了更高层的抽象，相当于提供了一些固定接口的函数库。通过定制 package.json，我们可以创建更复杂，更完善，更符合规范的包用于发布。 Node.js 在调用某个包时，会首先检查包中 packgage.json 文件的 main 字段，将其作为包的接口模块，如果 package.json 或 main 字段不存在，会尝试寻找 index.js 或 index.node 作为包的接口。 package.json 是 CommonJS 规定的用来描述包的文件，完全符合规范的 package.json 文件应该含有以下字段： name: 包的名字，必须是唯一的，由小写英文字母、数字和下划线组成，不能包含空格。description: 包的简要说明。version: 符合语义化版本识别规范的版本字符串。keywords: 关键字数组，通常用于搜索。maintainers: 维护者数组，每个元素要包含 name 、email(可选)、web(可选)字段。contributors: 贡献者数组，格式与 maintainers 相同。包的作者应该是贡献者数组的第一个元素。bugs: 提交 bug 的地址，可以是网址或者电子邮件地址。licenses: 许可证数组，每个元素要包含 type（许可证的名称）和 url（链接到许可证文本的地址）字段。repositories: 仓库托管地址数组，每个元素要包含 type（仓库的类型，如 git）、URL（仓库的地址）和 path（相对于仓库的路径，可选）字段。dependencies: 包的依赖，一个关联数组，由包名称和版本号组成。 包的发布通过使用npm init可以根据交互式回答产生一个符合标准的 package.json。创建一个 index.js 作为包的接口,一个简单的包就制作完成了。在发布前,我们还需要获得一个账号用于今后维护自己的包,使用npm adduser根据提示完成账号的创建。 完成后可以使用 npm whoami检测是否已经取得了账号。 接下来，在 package.json 所在目录下运行 npm publish，稍等片刻就可以完成发布了，打开浏览器，访问 http://search.npmjs.org/ 就可以找到自己刚刚发布的包了。现在我们可以在世界的任意一台计算机上使用 npm install neveryumodule 命令来安装它。 如果你的包将来有更新,只需要在 package.json 文件中修改 version 字段，然后重新使用 npm publish 命令就行了。如果你对已发布的包不满意，可以使用 npm unpublish命令来取消发布。需要说明的是：json 文件不能有注释 参考链接: https://blog.csdn.net/csdn_yudong/article/details/78946708 http://javascript.ruanyifeng.com/nodejs/npm.html https://zhuanlan.zhihu.com/p/24357770]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>npm</tag>
        <tag>社区文化</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[POJ 1163]]></title>
    <url>%2F2020%2F01%2F31%2FPOJ-1163%2F</url>
    <content type="text"><![CDATA[1163 The Triangle&ensp;&ensp;&ensp;&ensp;&ensp;7&ensp;&ensp;&ensp;&ensp;3 8&ensp;&ensp;&ensp;8 1 0&ensp;&ensp;2 7 4 4&ensp;4 5 2 6 5(Figure 1) Figure 1 shows a number triangle. Write a program that calculates the highest sum of numbers passed on a route that starts at the top and ends somewhere on the base. Each step can go either diagonally down to the left or diagonally down to the right. InputYour program is to read from standard input. The first line contains one integer N: the number of rows in the triangle. The following N lines describe the data of the triangle. The number of rows in the triangle is &gt; 1 but &lt;= 100. The numbers in the triangle, all integers, are between 0 and 99. OutputYour program is to write to standard output. The highest sum is written as an integer.Sample Input 573 88 1 02 7 4 44 5 2 6 5Sample Output 30 分析：最近刚学了动态规划，下面对其做个总结： 一个题目能dp的条件 满足无后效性（“未来与过去无关”，严格定义：如果给定某一阶段的状态，则在这一阶段以后的发展不受这阶段以前各段状态的影响。） 满足最优子结构性质（大问题的最优解可由小问题的最优解推出） dp的本质和快的原因：dp的核心思想就是尽量缩小可能解空间，DP自带剪枝，舍弃了一大堆不可能成为最优解的答案，自然就比常规穷举要快了。总之就是大事化小，小事化了。 设计DP算法的三连：我是谁?—设计状态，表示局面。我从哪里来？我要到哪里去？—设计转移 &lt;/font&gt;题解： #include&lt;stdio.h&gt; #define INF 100 using namespace std; void read(int a[][INF],int m) { int i,j; for(i=0;i&lt;m;i++) { for(j=0;j&lt;=i;j++) scanf(&quot;%d&quot;,&amp;a[i][j]); } } int dp(int a[][INF],int m) { int i,j; for(i=m-2;i&gt;=0;i--) { for(j=0;j&lt;=i;j++) { if(a[i+1][j+1]&gt;a[i+1][j]) a[i][j]+=a[i+1][j+1]; else a[i][j]+=a[i+1][j]; } } return a[0][0]; } int main() { int a[INF][INF],m; while(scanf(&quot;%d&quot;,&amp;m)!=EOF) { read(a,m); int c=dp(a,m); printf(&quot;%d\n&quot;,c); } return 0; }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Everyone has his time zone]]></title>
    <url>%2F2020%2F01%2F29%2FEveryone-has-his-time-zone%2F</url>
    <content type="text"><![CDATA[New York is 3 hour ahead of California,but it does not make Califonia slow.Someone graduated at the age of 22,but waited 5 years before securing a good job!Someone became a CEO at 25,and died at 50.While another become a CEO at 50,and lived to 90 years.Someone is still single,While someone else got married.Abosolutely everyone in world works based on their Time Zone.People around you might seem to go ahead of you,some might seem to behind you.But everyone is running their own RACE,in their own TIME.Don’t envy them or mock them.They are in their TIME ZONE, and you are in yours!Life is aboout waiting for the right moment to act.So,RELAX.You’re not LATE.You’re not EARLY.You are very much ON TIME,and in your TIME ZONE Destiny set up for you.]]></content>
      <tags>
        <tag>一首小诗</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[攻防世界web新手区题解]]></title>
    <url>%2F2019%2F09%2F16%2F%E6%94%BB%E9%98%B2%E4%B8%96%E7%95%8Cweb%E6%96%B0%E6%89%8B%E5%8C%BA%E9%A2%98%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[题目：view_source这道题没啥好说的，f12即可flag：cyberpeace{e07dcafaeeb31df23b4d661dd4da56f9} 题目：get_post这道题我使用的方法是：旧版本火狐+旧版本的hackbar hackbar勾选Post，load URL内容为：http://111.198.29.45:33495/?a=1 ， post data内容为：b=2，然后点击Execute即可看到flag了 flag：cyberpeace{c4e43c9c9d0f729358dd9417219a9da0} 题目:robots这个题考到了Robots协议，也就是爬虫排除标准，于是肯定有个robots.txt文件，直接构造url访问这个文件，看到了禁止爬取：f1ag_1s_h3re.php这个页面，我们直接访问这个页面于是便得到了flag了 flag：cyberpeace{1b59446bc8e566382e01b0c209b899bd} 题目：backup这道题考察的是备份文件漏洞，产生该类漏洞的方式一般又三个： 编辑器自动备份 版本控制系统备份 开发者主动备份 于是我们知道了备份文件：index.php.bak 下载后便得到flag了 flag：cyberpeace{4376485b1a095581d7fb57b8ab3bb924} 题目：cookie Cookie是当主机访问Web服务器时，由 Web 服务器创建的，将信息存储在用户计算机上的文件。一般网络用户习惯用其复数形式 Cookies，指某些网站为了辨别用户身份、进行 Session 跟踪而存储在用户本地终端上的数据，而这些数据通常会经过加密处理。 浏览器按下F12键打开开发者工具，刷新后，在存储一栏，可看到名为look-here的cookie的值为cookie.php 访问http://111.198.29.45:47911/cookie.php，提示查看http响应包，在网络一栏，可看到访问cookie.php的数据包 点击查看数据包，在消息头内可发现flag flag：cyberpeace{e865c062128d651191621df4662b3573} 题目：disabled_button这个题对于前端工作者来说绝对的简单的不能再简单了，直接删除掉disabled属性，就可以点击了 flag：cyberpeace{2e978e2dde5d8acdd7ff76f1c426bb29} 题目:simple_js这个题真正的密码部分因该是：\x35\x35\x2c\x35\x36\x2c\x35\x34\x2c\x37\x39\x2c\x31\x31\x35\x2c\x36\x39\x2c\x31\x31\x34\x2c\x31\x31\x36\x2c\x31\x30\x37\x2c\x34\x39\x2c\x35\x30 先要把这段16进制转换成10进制得到：55,56,54,79,115,69,114,116,107,49,50 然后直接一段python脚本解得flag s=[55,56,54,79,115,69,114,116,107,49,50]for i in s:print(chr(i),end=’’)flag：Cyberpeace{786OsErtk12} 题目：xff_referer直接刷新一下burp截包，然后添加如下两行内容： X-Forwarded-For:123.123.123.123 Referer:https://www.google.com 然后就看到flag了 flag：cyberpeace{63657c0c7f88a39a475f0de726ef109a} 题目：weak_auth打开网页看到标题提示weak auth弱验证，这就没啥好说的了，没看到验证码，burp直接来爆破吧！ 随便输入下用户名和密码,提示要用admin用户登入,然后跳转到了check.php,查看下源代码提示要用字典。 用burpsuite截下登录的数据包,把数据包发送到intruder爆破 设置爆破点为password 加载字典 开始攻击，查看响应包列表，发现密码为123456时，响应包的长度和别的不一样. 于是便得到了flag flag：cyberpeace{04415bd2dac05f0e2cd712bb43c447b2} 题目：webshell这个没啥好说的，菜刀连接上后发现目录下有个flag.txt，打开就看到了flag了 flag：cyberpeace{74fea3cfddba6bfdc6bfba5b38300b08} 题目：command_execution打开网页在标题看到command execution 命令执行，那就没啥好说的了，看看目录下有些啥吧! ping -c 3 3 127.0.0.1 | ls /binbootdevetchomeliblib64mediamntoptprocrootrunrun.shsbinsrvsystmpusrvar习惯性的看看home里有什么 ping -c 3 127.0.0.1 | ls /homeflag.txtping -c 3 3 127.0.0.1 | cat /home/flag.txtcyberpeace{39190fc825ce46b116b6829f0c13d625}于是便得到了flag！ flag：cyberpeace{39190fc825ce46b116b6829f0c13d625} 题目：simple_php这道题在阅读了PHP代码后，发现，要a==0，但a的值又不能为0，因此让a=0+任意非数字字符，而 b=数字就退出， 于是构造：?a=0a&amp;b=12345A便得到完整的flag flag：Cyberpeace{647E37C7627CC3E4019EC69324F66C7C}]]></content>
      <tags>
        <tag>网安</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机漏洞安全相关的概念]]></title>
    <url>%2F2019%2F08%2F08%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%BC%8F%E6%B4%9E%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E7%9A%84%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[最近在学校的网安协会招新群里做了几个CTF题，发现还是挺有意思的（其实我大一上就加入了，不过是潜水怪，纯混子） 算是重拾对网安的兴趣吧。 POCPOC，Proof ofConcept，中文意思是“观点证明”。这个短语会在漏洞报告中使用，漏洞报告中的POC则是一段说明或者一个攻击的样例，使得读者能够确认这个漏洞是真实存在的。 EXPExploit，中文意思是“漏洞利用”。意思是一段对漏洞如何利用的详细说明或者一个演示的漏洞攻击代码，可以使得读者完全了解漏洞的机理以及利用的方法。 VULVUL，Vulnerability的缩写，泛指漏洞。 CVECVE 的英文全称是“Common Vulnerabilities &amp; Exposures”公共漏洞和暴露，例如CVE-2015-0057、CVE-1999-0001等等。CVE就好像是一个字典表，为广泛认同的信息安全漏洞或者已经暴露出来的弱点给出一个公共的名称。如果在一个漏洞报告中指明的一个漏洞，如果有CVE名称，你就可以快速地在任何其它CVE兼容的数据库中找到相应修补的信息，解决安全问题。 可以在https://cve.mitre.org/ 网站根据漏洞的CVE编号搜索该漏洞的介绍。 也可以在中文社区http://www.scap.org.cn/ 上搜索关于漏洞的介绍 0DAY漏洞和0DAY攻击在计算机领域中，零日漏洞或零时差漏洞（英语：Zero-dayexploit）通常是指还没有补丁的安全漏洞，而零日攻击或零时差攻击（英语：Zero-dayattack）则是指利用这种漏洞进行的攻击。提供该漏洞细节或者利用程序的人通常是该漏洞的发现者。零日漏洞的利用程序对网络安全具有巨大威胁，因此零日漏洞不但是黑客的最爱，掌握多少零日漏洞也成为评价黑客技术水平的一个重要参数。零日漏洞及其利用代码不仅对犯罪黑客而言，具有极高的利用价值，一些国家间谍和网军部队，例如美国国家安全局和美国网战司令部也非常重视这些信息。据路透社报告称美国政府是零日漏洞黑市的最大买家。]]></content>
      <tags>
        <tag>漏洞安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[V2Ray服务器搭建科学上网]]></title>
    <url>%2F2019%2F07%2F04%2FV2ray%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%2F</url>
    <content type="text"><![CDATA[本文从零开始，手把手教你搭建自己的V2ray和SS服务器实现全球互联。史上最详细的小白搭建V2ray和ss教程。内容包括VPS购买，连接VPS，一键搭建V2ray和SS，开启bbr加速，客户端配置。 购买境外VPS服务器首先进入Vultr官网注册：https://www.vultr.com （通过此链接注册充值10美元送50美元）注意：密码首字母需要大写，且长度需要超过10个字符！！！ 再次确认一遍注册邮箱和密码 登录并进入充值界面进行充值 支持信用卡，支付宝，微信支付。创建服务器点击右上方 “+” 号来创建服务器。选择服务器机房 推荐使用东京和新加坡服务器，物理距离近，延迟要低不少。 选择东京服务器可能需要点耐心，因为使用的人比较多，好多IP被墙，没有耐心的可以选择新加坡服务器。 查询服务器是否被墙下面会有讲到。选择服务器操作系统及配置 选择服务器系统，仅推荐使用Debian9 ，使用其他操作系统可能会有一些列问题。 选择完毕点击创建。 服务器规格选择3.5美元的足矣点击我们刚刚创建的服务器 进入查看服务器配置参数复制服务器IP地址服务器端口扫描 使用端口扫描工具扫描我们创建的服务器IP，查看22端口是否开放，如果是关闭的话按照上面教程重新创建服务器，直到“22”端口为开放状态。 然后再删除之前被墙的服务器，Vultr服务器是按小时收费的，所以我们刚刚创建的服务器删除的话是不收费的。 端口扫描工具我使用的是 http://coolaf.com/tool/port 你也可以上百度搜索端口扫描工具即可。 使用Xshell终端连接服务器安装Xshell Xshell 官网下载 安装完成后打开软件，新建会话。填入服务器IP地址 输入一个名称，方便自己以后管理。 填入服务器IP地址。回到Vultr，复制服务器密码填入服务器用户名及密码 点击用户身份验证 填入服务器用户名root（Vultr用户名默认都是root） 粘贴刚才复制的密码 点击“连接”SSH安全警告 首次连接服务器会出现SSH安全警告，点击“接受并保持”即可 搭建V2ray使用一键安装脚本安装V2ray 推荐使用一键安装脚本，一行代码解决所有问题。 复制下面的代码，然后在Xshell 黑色处点击右键粘贴，然后回车安装。（这里不能使用Ctrl+V粘贴）bash &lt;(curl -s -L https://git.io/v2ray.sh) 也可以通过谷歌云安装官方脚本(据说上面的脚本有后门，对安全性要求高的可以选这个)v2ray官网v2ray配置文件生成器输入 “1” 进行安装选择传输协议 没有特殊需要就直接回车，使用默认的TCP协议。选择端口号 输入端口号，这个自己随意，但是未了避免和以后折腾其他的东西冲突，推荐使用1000以上的端口号但是不能超过65535 建议直接输入“10086” （没有特殊意义，单纯为了好记，PS：中国移动记得给我广告费）广告拦截是否开启广告拦截，看自己需要吧，推荐不要开启，开启广告拦截会消耗服务器资源，国外环境要比国内好得多。开启SS 最好是开启，后面使用游戏加速器会用得上。选择SS端口号 SS端口号，还是随意。但是千万不要和上面V2ray的端口号冲突。输入SS连接密码这个没有要求，只要你自己能记得住就行，越简单越好。选择SS加密协议 不多说，推荐使用默认的。搭建完成 接下来就是回车，回车。 然后喝杯咖啡，等待几分钟，出现下面这个界面就表示服务器搭建完成了 开启BBR 如果使用的是Debian9 系统，BBR是自动开启的。 Ubuntu 18.04/18.10开启BBR加速: Step 1：修改系统变量echo &quot;net.core.default_qdisc=fq&quot; &gt;&gt; /etc/sysctl.conf echo &quot;net.ipv4.tcp_congestion_control=bbr&quot; &gt;&gt; /etc/sysctl.conf Step 2:保存生效sysctl -p Step 3：检查BBR是否开启sysctl net.ipv4.tcp_available_congestion_control如果 返回net.ipv4.tcp_available_congestion_control = bbr cubic reno则 开启 成功！ Step 4：检查BBR是否启动成功lsmod | grep bbr如果 返回tcp_bbr 20480 14则 启动 成功 CentOS 7 开启BBR加速 客户端使用 V2ray和SS客户端使用教程 物尽其用这么高配置的服务器只用来搭建梯子服务器？未免也太浪费了吧，接下来教你在梯子服务器的基础上再搭建一个 个人网盘服务器。 使用NextCloud搭建个人网盘服务器]]></content>
      <tags>
        <tag>v2ray</tag>
        <tag>科学上网</tag>
        <tag>vultr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比特币与区块链入门]]></title>
    <url>%2F2019%2F06%2F30%2F%E6%AF%94%E7%89%B9%E5%B8%81%E4%B8%8E%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[虚拟货币终将迎来春天 区块链入门比特币入门加密货币的本质知乎大佬靠比特币实现财务自由论坛 阮老师写得很通俗易懂了，关于比特币争议也很大，有看好的也有嗤之以鼻的，看了知乎上前段时间的孙宇晨买下巴菲特午餐的讨论，只想说，币圈真乱。我对很多事情都有极大的兴趣，想探索任何未知的东西，我认为好奇心在人的一生中是至关重要的。我不相信人，认为人的行为是不可控的，所以我非常宅。我相信机器，因为机器的结果都能在我的掌控中。]]></content>
      <tags>
        <tag>哎折腾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Next如何在文章摘要展示图片]]></title>
    <url>%2F2019%2F06%2F28%2FHexo-Next%E5%A6%82%E4%BD%95%E5%9C%A8%E6%96%87%E7%AB%A0%E6%91%98%E8%A6%81%E5%B1%95%E7%A4%BA%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[一般有两种方法 在文章的属性列表中添加photos属性编写的文章属性中photos默认为文章的配图，这是我目前最喜欢的配图方式，但是有一个缺点，它不能自定义裁剪和缩略比，展示的是原图，这相当于如果你的每张配图大小比例不一致将会很影响美观性，目前没有很好的解决方案，所以只好自己裁剪好再引入。 如这篇文章： --- title: Hexo Next如何在文章摘要展示图片 date: 2019-06-28 17:43:44 tags: Hexo categories: Hexo photos: - &quot;xxx&quot; --- 在你的正文中使用&lt;!-- more --&gt;进行截断由于markdown是支持原生html的，所以我们可以在正文引用img来为我们的文章设置摘要配图,在&lt;!-- more --&gt;之前的内容都会展示到摘要中(同时与你主题文件中配置的摘要字数有关).如： --- title: Hexo Next如何在文章摘要展示图片 date: 2019-06-28 17:43:44 tags: Hexo categories: Hexo --- &lt;img src=&quot;XXX&quot; width=50% /&gt; 哇，漂亮的小姐姐(❤ ω ❤) &lt;!--more--&gt;]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PAT 1054 求平均值]]></title>
    <url>%2F2019%2F03%2F18%2FPAT-1054-%E6%B1%82%E5%B9%B3%E5%9D%87%E5%80%BC%2F</url>
    <content type="text"><![CDATA[1054 求平均值 （20 分) 本题的基本要求非常简单：给定 N 个实数，计算它们的平均值。但复杂的是有些输入数据可能是非法的。一个“合法”的输入是 [−1000,1000] 区间内的实数，并且最多精确到小数点后 2 位。当你计算平均值的时候，不能把那些非法的数据算在内。输入格式：输入第一行给出正整数 N（≤100）。随后一行给出 N 个实数，数字间以一个空格分隔。输出格式：对每个非法输入，在一行中输出 ERROR: X is not a legal number，其中 X 是输入。最后在一行中输出结果：The average of K numbers is Y，其中 K 是合法输入的个数，Y 是它们的平均值，精确到小数点后 2 位。如果平均值无法计算，则用 Undefined 替换 Y。如果 K 为 1，则输出 The average of 1 number is Y。输入样例 1：75 -3.2 aaa 9999 2.3.4 7.123 2.35输出样例 1：ERROR: aaa is not a legal numberERROR: 9999 is not a legal numberERROR: 2.3.4 is not a legal numberERROR: 7.123 is not a legal numberThe average of 3 numbers is 1.38输入样例 2：2aaa -9999输出样例 2：ERROR: aaa is not a legal numberERROR: -9999 is not a legal numberThe average of 0 numbers is Undefined&lt;/font&gt; 分析：使用sscanf和sprintf函数～sscanf() – 从一个字符串中读进与指定格式相符的数据sprintf() – 字符串格式化命令，主要功能是把格式化的数据写入某个字符串中 题解： #include&lt;iostream&gt; #include&lt;cstring&gt; #include&lt;cstdio&gt; using namespace std; int main() { int n,cnt=0; char a[50],b[50]; cin&gt;&gt;n; double temp,sum=0.0; for(int i=0;i&lt;n;i++) { scanf(&quot;%s&quot;,a); sscanf(a,&quot;%lf&quot;,&amp;temp);//从7.123中读入7.123道temp中 sprintf(b,&quot;%.2f&quot;,temp);//把temp变为7.12写入b中 int flag=0; for(int j=0;j&lt;strlen(a);j++) if(a[j]!=b[j])flag=1; if(flag||temp&lt;-1000||temp&gt;1000) { printf(&quot;ERROR: %s is not a legal number\n&quot;,a); continue; } else { sum+=temp; cnt++; } } if(cnt==1) printf(&quot;The average of 1 number is %.2f&quot;,sum); else if(cnt&gt;1) printf(&quot;The average of %d numbers is %.2f&quot;,cnt,sum/cnt); else printf(&quot;The average of 0 numbers is Undefined&quot;); return 0; }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>字符串处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PAT 1055 集体照]]></title>
    <url>%2F2019%2F03%2F18%2FPAT-1055-%E9%9B%86%E4%BD%93%E7%85%A7%2F</url>
    <content type="text"><![CDATA[1055 集体照 （25 分)拍集体照时队形很重要，这里对给定的 N 个人 K 排的队形设计排队规则如下：每排人数为 N/K（向下取整），多出来的人全部站在最后一排；后排所有人的个子都不比前排任何人矮；每排中最高者站中间（中间位置为 m/2+1，其中 m 为该排人数，除法向下取整）；每排其他人以中间人为轴，按身高非增序，先右后左交替入队站在中间人的两侧（例如5人身高为190、188、186、175、170，则队形为175、188、190、186、170。这里假设你面对拍照者，所以你的左边是中间人的右边）；若多人身高相同，则按名字的字典序升序排列。这里保证无重名。现给定一组拍照人，请编写程序输出他们的队形。输入格式：每个输入包含 1 个测试用例。每个测试用例第 1 行给出两个正整数 N（≤10^4​总人数）和 K（≤10^4，总排数）。随后 N 行，每行给出一个人的名字（不包含空格、长度不超过 8 个英文字母）和身高（[30, 300] 区间内的整数）。输出格式：输出拍照的队形。即K排人名，其间以空格分隔，行末不得有多余空格。注意：假设你面对拍照者，后排的人输出在上方，前排输出在下方。输入样例：10 3Tom 188Mike 170Eva 168Tim 160Joe 190Ann 168Bob 175Nick 186Amy 160John 159输出样例：Bob Tom Joe NickAnn Mike EvaTim Amy John 分析：拍照的最后一行是输出的第一行，人数是m=n-n/k*(k-1),其他行数均为m=n/k，用结构体+vector将身高降序排列，注意身高相同名字按升序排列，用while循环排列每一行，将每一行的排列结果的姓名储存在ans数组中，最中间一个学生应该排在m/2的下标位置，即ans[m / 2] = stu[t].name；然后排左边一列，ans数组的下标 j 从m/2-1开始，一直往左j–，而对于stu的下标 i，是从t+1开始，每次隔一个人选取（即i = i+2，因为另一些人的名字是给右边的），每次把stu[i]的name赋值给ans[j–]；排右边的队伍同理，ans数组的下标 j 从m/2 + 1开始，一直往右j++，stu的下标 i，从t+2开始，每次隔一个人选取（i = i+2），每次把stu[i]的name赋值给ans[j++]，然后输出当前已经排好的ans数组～每一次排完一列row-1，直到row等于0时退出循环表示已经排列并输出所有的行～ #include&lt;iostream&gt; #include&lt;algorithm&gt; #include&lt;vector&gt; using namespace std; struct node{ string name; int high; }; int cmp(struct node a,struct node b ) { return a.high!=b.high?a.high&gt;b.high:a.name&lt;b.name; } int main() { int n,k,m; cin&gt;&gt;n&gt;&gt;k; vector&lt;node&gt;stu(n); for(int i=0;i&lt;n;i++) cin&gt;&gt;stu[i].name&gt;&gt;stu[i].high; sort(stu.begin(),stu.end(),cmp); int t=0,row=k; while(row) { if(row==k) m=n-n/k*(k-1); else m=n/k; vector&lt;string&gt;ans(m); ans[m/2]=stu[t].name; //处理左边一列 int j=m/2-1; for(int i=t+1;i&lt;t+m;i=i+2) ans[j--]=stu[i].name; //处理右边一列 j=m/2+1; for(int i=t+2;i&lt;t+m;i=i+2) ans[j++]=stu[i].name; cout&lt;&lt;ans[0]; for(int i=1;i&lt;m;i++) cout&lt;&lt;&quot; &quot;&lt;&lt;ans[i]; cout&lt;&lt;endl; t=t+m;row--; } return 0; }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PAT 1057 数壹零]]></title>
    <url>%2F2019%2F03%2F18%2FPAT-1057-%E6%95%B0%E5%A3%B9%E9%9B%B6%2F</url>
    <content type="text"><![CDATA[1057 数零壹 （20 分) 给定一串长度不超过 10^5的字符串，本题要求你将其中所有英文字母的序号（字母 a-z 对应序号 1-26，不分大小写）相加，得到整数 N，然后再分析一下 N 的二进制表示中有多少 0、多少 1。例如给定字符串 PAT (Basic)，其字母序号之和为：16+1+20+2+1+19+9+3=71，而 71 的二进制是 1000111，即有 3 个 0、4 个 1。输入格式：输入在一行中给出长度不超过 10^5,以回车结束的字符串。输出格式：在一行中先后输出 0 的个数和 1 的个数，其间以空格分隔。输入样例：PAT (Basic)输出样例：3 4&lt;/font&gt; 分析：用getline接收一行字符串，对于字符串的每一位，如果是字母(isalpha)，则将字母转化为大写(toupper)，并累加(s[i] – ‘A’ + 1)算出n，然后将n转化为二进制，对每一位处理，如果是0则cnt0++，如果是1则cnt1++，最后输出cnt0和cnt1的值～～ 题解： #include&lt;iostream&gt; #include&lt;cstring&gt; #include&lt;cctype&gt; using namespace std; int main() { string s; getline(cin,s); int n=0; for(int i=0;i&lt;s.length();i++) { if(isalpha(s[i])) { s[i]=toupper(s[i]); n+=(s[i]-&#39;A&#39;+1); } } int cnt0=0,cnt1=0; while(n!=0) { if(n%2==0) { cnt0++; } else cnt1++; n=n/2; } cout&lt;&lt;cnt0&lt;&lt;&quot; &quot;&lt;&lt;cnt1; return 0; }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PAT 1035 插入与归并]]></title>
    <url>%2F2019%2F03%2F18%2FPAT-1035-%E6%8F%92%E5%85%A5%E4%B8%8E%E5%BD%92%E5%B9%B6%2F</url>
    <content type="text"><![CDATA[1035 插入与归并（25 分）根据维基百科的定义： 插入排序是迭代算法，逐一获得输入数据，逐步产生有序的输出序列。每步迭代中，算法从输入序列中取出一元素，将之插入有序序列中正确的位置。如此迭代直到全部元素有序。归并排序进行如下迭代操作：首先将原始序列看成 N 个只包含 1 个元素的有序子序列，然后每次迭代归并两个相邻的有序子序列，直到最后只剩下 1 个有序的序列。现给定原始序列和由某排序算法产生的中间序列，请你判断该算法究竟是哪种排序算法？输入格式：输入在第一行给出正整数 N (≤100)；随后一行给出原始序列的 N 个整数；最后一行给出由某排序算法产生的中间序列。这里假设排序的目标序列是升序。数字间以空格分隔。输出格式：首先在第 1 行中输出Insertion Sort表示插入排序、或Merge Sort表示归并排序；然后在第 2 行中输出用该排序算法再迭代一轮的结果序列。题目保证每组测试的结果是唯一的。数字间以空格分隔，且行首尾不得有多余空格。输入样例 1： 10 3 1 2 8 7 5 9 4 6 0 1 2 3 7 8 5 9 4 6 0输出样例 1： Insertion Sort 1 2 3 5 7 8 9 4 6 0输入样例 2： 10 3 1 2 8 7 5 9 4 0 6 1 3 2 8 5 7 4 9 0 6输出样例 2： Merge Sort 1 2 3 8 4 5 7 9 0 6&lt;/font&gt; 思路：先将i指向中间序列中满足从左到右是从小到大顺序的最后一个下标，再将j指向从i+1开始，第一个不满足a[j] == b[j]的下标，如果j顺利到达了下标n，说明是插入排序，再下一次的序列是sort(a, a+i+2);否则说明是归并排序。归并排序就别考虑中间序列了，直接对原来的序列进行模拟归并时候的归并过程，i从0到n/k，每次一段段得sort(a + i k, a + (i + 1) k);最后别忘记还有最后剩余部分的sort(a + n / k * k, a + n);这样是一次归并的过程。直到有一次发现a的顺序和b的顺序相同，则再归并一次，然后退出循环～ 题解： #include&lt;iostream&gt; #include&lt;algorithm&gt; using namespace std; int main() { int N; int a[101], b[101]; // 原始序列a 中间序列b int i, j; cin&gt;&gt;N; for( i=0; i&lt;N; i++ ) cin&gt;&gt;A1[i]; for( i=0; i&lt;N; i++ ) cin&gt;&gt;A2[i]; for( i=0; b[i]&lt;=b[i+1] &amp;&amp; i&lt;N-1; i++ ) ; // i作为有序序列最后一个元素下标退出循环 for( j=++i; a[j]==b[j] &amp;&amp; j&lt;N; j++ ) ; // a b从第一个无序的元素开始，逐一比对 if( j==N ){// 前半部分有序而后半部分未改动可以确定是插入排序 cout&lt;&lt;&quot;Insertion Sort&quot;&lt;&lt;endl; sort( a, a+i+1 ); } else{ cout&lt;&lt;&quot;Merge Sort&quot;&lt;&lt;endl; int k = 1; int flag=1; //用来标记是否归并到 “中间序列” while( flag ) { flag = 0; for( i=0; i&lt;N; i++ ) if( a[i]!=b[i] ) flag = 1; k*=2; for( i=0; i&lt;N/k; i++ ) sort( a+i*k, a+(i+1)*k ); i=k*(N/k); // 对非偶数序列的“尾巴”进行排序 if(i&lt;N-1) sort( a+k*(N/k), a+N ); } } cout&lt;&lt;a[0]; for( i=1; i&lt;N; i++ ) cout&lt;&lt;&quot; &quot;&lt;&lt;a[i]; cout&lt;&lt;endl; return 0; }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>插入与归并</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdowm语法说明]]></title>
    <url>%2F2019%2F03%2F18%2FMarkdown%E8%AF%AD%E6%B3%95%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[写博客什么的超级好用 *斜体* _斜体第二种方法_ **加粗** __加粗的第二种方法__ ___粗斜体___ 两个enter是换行，或者用&lt;/br&gt;标签表示换行 用一行的=或者-表示一级标题和二级标题。如： 一级标题 ======= 二级标题 -------- 也可以在前面加上一到六个#表示标题的1级到6级。如： # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 无序列表：在前面加上 * 或者 + 或者 - 然后加个空格： * ABC * DEF * GHI + JKL + MNO + PQR - STU - VWX - YZZ 有序列表：数字+英文句点+空格。如下： 1. 呵呵 2. 哈哈 3. 嘿嘿 4. 哼哼 &amp;lt; // 会显示为”&lt;“ &amp;amp; // 会显示为”&amp;“：在 href 属性里面，必须将 &amp; 转变为 &amp;amp; \. // 为了防止产生&quot;1.&quot;变为有序列表，则可以写成&quot;1\.&quot; * _ // 如果 * 和 _ 两边都有空白的话，它们就只会被当成普通的符号。 &gt;只在整个段落的第一行最前面加上大于号可以显示引用（此时出现引用形式，并且为斜体）。但是引言内如果要断行，那个空行也必须在前面加上大于号。就像下面写的酱紫： &gt;&gt;区块引言也可以有级别，在前面加上不同数量的大于号即可。比如说这就是一个二级引言。 &gt;&gt;&gt;这是一个三级引言。格式会显示为字体更小了。 C++ 代码块语法高亮:前后使用```,在前面的三点后写上C++。 建立分割线的方法有： * * * ***** - - - ------------------- 超级链接：[超级链接显示的文字](超级链接的网址，可以是绝对路径、相对路径) 也支持HTML格式的超级链接&lt;a href=&quot;https://www.baidu.com/&quot;&gt;百度&lt;/a&gt; 如果要标记一小段行内程序代码，可以用反引号把它包起来（`），像这样： Use the `printf()` function. 插入图片：![图片的替换文字](图片的地址或路径) ![风景区图片](/Snip20160202_227.png) Email邮件： &lt;123456789@qq.com&gt; 锚点：(能够链接到某个一级标题) [想要显示的名称](#锚点的名称) 参考：https://www.jianshu.com/p/191d1e21f7ed]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>标记语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ STL lower_bound & upper_bound]]></title>
    <url>%2F2019%2F01%2F02%2FC-STL-lower-bound-upper-bound%2F</url>
    <content type="text"><![CDATA[background首先，lower_bound和upper_bound是C++ STL中提供的非常实用的函数。其操作对象可以是vector、set以及map。lower_bound返回值一般是&gt;= 给定val的最小指针（iterator）。upper_bound返回值则是 &gt; 给定val的最小指针（iterator）。 vector中的lower_bound &amp; upper_bound// lower_bound/upper_bound example #include &lt;iostream&gt; // std::cout #include &lt;algorithm&gt; // std::lower_bound, std::upper_bound, std::sort #include &lt;vector&gt; // std::vector int main () { int myints[] = {10,20,30,30,20,10,10,20}; std::vector&lt;int&gt; v(myints,myints+8); // 10 20 30 30 20 10 10 20 std::sort (v.begin(), v.end()); // 10 10 10 20 20 20 30 30 std::vector&lt;int&gt;::iterator low,up; low=std::lower_bound (v.begin(), v.end(), 20); // ^ up= std::upper_bound (v.begin(), v.end(), 20); // ^ std::cout &lt;&lt; &quot;lower_bound at position &quot; &lt;&lt; (low- v.begin()) &lt;&lt; &#39;\n&#39;; std::cout &lt;&lt; &quot;upper_bound at position &quot; &lt;&lt; (up - v.begin()) &lt;&lt; &#39;\n&#39;; return 0; } set中的 lower_bound 和 upper_bound// set::lower_bound/upper_bound #include &lt;iostream&gt; #include &lt;set&gt; int main () { std::set&lt;int&gt; myset; std::set&lt;int&gt;::iterator itlow,itup; for (int i=1; i&lt;10; i++) myset.insert(i*10); // 10 20 30 40 50 60 70 80 90 itlow=myset.lower_bound (30); // ^ itup=myset.upper_bound (60); // ^ // 由于set中没有像vector中那样排序的概念，因此itlow - myset.begin()是错误的，itlow重载这类运算符 myset.erase(itlow,itup); // 10 20 70 80 90 // erase 删除时传入两个iterator，同样删除区间是左闭右开 std::cout &lt;&lt; &quot;myset contains:&quot;; for (std::set&lt;int&gt;::iterator it=myset.begin(); it!=myset.end(); ++it) std::cout &lt;&lt; &#39; &#39; &lt;&lt; *it; std::cout &lt;&lt; &#39;\n&#39;; return 0; } map中的lower_bound 和 upper_bound// map::lower_bound/upper_bound #include &lt;iostream&gt; #include &lt;map&gt; int main () { std::map&lt;char,int&gt; mymap; std::map&lt;char,int&gt;::iterator itlow,itup; mymap[&#39;a&#39;]=20; mymap[&#39;b&#39;]=40; mymap[&#39;c&#39;]=60; mymap[&#39;d&#39;]=80; mymap[&#39;e&#39;]=100; itlow=mymap.lower_bound (&#39;b&#39;); // itlow points to b itup=mymap.upper_bound (&#39;d&#39;); // itup points to e (not d!) 同样返回的是&gt;&#39;d&#39;对应的iterator mymap.erase(itlow,itup); // erases [itlow,itup) // print content: for (std::map&lt;char,int&gt;::iterator it=mymap.begin(); it!=mymap.end(); ++it) std::cout &lt;&lt; it-&gt;first &lt;&lt; &quot; =&gt; &quot; &lt;&lt; it-&gt;second &lt;&lt; &#39;\n&#39;; return 0; }]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《慢慢来，一切都来得及》读书笔记]]></title>
    <url>%2F2018%2F12%2F18%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[因为我知道自己每一天都在认真地生活着，因为我正努力一步步朝着梦想迈进，因此每一天过得还算充实和快乐。这样一想我就不再焦虑了。我又问自己，如果给自己两年的时间去学习英语口语，慢慢来，给自己20年的时间去实现梦想，慢慢来，可以吗？答案是可以。我顿时整个人放松下来，当我允许自己慢慢来时，忽然感觉那种轻装上阵，脚踏实地的坚实力量又回到了自己的身上。有朋友问我，你会一直待在上海吗？我会回答不知道，因为我觉得未来是迷茫的，未来的事情也是难以预料的。我对生活一直怀有很多困惑，我觉得正是这些困惑推动着我不断去思考、去努力、去前进。 你问我不知道自己想要什么，怎么办？我会告诉你，那你赶紧去找啊。在20岁出头的年纪，不知道自己想要什么是一件极其正常的事情，也是一件幸运的事情，因为当你有了困惑之后，你才会思考，才会一步步地寻找自己想要的东西。 如果你真的没有发现自己喜欢的事情，那请不要放过任何尝试的机会，你可以接受各种挑战，尝试去做各种事情，不要拿自己太当回事了，丢弃那虚妄的自尊，不要怕出丑不要怕失败，你甚至要允许自己经常失败，给你面对失败的经验，给自己不断重新再来的勇气，你要做的就是积极地尝试，直到找到自己内心真正的热爱，找到自己愿意为之努力的梦想。要给自己时间，让自己慢慢来，给自己面对失败的勇气和对梦想持续的热情，因为最难的事情不是面对失败，而是面对一而再再而三的失败还能永保热情。 人生从来不是规划出来的，而是一步步走出来的。找到自己喜欢的事情，每天做那么一点点，时间一长，你就会看到自己的成长。 对于很多像我一样缺乏独立思考能力，又不懂得借鉴他人历史教训的人，只有亲身经历过，才能知道自己想要什么样的生活，就算不知道自己到底想要的是怎样的生活，也至少能明白自己不想要怎样的生活。 我一直想不明白，怎么有这么多人这样算计人生呢？人生真的不是算计出来的。有人说：“只有一次的生命，需要活得真性情一点。”真性情就是你不要压抑自己的需求，你要听从自己内心的声音，过自己想要的生活。也许我在念书的时候就结婚生孩子呢？就算念完书，年纪大了再结婚生子又怎样呢？就算我一辈子不结婚生孩子又怎样呢？难道就不会幸福吗？你的生活是需要别人对你说“好”你才会觉得好吗？你的安全感是来自符合社会习俗制定的标准吗？你的幸福感是建立在别人对你的生活投以羡慕嫉妒的目光上的吗？真正的强者是能在人生的旅途中蜕变为只对自己心声负责的达人。 那些早早找到自己的人生梦想，遵循天命的人，固然很幸运；但是，那些还没有找到自己应该走的道路的人也不必感到万分痛苦，因为一切都还来得及，你要给自己慢慢来的机会。我们乡下的老人常常告诫年轻人的一句话：饭要一口口地吃，路要一步步地走。 我常常告诫自己说，想做一件事就要立刻行动起来，不然就跟那些徒有羡慕之情却给自己诸多理由毫无行动的人们一个样。 只有一种英雄主义，就是在认清生活真相之后依然热爱生活 梭罗说：“生命并没有价值，除非你选择并赋予它价值。没有哪一个地方有幸福，除非你为自己带来幸福。” “常有人说我坚持得好，其实真正喜欢的事不用‘坚持’，让自己变得健康，真的很容易，不停地跑下去，就不会老。跑步可以沿途欣赏美景，享受运动的快乐，人生就是一场马拉松，谁健康，谁就能跑得更长远！” “做真正喜欢的事情不用坚持。” 所以，找到自己喜欢的事情非常重要。因为喜欢，你不用苦苦坚持，也因为喜欢，你愿意投入时间、精力，长久以往获得成功就是自然而然的事情。这一点同样适用在寻找爱人这件事上。找到自己真正喜欢的人，与之在一起，并不需要费力坚持，太过辛苦经营，只因为你们在一起是喜欢的、快乐的、充实的。在一起的时间越长，爱情如美酒一般变得愈加醇美。 就像山田本一所说的那样，拆分目标的好处在于：一、使得原本看起来有些吓人的大目标变得容易靠近和比较现实了。当你的心里认定这个目标可以实现时，就不会因为害怕失败而放弃你的行动。人做一件事拖延的原因有很多，其中一个就是把目标定得太高，害怕自己无法实现，其实就是恐惧失败。细化目标可以减少或者避免由于害怕失败而产生的拖延。二、细化目标还可以增加信心。当你觉得目标可以实现时、容易成功时，你就会更有信心。不言而喻的是信心对完成任务的作用很大。 吴淡如在《时间管理幸福学》中说道：“只要想到一件事情可以‘一石二鸟’或‘一石三鸟’我们比较容易有‘赚到’的感觉，会因为自己的‘贪恋’而继续下去。” “为一件事情找到多种目的”在工作和学习中都很适用。 做一件事情时，加强它的正面意义，为它多找一些其他目的，不仅能让你快乐地完成这件事，还让你的生活变得积极而高效，充满正能量。 下雨天的时候，一下班我就匆匆回家，刚到楼梯口，嘴里就念着：泡面、泡面、荷包蛋、荷包蛋……（我是个多容易满足的正牌吃货啊）然后“咔嚓”一声开门，蹬掉高跟鞋，用平底锅煮泡面吃，就着外面的雨声，吃着热气腾腾的荷包蛋泡面。下雨的夜晚，抱着锅，吃着泡面，我会感觉很幸福呢！ 孤独要趁好时光。趁着好时光，独自欣赏月升日落，独自面对生活的波澜起伏。孤独是人生的重要伴侣，学会独处，乐在独处的人也许过得才最自由自在。越来越觉得人的一生归根结底是与自己相处，与自己斗争的过程，要与自己的万千情绪相处，与自己的各种欲望斗争，与自己的软弱、惰性、劣势不停地斗争下去，爱恨情仇，贪嗔痴慢全是你自己一个人的。 上周和许久未见的一个朋友见面，他说我变得自信了。我明白我的自信不是来自薪水的增加、消费能力的提高或者工作能力的增强，而是来源于相信自己有进一步完善自己、改变自己的能力，同时能看到自己的局限，做得到改变能够改变的，接受不能改变的；相信自己有爱自己、爱他人的能力；相信自己一个人生活也过得好。 以前我一直在逃离生活，与生活保持着一定的距离，觉得走到哪里，怎样的生活都不是自己想要的。这两年我感觉自己渐渐脚踏实地了，开始贴着生活在好好地过日子，虽然做得还不够好，但是一直在进步。蓦然回首，我一个人走过了那么多时光，也走了很远，从乡村到都市，从荒凉到繁华，从深夜到清晨，从弱小到强大，从艰难到轻松，从痛苦到狂喜，所有的这些我都一个人一一走过，虽然我走得慢，但是我走得很认真很努力，从没有因为害怕而停止。 通过观察和经验，我发现那些稍微准备就去干的人和非要准备充分才去行动的人最大的区别就在于对人生的认知不同。前者认为人生是各种体验的集合，后者认为人生是各种成功的档案。因此前者往往充满活力和冒险精神，充满勇气和自信。注重过程，乐于接受变化和挑战，不惧怕失败，情绪乐观，面对失败也较轻松和正面，觉得至少能收获一份经验。这样的人常常大胆尝试，敢于打破规则，愿意去做许多未知的事情；后者则畏首畏尾，缺乏勇气和自信，全然以目标为导向。害怕变化和挑战，也非常害怕失败，只要一失败简直会要了他的命，压力沉重，甚至陷入无法自拔的沮丧和毁灭之中，这样的人因为很多的不敢为，所以经历的事情也比较少，囿于自身思维中的各种限制，躲在自己认为的安全区中。 李欣频说：“当你匮乏时不会有人把资源给你，只有当你真正丰富了才会给你。”当你真正做到踏踏实实地完善自己、丰富自己，专心做可以提升自己的事情，学习并拥有更高的技能的时候，很多机会就会降临到你身上。 你经受的每一份痛苦都是上天赐予你的一份神秘礼物（其实能这样想还真不容易），我希望你能从所受的每一份痛苦中获得学习、累积和成长。如果你经历的痛苦仅仅是痛苦，无法将痛苦转换成人生的养分，去灌注自己内心的坚强之花，那么你也许一辈子都痛苦脆弱，与坚强无缘，也找不到自己的存在感。 我一边心不甘情不愿地写着方案，一边想到后面还有那么多工作要做，想着明天就要提交工作成果了。重压、愤怒、怨恨、控诉、敌意和挫败等负面情绪一股脑地冲向我，我崩溃了，居然呜呜地哭了起来。意识到眼泪正夺眶而出，我被自己“正在哭”这一事实吓坏了，这虽然不是我第一次因为工作压力大而哭泣，但那是前两年的事情了，现在我毕竟是工作了三年的职场之人，怎么就这样脆弱，不堪一击？这时心中有一个声音响起：“哭能解决问题吗？难道有人逼你这样做吗？现在这个局面是谁造成的？你打算怎么办？” 趋利避害，逃避责任，这是每一个人都会有的正常心理，但是这并不代表它是好东西，相反，这正是导致许多人生活不幸的原因。 是的，我们需要停止抱怨，抱怨只会带来坏处，一点正面积极的好处都没有的，它会分散你的注意力，消耗你的精力，瓦解你的信心，摧毁你的行动力。抱怨还会限制我们思考，阻挡我们有效工作。因为，当我们抱怨的时候就把焦点放在我们不想要的东西上，所谈论的是负面的、出错的事情，而我们把注意力放在什么上头，那个东西就会扩大。我们抱怨的言语会影响我们的思维，进而影响我们的想法和态度，从而给我们的生活带来负面的影响。同时抱怨还会影响我们的人际关系。试想一下，谁愿意跟一个成天抱怨的人在一起共事呢？ Bronnie Ware专门照顾那些临终病人，听到很多人临终前说出他们一生里最后悔的事。她作了一个概括，有5件事是大多数人最后悔的。 我希望当初我有勇气过自己真正想要的生 活，而不是别人希望我过的生活。 我希望当初我没有花这么多精力在工作上。 我希望当初我能有勇气表达我的感受。 我希望当初我能和朋友保持联系。 我希望当初我能让自己活得开心点。 亲自听闻了1000多例病患的临终遗言后，他写下了这本书，其中排在前五位的是： 没做自己想做的事。 没有实现梦想。 做过对不起良心的事。 被感情左右度过一生。 没有尽力帮助过别人。 我想，人生的意义对任何人来说都显得重要。德国哲学家威廉·施密德在自己《幸福》一书中表达了这样的观点：幸福并不是人生的第一要义，意义才是。我们真正要寻找和建立的并不是幸福，而是意义。我想也许当我们找到自己人生的意义时，我们会觉得自己更有价值，更幸福，更能够战胜人生的虚无和幻灭。 我主张积极地看待自己的童年阴影。如果我们过去的经验、受到的教育、家庭环境和社会环境决定了我们的未来，那不是说明我们的人生早早就被安排好了，这听起来多可怕啊？把自己的问题全部归咎于童年阴影是很不负责的，置自己的主观能动性和创造性于何处？如果依照这种理论，你会带着很负面的能量生活，我劝大家不要信奉。 虽然全世界72.8%的人都会得拖延症，虽然拖延症是个可怕的顽疾，但是治疗起来却也很简单：立即行动。连岳在他的专栏里说：“有什么事让你拖得心烦，先做三分钟再说。如果你是个专栏作家，从昨晚开始就在拖一篇文章，那不如现在马上坐下，打开写字板，先写180秒，于是，奇迹发生了。三分钟后你会继续写，直到把文章写完。” 《少有人走的路》中说“推迟满足感，意味着不贪图暂时的安逸，重新设置人生快乐与痛苦的次序：首先，面对问题并感受痛苦；然后，解决问题并享受更大的快乐，这是唯一可行的生活方式” 不要草率地给自己贴标签。如果你并没有连续20几天持续睡不着、晚睡，只是因为诸如失恋、情绪低落、被领导批评、工作不顺等，那么，不要给自己贴上失眠症、晚睡强迫症、抑郁症之类的标签。这并不是一件值得赶时髦的事情，因为一旦贴上标签，你容易躲在这个舒适的标签里，不愿对自己负责，没有改变自己行为的动力和能量。 管理好白天的时间。不要认为很多事情白天干不了、干不好，这是不良的心理暗示。我有个朋友认为白天写不了文章，只有夜深人静的时候才能安心写稿，其实白天一样可以写稿子，只要自己开始动笔写起来，就会投入其中。学会积极地在白天做科学的时间规划，提高白天的工作效率，避免拖拉，将工作任务在白天完成，把晚上留给睡眠。 每年的3月21日是世界睡眠日，在这一天全球性健康睡眠主题公益活动中有一个“多睡一小时”的活动 让我们互道一声晚安 送走这匆匆的一天 值得怀念的请你珍藏 应该忘记的莫再留恋 让我们互道一声晚安 迎接那崭新的明天 把握那美好的前程 珍惜你锦绣的人生 愿你走进甜甜的梦乡 祝你有个宁静的夜晚 晚安 晚安 再说一声 明天见 你在哪一方面花了时间，那一方面就会回馈给你成果，一切的付出都不会白费如流水。学习如是，工作如是，恋爱亦如是。 兴趣真的有那么重要吗？其实不然。兴趣带来的热情只是最初的火种，想要形成燎原之势还需要我们持续不懈地投入，人是因为把一件事情干得越来越好才越来越有兴趣的，不是对什么感兴趣才干得好。]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>成长</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[first blood]]></title>
    <url>%2F2018%2F12%2F11%2Ffirstblood%2F</url>
    <content type="text"><![CDATA[This is my first blog! 不忘初心，假装这里有很多字 嗯，写完了，滚去四级备考了 考试必过！]]></content>
      <tags>
        <tag>试验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[测试]]></title>
    <url>%2F2018%2F12%2F11%2F%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F12%2F11%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
